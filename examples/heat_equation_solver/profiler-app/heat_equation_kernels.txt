Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554231 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 519.066 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 519.13 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554231
[554231] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.28
    SM Frequency            cycle/usecond       886.65
    Elapsed Cycles                  cycle       10,074
    Memory Throughput                   %        12.69
    DRAM Throughput                     %         0.30
    Duration                      usecond        11.36
    L1/TEX Cache Throughput             %        15.78
    L2 Cache Throughput                 %         4.52
    SM Active Cycles                cycle     8,094.80
    Compute (SM) Throughput             %        26.41
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        39.01
    Achieved Active Warps Per SM           warp        12.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 21.98%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (39.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554284 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 538.344 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 538.433 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554284
[554284] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       899.52
    Elapsed Cycles                  cycle       10,483
    Memory Throughput                   %        29.57
    DRAM Throughput                     %         0.29
    Duration                      usecond        11.65
    L1/TEX Cache Throughput             %        36.11
    L2 Cache Throughput                 %         4.53
    SM Active Cycles                cycle     8,579.63
    Compute (SM) Throughput             %        32.79
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        40.07
    Achieved Active Warps Per SM           warp        12.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554327 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 520.028 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 520.1 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554327
[554327] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.25
    SM Frequency            cycle/usecond       885.51
    Elapsed Cycles                  cycle        9,524
    Memory Throughput                   %        13.43
    DRAM Throughput                     %         0.32
    Duration                      usecond        10.75
    L1/TEX Cache Throughput             %        16.49
    L2 Cache Throughput                 %         4.81
    SM Active Cycles                cycle     7,749.70
    Compute (SM) Throughput             %        28.14
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        37.41
    Achieved Active Warps Per SM           warp        11.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.19%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (37.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554375 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.165 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 543.243 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554375
[554375] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       913.50
    Elapsed Cycles                  cycle       10,378
    Memory Throughput                   %        29.85
    DRAM Throughput                     %         0.29
    Duration                      usecond        11.36
    L1/TEX Cache Throughput             %        36.13
    L2 Cache Throughput                 %         4.48
    SM Active Cycles                cycle     8,574.87
    Compute (SM) Throughput             %        31.69
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        38.64
    Achieved Active Warps Per SM           warp        12.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 22.72%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (38.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554430 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 570.389 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 570.457 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554430
[554430] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       925.46
    Elapsed Cycles                  cycle        8,383
    Memory Throughput                   %        15.25
    DRAM Throughput                     %         0.36
    Duration                      usecond         9.06
    L1/TEX Cache Throughput             %        20.81
    L2 Cache Throughput                 %         5.42
    SM Active Cycles                cycle     6,141.23
    Compute (SM) Throughput             %        15.25
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.07
    Achieved Active Warps Per SM           warp         9.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 39.86%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=1
Block size: 1 x 1
==PROF== Connected to process 554480 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 504.928 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 505.035 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554480
[554480] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 50, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       930.01
    Elapsed Cycles                  cycle        8,369
    Memory Throughput                   %        15.28
    DRAM Throughput                     %         0.36
    Duration                      usecond         8.99
    L1/TEX Cache Throughput             %        21.21
    L2 Cache Throughput                 %         5.45
    SM Active Cycles                cycle     6,023.30
    Compute (SM) Throughput             %        15.28
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,500
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                5.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.58
    Achieved Active Warps Per SM           warp         9.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.83%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554522 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 520.166 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 520.235 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554522
[554522] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        15.96
    SM Frequency            cycle/nsecond         2.26
    Elapsed Cycles                  cycle       17,970
    Memory Throughput                   %         3.70
    DRAM Throughput                     %         0.17
    Duration                      usecond         7.97
    L1/TEX Cache Throughput             %        12.90
    L2 Cache Throughput                 %         2.88
    SM Active Cycles                cycle     5,149.67
    Compute (SM) Throughput             %         7.73
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 29.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        35.35
    Achieved Active Warps Per SM           warp        11.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 29.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (35.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554564 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 500.65 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 500.715 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554564
[554564] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.04
    SM Frequency            cycle/usecond       850.09
    Elapsed Cycles                  cycle        7,243
    Memory Throughput                   %        21.80
    DRAM Throughput                     %         0.41
    Duration                      usecond         8.51
    L1/TEX Cache Throughput             %        29.64
    L2 Cache Throughput                 %         3.97
    SM Active Cycles                cycle     5,323.23
    Compute (SM) Throughput             %        24.60
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              48
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 25.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        37.14
    Achieved Active Warps Per SM           warp        11.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (37.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554606 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 557.54 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 557.599 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554606
[554606] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.23
    SM Frequency            cycle/usecond       880.35
    Elapsed Cycles                  cycle        7,019
    Memory Throughput                   %         9.48
    DRAM Throughput                     %         0.43
    Duration                      usecond         7.97
    L1/TEX Cache Throughput             %        12.97
    L2 Cache Throughput                 %         3.97
    SM Active Cycles                cycle     5,127.57
    Compute (SM) Throughput             %        19.95
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 33.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        33.41
    Achieved Active Warps Per SM           warp        10.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 33.18%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554649 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.504 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 549.565 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554649
[554649] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.29
    SM Frequency            cycle/usecond       888.25
    Elapsed Cycles                  cycle        7,422
    Memory Throughput                   %        21.27
    DRAM Throughput                     %         0.40
    Duration                      usecond         8.35
    L1/TEX Cache Throughput             %        27.87
    L2 Cache Throughput                 %         3.79
    SM Active Cycles                cycle     5,661.10
    Compute (SM) Throughput             %        22.93
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              48
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 32.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        33.86
    Achieved Active Warps Per SM           warp        10.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 32.27%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554704 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.324 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 540.415 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554704
[554704] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.68
    SM Frequency            cycle/usecond       941.87
    Elapsed Cycles                  cycle        5,969
    Memory Throughput                   %        11.13
    DRAM Throughput                     %         0.50
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %        16.71
    L2 Cache Throughput                 %         4.64
    SM Active Cycles                cycle     3,976.03
    Compute (SM) Throughput             %        11.22
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 40.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.90
    Achieved Active Warps Per SM           warp         9.57
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.2%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=2
Block size: 1 x 2
==PROF== Connected to process 554754 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 562.795 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 562.853 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554754
[554754] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 25, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       943.96
    Elapsed Cycles                  cycle        6,043
    Memory Throughput                   %        11.00
    DRAM Throughput                     %         0.50
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %        16.70
    L2 Cache Throughput                 %         4.58
    SM Active Cycles                cycle        3,979
    Compute (SM) Throughput             %        11.08
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 41.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.31
    Achieved Active Warps Per SM           warp         9.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 554796 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 596.82 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 596.878 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554796
[554796] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.08
    SM Frequency            cycle/usecond       862.48
    Elapsed Cycles                  cycle        5,330
    Memory Throughput                   %         6.60
    DRAM Throughput                     %         0.56
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        10.50
    L2 Cache Throughput                 %         3.16
    SM Active Cycles                cycle     3,350.80
    Compute (SM) Throughput             %        13.84
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 36.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        31.73
    Achieved Active Warps Per SM           warp        10.15
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 36.55%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 554839 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 544.913 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 545.019 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554839
[554839] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.81
    SM Frequency            cycle/usecond       823.36
    Elapsed Cycles                  cycle        5,563
    Memory Throughput                   %        14.87
    DRAM Throughput                     %         0.54
    Duration                      usecond         6.75
    L1/TEX Cache Throughput             %        22.81
    L2 Cache Throughput                 %         3.18
    SM Active Cycles                cycle     3,623.43
    Compute (SM) Throughput             %        16.95
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              72
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 33.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        33.18
    Achieved Active Warps Per SM           warp        10.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 33.63%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 554881 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 603.809 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 603.892 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554881
[554881] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.16
    SM Frequency            cycle/usecond       864.42
    Elapsed Cycles                  cycle        5,367
    Memory Throughput                   %         6.56
    DRAM Throughput                     %         0.55
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %        10.15
    L2 Cache Throughput                 %         3.15
    SM Active Cycles                cycle     3,470.43
    Compute (SM) Throughput             %        13.90
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 40.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.65
    Achieved Active Warps Per SM           warp         9.49
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.71%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 554938 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 519.267 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 519.39 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554938
[554938] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.07
    SM Frequency            cycle/usecond       855.60
    Elapsed Cycles                  cycle        5,778
    Memory Throughput                   %        14.31
    DRAM Throughput                     %         0.52
    Duration                      usecond         6.75
    L1/TEX Cache Throughput             %        22.02
    L2 Cache Throughput                 %         2.95
    SM Active Cycles                cycle     3,753.90
    Compute (SM) Throughput             %        15.61
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              72
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 38.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.76
    Achieved Active Warps Per SM           warp         9.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 554989 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 614.573 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 614.659 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 554989
[554989] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.55
    SM Frequency            cycle/usecond       924.92
    Elapsed Cycles                  cycle        4,413
    Memory Throughput                   %         7.97
    DRAM Throughput                     %         0.68
    Duration                      usecond         4.77
    L1/TEX Cache Throughput             %        13.88
    L2 Cache Throughput                 %         3.84
    SM Active Cycles                cycle     2,533.87
    Compute (SM) Throughput             %         8.20
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 40.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.72
    Achieved Active Warps Per SM           warp         9.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=4
Block size: 1 x 4
==PROF== Connected to process 555031 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.2 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 539.239 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555031
[555031] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 13, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.51
    SM Frequency            cycle/usecond       916.46
    Elapsed Cycles                  cycle        4,372
    Memory Throughput                   %         8.05
    DRAM Throughput                     %         0.68
    Duration                      usecond         4.77
    L1/TEX Cache Throughput             %        13.98
    L2 Cache Throughput                 %         3.83
    SM Active Cycles                cycle     2,515.50
    Compute (SM) Throughput             %         8.27
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 41.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.10
    Achieved Active Warps Per SM           warp         9.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.79%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555073 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.664 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 553.709 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555073
[555073] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.87
    SM Frequency            cycle/usecond       823.25
    Elapsed Cycles                  cycle        4,163
    Memory Throughput                   %         4.69
    DRAM Throughput                     %         0.71
    Duration                      usecond         5.06
    L1/TEX Cache Throughput             %         8.43
    L2 Cache Throughput                 %         2.72
    SM Active Cycles                cycle     2,317.03
    Compute (SM) Throughput             %         9.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.37
    Achieved Active Warps Per SM           warp         8.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 45.25%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (27.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555115 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 591.894 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 591.978 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555115
[555115] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.92
    SM Frequency            cycle/usecond       830.56
    Elapsed Cycles                  cycle        4,386
    Memory Throughput                   %        10.28
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.28
    L1/TEX Cache Throughput             %        17.87
    L2 Cache Throughput                 %         2.78
    SM Active Cycles                cycle        2,524
    Compute (SM) Throughput             %        11.81
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             120
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.91
    Achieved Active Warps Per SM           warp         9.25
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 42.18%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555170 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 517.727 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 517.778 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555170
[555170] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.46
    SM Frequency            cycle/usecond       770.27
    Elapsed Cycles                  cycle        4,092
    Memory Throughput                   %         4.79
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %         8.70
    L2 Cache Throughput                 %         2.76
    SM Active Cycles                cycle     2,251.67
    Compute (SM) Throughput             %        10.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.34
    Achieved Active Warps Per SM           warp         9.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.32%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555220 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 614.413 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 614.513 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555220
[555220] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       805.85
    Elapsed Cycles                  cycle        4,204
    Memory Throughput                   %        10.73
    DRAM Throughput                     %         0.71
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %        19.52
    L2 Cache Throughput                 %         2.68
    SM Active Cycles                cycle     2,310.87
    Compute (SM) Throughput             %        11.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             120
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.75
    Achieved Active Warps Per SM           warp         9.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.5%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555263 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3550.7 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3550.75 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555263
[555263] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       917.49
    Elapsed Cycles                  cycle        3,349
    Memory Throughput                   %         5.83
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %        11.45
    L2 Cache Throughput                 %         3.37
    SM Active Cycles                cycle     1,704.83
    Compute (SM) Throughput             %         6.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.53
    Achieved Active Warps Per SM           warp         9.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 42.94%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=8
Block size: 1 x 8
==PROF== Connected to process 555341 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 555.384 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 555.436 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555341
[555341] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 7, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       917.21
    Elapsed Cycles                  cycle        3,349
    Memory Throughput                   %         5.84
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %        11.96
    L2 Cache Throughput                 %         3.34
    SM Active Cycles                cycle     1,632.20
    Compute (SM) Throughput             %         6.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.25
    Achieved Active Warps Per SM           warp         9.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 43.5%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555383 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 545.862 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 545.969 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555383
[555383] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.88
    SM Frequency            cycle/usecond       826.66
    Elapsed Cycles                  cycle        4,127
    Memory Throughput                   %         2.84
    DRAM Throughput                     %         0.73
    Duration                      usecond         4.99
    L1/TEX Cache Throughput             %         5.18
    L2 Cache Throughput                 %         2.30
    SM Active Cycles                cycle        2,261
    Compute (SM) Throughput             %         5.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.83
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 66.34%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555425 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 531.159 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 531.206 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555425
[555425] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.70
    SM Frequency            cycle/usecond       807.19
    Elapsed Cycles                  cycle        4,161
    Memory Throughput                   %         6.33
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.15
    L1/TEX Cache Throughput             %        11.68
    L2 Cache Throughput                 %         2.47
    SM Active Cycles                cycle     2,252.77
    Compute (SM) Throughput             %         7.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             216
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.47
    Achieved Active Warps Per SM           warp         5.59
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 65.06%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555467 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 519.363 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 519.427 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555467
[555467] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.37
    SM Frequency            cycle/usecond       760.48
    Elapsed Cycles                  cycle        3,992
    Memory Throughput                   %         2.95
    DRAM Throughput                     %         0.76
    Duration                      usecond         5.25
    L1/TEX Cache Throughput             %         5.76
    L2 Cache Throughput                 %         2.41
    SM Active Cycles                cycle     2,042.43
    Compute (SM) Throughput             %         6.06
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.68
    Achieved Active Warps Per SM           warp         5.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 64.63%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555510 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 544.524 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 544.569 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555510
[555510] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.43
    SM Frequency            cycle/usecond       767.06
    Elapsed Cycles                  cycle        3,929
    Memory Throughput                   %         6.70
    DRAM Throughput                     %         0.77
    Duration                      usecond         5.12
    L1/TEX Cache Throughput             %        12.35
    L2 Cache Throughput                 %         2.43
    SM Active Cycles                cycle     2,131.53
    Compute (SM) Throughput             %         7.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             216
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.85
    Achieved Active Warps Per SM           warp         5.71
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 64.29%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555564 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 532.518 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 532.595 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555564
[555564] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       915.74
    Elapsed Cycles                  cycle        3,284
    Memory Throughput                   %         3.57
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         6.84
    L2 Cache Throughput                 %         2.89
    SM Active Cycles                cycle     1,710.27
    Compute (SM) Throughput             %         3.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.52
    Achieved Active Warps Per SM           warp         5.61
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 64.95%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=16
Block size: 1 x 16
==PROF== Connected to process 555614 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.481 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 539.544 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555614
[555614] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 4, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       906.62
    Elapsed Cycles                  cycle        3,251
    Memory Throughput                   %         3.60
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         7.18
    L2 Cache Throughput                 %         2.93
    SM Active Cycles                cycle     1,631.37
    Compute (SM) Throughput             %         3.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.14
    Achieved Active Warps Per SM           warp         5.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 65.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555670 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 515.805 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 515.876 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555670
[555670] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       802.39
    Elapsed Cycles                  cycle        4,340
    Memory Throughput                   %         2.01
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.41
    L1/TEX Cache Throughput             %         2.56
    L2 Cache Throughput                 %         2.01
    SM Active Cycles                cycle     2,541.20
    Compute (SM) Throughput             %         2.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.11
    Achieved Active Warps Per SM           warp         2.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.79%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.1%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555712 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 528.564 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 528.636 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555712
[555712] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       785.22
    Elapsed Cycles                  cycle        4,021
    Memory Throughput                   %         3.43
    DRAM Throughput                     %         0.75
    Duration                      usecond         5.12
    L1/TEX Cache Throughput             %         6.54
    L2 Cache Throughput                 %         2.38
    SM Active Cycles                cycle     2,110.77
    Compute (SM) Throughput             %         3.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             408
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.37
    Achieved Active Warps Per SM           warp         3.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.4%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555756 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 529.399 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 529.507 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555756
[555756] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.27
    SM Frequency            cycle/usecond       742.91
    Elapsed Cycles                  cycle        3,947
    Memory Throughput                   %         2.20
    DRAM Throughput                     %         0.76
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %         3.30
    L2 Cache Throughput                 %         2.20
    SM Active Cycles                cycle     1,986.33
    Compute (SM) Throughput             %         3.23
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.54
    Achieved Active Warps Per SM           warp         3.05
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.92%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.5%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555812 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 538.634 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 538.7 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555812
[555812] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.37
    SM Frequency            cycle/usecond       754.82
    Elapsed Cycles                  cycle        3,917
    Memory Throughput                   %         3.53
    DRAM Throughput                     %         0.77
    Duration                      usecond         5.18
    L1/TEX Cache Throughput             %         6.81
    L2 Cache Throughput                 %         2.26
    SM Active Cycles                cycle     2,027.27
    Compute (SM) Throughput             %         3.98
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             408
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.67
    Achieved Active Warps Per SM           warp         3.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.65%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555862 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.374 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 539.421 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555862
[555862] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       902.15
    Elapsed Cycles                  cycle        3,378
    Memory Throughput                   %         2.55
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         3.65
    L2 Cache Throughput                 %         2.55
    SM Active Cycles                cycle     1,780.50
    Compute (SM) Throughput             %         1.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.67
    Achieved Active Warps Per SM           warp         3.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.67%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=32
Block size: 1 x 32
==PROF== Connected to process 555904 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3565.76 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 3565.81 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555904
[555904] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 2, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       929.33
    Elapsed Cycles                  cycle        3,451
    Memory Throughput                   %         2.52
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.71
    L1/TEX Cache Throughput             %         3.58
    L2 Cache Throughput                 %         2.52
    SM Active Cycles                cycle     1,811.30
    Compute (SM) Throughput             %         1.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.66
    Achieved Active Warps Per SM           warp         3.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.67%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 555979 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 614.564 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 614.638 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 555979
[555979] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       803.85
    Elapsed Cycles                  cycle        4,400
    Memory Throughput                   %         1.90
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         2.65
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle     2,450.80
    Compute (SM) Throughput             %         2.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.57
    Achieved Active Warps Per SM           warp         3.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 556021 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 626.55 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 626.613 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556021
[556021] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       787.93
    Elapsed Cycles                  cycle        4,013
    Memory Throughput                   %         3.44
    DRAM Throughput                     %         0.75
    Duration                      usecond         5.09
    L1/TEX Cache Throughput             %         6.64
    L2 Cache Throughput                 %         2.23
    SM Active Cycles                cycle     2,078.17
    Compute (SM) Throughput             %         3.87
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             792
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.56
    Achieved Active Warps Per SM           warp         3.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.44%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 556063 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 563.022 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 563.084 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556063
[556063] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.27
    SM Frequency            cycle/usecond       745.12
    Elapsed Cycles                  cycle        3,820
    Memory Throughput                   %         2.18
    DRAM Throughput                     %         0.79
    Duration                      usecond         5.12
    L1/TEX Cache Throughput             %         3.38
    L2 Cache Throughput                 %         2.18
    SM Active Cycles                cycle     1,936.20
    Compute (SM) Throughput             %         3.34
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.80
    Achieved Active Warps Per SM           warp         3.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 556105 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 545.857 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 545.923 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556105
[556105] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.30
    SM Frequency            cycle/usecond       751.60
    Elapsed Cycles                  cycle        3,923
    Memory Throughput                   %         3.52
    DRAM Throughput                     %         0.77
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %         6.81
    L2 Cache Throughput                 %         2.18
    SM Active Cycles                cycle     2,025.37
    Compute (SM) Throughput             %         3.96
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             792
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.84
    Achieved Active Warps Per SM           warp         3.15
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.16%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 556158 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 568.848 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 568.948 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556158
[556158] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       911.92
    Elapsed Cycles                  cycle        3,271
    Memory Throughput                   %         2.53
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         3.81
    L2 Cache Throughput                 %         2.53
    SM Active Cycles                cycle     1,702.13
    Compute (SM) Throughput             %         1.99
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.08
    Achieved Active Warps Per SM           warp         3.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=64
Block size: 1 x 64
==PROF== Connected to process 556207 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 537.082 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 537.133 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556207
[556207] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       924.36
    Elapsed Cycles                  cycle        3,284
    Memory Throughput                   %         2.55
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.55
    L1/TEX Cache Throughput             %         3.74
    L2 Cache Throughput                 %         2.55
    SM Active Cycles                cycle     1,734.77
    Compute (SM) Throughput             %         1.98
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.05
    Achieved Active Warps Per SM           warp         3.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.95%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556249 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87552e-17
GPU Step==nostream 3000, Center temp: 2.26759e-13
GPU Step==nostream 4000, Center temp: 5.82888e-11
GPU Step==nostream 5000, Center temp: 3.17071e-09
GPU Step==nostream 6000, Center temp: 6.61691e-08
GPU Step==nostream 7000, Center temp: 7.26251e-07
GPU Step==nostream 8000, Center temp: 5.05338e-06
GPU Step==nostream 9000, Center temp: 2.51149e-05
GPU: Temperature at center: 9.6495e-05
GPU Execution Time: 534.998 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 535.064 ms
GPU: Temperature at center: 9.6495e-05
==PROF== Disconnected from process 556249
[556249] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       807.44
    Elapsed Cycles                  cycle        4,421
    Memory Throughput                   %         1.92
    DRAM Throughput                     %         0.70
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         3.15
    L2 Cache Throughput                 %         1.92
    SM Active Cycles                cycle     2,498.33
    Compute (SM) Throughput             %         3.38
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.71
    Achieved Active Warps Per SM           warp         4.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 87.29%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (12.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556291 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 535.882 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 535.949 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556291
[556291] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.39
    SM Frequency            cycle/usecond       758.27
    Elapsed Cycles                  cycle        4,256
    Memory Throughput                   %         5.14
    DRAM Throughput                     %         0.72
    Duration                      usecond         5.60
    L1/TEX Cache Throughput             %         9.78
    L2 Cache Throughput                 %         2.61
    SM Active Cycles                cycle     2,232.20
    Compute (SM) Throughput             %         5.14
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.56
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        15.68
    Achieved Active Warps Per SM           warp         5.02
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 84.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (15.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556333 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 592.298 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 592.386 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556333
[556333] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.30
    SM Frequency            cycle/usecond       746.53
    Elapsed Cycles                  cycle        3,872
    Memory Throughput                   %         2.18
    DRAM Throughput                     %         0.80
    Duration                      usecond         5.18
    L1/TEX Cache Throughput             %         4.03
    L2 Cache Throughput                 %         2.18
    SM Active Cycles                cycle     1,963.63
    Compute (SM) Throughput             %         4.15
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.11
    Achieved Active Warps Per SM           warp         4.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 85.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556375 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 526.681 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 526.752 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556375
[556375] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.40
    SM Frequency            cycle/usecond       762.47
    Elapsed Cycles                  cycle        3,954
    Memory Throughput                   %         3.84
    DRAM Throughput                     %         0.78
    Duration                      usecond         5.18
    L1/TEX Cache Throughput             %         7.38
    L2 Cache Throughput                 %         2.16
    SM Active Cycles                cycle     2,055.60
    Compute (SM) Throughput             %         4.93
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.56
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        16.18
    Achieved Active Warps Per SM           warp         5.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.82%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (16.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556430 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74315e-24
GPU Step==nostream 2000, Center temp: 4.87552e-17
GPU Step==nostream 3000, Center temp: 2.26759e-13
GPU Step==nostream 4000, Center temp: 5.82888e-11
GPU Step==nostream 5000, Center temp: 3.17071e-09
GPU Step==nostream 6000, Center temp: 6.61691e-08
GPU Step==nostream 7000, Center temp: 7.26251e-07
GPU Step==nostream 8000, Center temp: 5.05338e-06
GPU Step==nostream 9000, Center temp: 2.5115e-05
GPU: Temperature at center: 9.6495e-05
GPU Execution Time: 586.061 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 586.152 ms
GPU: Temperature at center: 9.6495e-05
==PROF== Disconnected from process 556430
[556430] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       919.48
    Elapsed Cycles                  cycle        3,271
    Memory Throughput                   %         2.54
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.55
    L1/TEX Cache Throughput             %         4.53
    L2 Cache Throughput                 %         2.54
    SM Active Cycles                cycle     1,736.73
    Compute (SM) Throughput             %         2.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.57
    Achieved Active Warps Per SM           warp         4.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 85.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=128
Block size: 1 x 128
==PROF== Connected to process 556480 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74315e-24
GPU Step==nostream 2000, Center temp: 4.87552e-17
GPU Step==nostream 3000, Center temp: 2.26759e-13
GPU Step==nostream 4000, Center temp: 5.82888e-11
GPU Step==nostream 5000, Center temp: 3.17071e-09
GPU Step==nostream 6000, Center temp: 6.61691e-08
GPU Step==nostream 7000, Center temp: 7.26251e-07
GPU Step==nostream 8000, Center temp: 5.05338e-06
GPU Step==nostream 9000, Center temp: 2.5115e-05
GPU: Temperature at center: 9.6495e-05
GPU Execution Time: 571.965 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 572.098 ms
GPU: Temperature at center: 9.6495e-05
==PROF== Disconnected from process 556480
[556480] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       907.55
    Elapsed Cycles                  cycle        3,254
    Memory Throughput                   %         2.57
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         4.47
    L2 Cache Throughput                 %         2.57
    SM Active Cycles                cycle     1,760.80
    Compute (SM) Throughput             %         2.80
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.54
    Achieved Active Warps Per SM           warp         4.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 85.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556523 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 4.58607e-21
GPU Step==nostream 2000, Center temp: 7.42403e-15
GPU Step==nostream 3000, Center temp: 1.57469e-11
GPU Step==nostream 4000, Center temp: 2.34571e-09
GPU Step==nostream 5000, Center temp: 8.45332e-08
GPU Step==nostream 6000, Center temp: 1.27376e-06
GPU Step==nostream 7000, Center temp: 1.07201e-05
GPU Step==nostream 8000, Center temp: 5.97902e-05
GPU Step==nostream 9000, Center temp: 0.000246413
GPU: Temperature at center: 0.000806474
GPU Execution Time: 528.788 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 528.858 ms
GPU: Temperature at center: 0.000806474
==PROF== Disconnected from process 556523
[556523] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.62
    SM Frequency            cycle/usecond       798.26
    Elapsed Cycles                  cycle        4,803
    Memory Throughput                   %         2.21
    DRAM Throughput                     %         0.64
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %         4.10
    L2 Cache Throughput                 %         1.81
    SM Active Cycles                cycle     2,588.53
    Compute (SM) Throughput             %         4.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        18.92
    Achieved Active Warps Per SM           warp         6.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (18.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556565 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 530.438 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 530.518 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 556565
[556565] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.59
    SM Frequency            cycle/usecond       787.19
    Elapsed Cycles                  cycle        4,708
    Memory Throughput                   %         8.09
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %        15.32
    L2 Cache Throughput                 %         3.11
    SM Active Cycles                cycle     2,474.53
    Compute (SM) Throughput             %         8.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.10
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        27.88
    Achieved Active Warps Per SM           warp         8.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 72.12%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556607 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 567.808 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 567.873 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556607
[556607] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.40
    SM Frequency            cycle/usecond       758.56
    Elapsed Cycles                  cycle        3,959
    Memory Throughput                   %         2.70
    DRAM Throughput                     %         0.81
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %         5.29
    L2 Cache Throughput                 %         2.20
    SM Active Cycles                cycle     2,016.20
    Compute (SM) Throughput             %         5.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.98
    Achieved Active Warps Per SM           warp         7.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.02%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (23.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556662 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55383e-05
GPU: Temperature at center: 9.84825e-05
GPU Execution Time: 526.773 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 526.815 ms
GPU: Temperature at center: 9.84825e-05
==PROF== Disconnected from process 556662
[556662] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.52
    SM Frequency            cycle/usecond       781.37
    Elapsed Cycles                  cycle        4,357
    Memory Throughput                   %         4.12
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.57
    L1/TEX Cache Throughput             %         8.16
    L2 Cache Throughput                 %         2.02
    SM Active Cycles                cycle     2,195.63
    Compute (SM) Throughput             %         6.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.10
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        28.11
    Achieved Active Warps Per SM           warp         9.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 71.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (28.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556712 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 4.5829e-21
GPU Step==nostream 2000, Center temp: 7.41767e-15
GPU Step==nostream 3000, Center temp: 1.57349e-11
GPU Step==nostream 4000, Center temp: 2.34423e-09
GPU Step==nostream 5000, Center temp: 8.44893e-08
GPU Step==nostream 6000, Center temp: 1.27322e-06
GPU Step==nostream 7000, Center temp: 1.07163e-05
GPU Step==nostream 8000, Center temp: 5.97731e-05
GPU Step==nostream 9000, Center temp: 0.000246355
GPU: Temperature at center: 0.000806313
GPU Execution Time: 548.933 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 549.03 ms
GPU: Temperature at center: 0.000806313
==PROF== Disconnected from process 556712
[556712] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       909.78
    Elapsed Cycles                  cycle        3,263
    Memory Throughput                   %         3.25
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         5.66
    L2 Cache Throughput                 %         2.63
    SM Active Cycles                cycle     1,876.43
    Compute (SM) Throughput             %         4.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        23.12
    Achieved Active Warps Per SM           warp         7.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 76.88%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (23.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=256
Block size: 1 x 256
==PROF== Connected to process 556754 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 4.5829e-21
GPU Step==nostream 2000, Center temp: 7.41767e-15
GPU Step==nostream 3000, Center temp: 1.57349e-11
GPU Step==nostream 4000, Center temp: 2.34423e-09
GPU Step==nostream 5000, Center temp: 8.44893e-08
GPU Step==nostream 6000, Center temp: 1.27322e-06
GPU Step==nostream 7000, Center temp: 1.07163e-05
GPU Step==nostream 8000, Center temp: 5.97731e-05
GPU Step==nostream 9000, Center temp: 0.000246355
GPU: Temperature at center: 0.000806313
GPU Execution Time: 535.549 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 535.625 ms
GPU: Temperature at center: 0.000806313
==PROF== Disconnected from process 556754
[556754] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.49
    SM Frequency            cycle/usecond       920.98
    Elapsed Cycles                  cycle        3,272
    Memory Throughput                   %         3.24
    DRAM Throughput                     %         1.01
    Duration                      usecond         3.55
    L1/TEX Cache Throughput             %         5.96
    L2 Cache Throughput                 %         2.63
    SM Active Cycles                cycle     1,781.27
    Compute (SM) Throughput             %         4.41
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        23.86
    Achieved Active Warps Per SM           warp         7.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 76.14%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (23.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 556796 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 2.07926e-14
GPU Step==nostream 2000, Center temp: 1.05862e-09
GPU Step==nostream 3000, Center temp: 3.13056e-07
GPU Step==nostream 4000, Center temp: 1.20099e-05
GPU Step==nostream 5000, Center temp: 0.000156654
GPU Step==nostream 6000, Center temp: 0.0010622
GPU Step==nostream 7000, Center temp: 0.00468033
GPU Step==nostream 8000, Center temp: 0.0152734
GPU Step==nostream 9000, Center temp: 0.040083
GPU: Temperature at center: 0.08929
GPU Execution Time: 560.674 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 560.718 ms
GPU: Temperature at center: 0.08929
==PROF== Disconnected from process 556796
[556796] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       809.83
    Elapsed Cycles                  cycle        4,951
    Memory Throughput                   %         3.25
    DRAM Throughput                     %         0.64
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         5.84
    L2 Cache Throughput                 %         1.86
    SM Active Cycles                cycle     2,756.57
    Compute (SM) Throughput             %         6.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        31.48
    Achieved Active Warps Per SM           warp        10.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.52%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (31.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 556838 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18296e-09
GPU Step==nostream 6000, Center temp: 6.66042e-08
GPU Step==nostream 7000, Center temp: 7.33367e-07
GPU Step==nostream 8000, Center temp: 5.12109e-06
GPU Step==nostream 9000, Center temp: 2.55491e-05
GPU: Temperature at center: 9.85596e-05
GPU Execution Time: 535.474 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 535.517 ms
GPU: Temperature at center: 9.85596e-05
==PROF== Disconnected from process 556838
[556838] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.83
    SM Frequency            cycle/usecond       815.60
    Elapsed Cycles                  cycle        5,116
    Memory Throughput                   %        13.77
    DRAM Throughput                     %         0.69
    Duration                      usecond         6.24
    L1/TEX Cache Throughput             %        23.81
    L2 Cache Throughput                 %         4.37
    SM Active Cycles                cycle     2,942.73
    Compute (SM) Throughput             %        13.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.17
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        52.79
    Achieved Active Warps Per SM           warp        16.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 47.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (52.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 556884 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 529.688 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 529.731 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 556884
[556884] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.24
    SM Frequency            cycle/usecond       740.20
    Elapsed Cycles                  cycle        4,009
    Memory Throughput                   %         4.04
    DRAM Throughput                     %         0.77
    Duration                      usecond         5.41
    L1/TEX Cache Throughput             %         7.74
    L2 Cache Throughput                 %         2.29
    SM Active Cycles                cycle     2,088.47
    Compute (SM) Throughput             %         8.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.70
    Achieved Active Warps Per SM           warp        13.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.3%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 556934 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66028e-08
GPU Step==nostream 7000, Center temp: 7.33317e-07
GPU Step==nostream 8000, Center temp: 5.12021e-06
GPU Step==nostream 9000, Center temp: 2.55399e-05
GPU: Temperature at center: 9.84949e-05
GPU Execution Time: 528.753 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 528.822 ms
GPU: Temperature at center: 9.84949e-05
==PROF== Disconnected from process 556934
[556934] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       804.78
    Elapsed Cycles                  cycle        4,606
    Memory Throughput                   %         5.11
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.70
    L1/TEX Cache Throughput             %         9.76
    L2 Cache Throughput                 %         2.00
    SM Active Cycles                cycle     2,399.23
    Compute (SM) Throughput             %         9.91
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.17
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        51.58
    Achieved Active Warps Per SM           warp        16.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (51.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 556983 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 5.22532e-17
GPU Step==nostream 2000, Center temp: 1.05968e-11
GPU Step==nostream 3000, Center temp: 6.86331e-09
GPU Step==nostream 4000, Center temp: 4.50829e-07
GPU Step==nostream 5000, Center temp: 8.78322e-06
GPU Step==nostream 6000, Center temp: 8.15131e-05
GPU Step==nostream 7000, Center temp: 0.000462669
GPU Step==nostream 8000, Center temp: 0.00186048
GPU Step==nostream 9000, Center temp: 0.00581715
GPU: Temperature at center: 0.0150366
GPU Execution Time: 539.249 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 539.289 ms
GPU: Temperature at center: 0.0150366
==PROF== Disconnected from process 556983
[556983] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       925.56
    Elapsed Cycles                  cycle        3,436
    Memory Throughput                   %         4.69
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.71
    L1/TEX Cache Throughput             %         8.74
    L2 Cache Throughput                 %         2.62
    SM Active Cycles                cycle     1,843.20
    Compute (SM) Throughput             %         7.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.25
    Achieved Active Warps Per SM           warp        13.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=512
Block size: 1 x 512
==PROF== Connected to process 557025 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 8.01874e-16
GPU Step==nostream 2000, Center temp: 7.81468e-11
GPU Step==nostream 3000, Center temp: 3.30605e-08
GPU Step==nostream 4000, Center temp: 1.61037e-06
GPU Step==nostream 5000, Center temp: 2.50772e-05
GPU Step==nostream 6000, Center temp: 0.000195666
GPU Step==nostream 7000, Center temp: 0.000968325
GPU Step==nostream 8000, Center temp: 0.00348859
GPU Step==nostream 9000, Center temp: 0.00997815
GPU: Temperature at center: 0.0239807
GPU Execution Time: 524.033 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 524.099 ms
GPU: Temperature at center: 0.0239807
==PROF== Disconnected from process 557025
[557025] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.69
    SM Frequency            cycle/usecond       939.88
    Elapsed Cycles                  cycle        3,433
    Memory Throughput                   %         4.70
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %         8.75
    L2 Cache Throughput                 %         2.60
    SM Active Cycles                cycle     1,841.13
    Compute (SM) Throughput             %         7.33
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.40
    Achieved Active Warps Per SM           warp        13.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.6%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557067 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 568.819 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 568.89 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557067
[557067] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.96
    SM Frequency            cycle/usecond       844.34
    Elapsed Cycles                  cycle        6,192
    Memory Throughput                   %         4.38
    DRAM Throughput                     %         0.49
    Duration                      usecond         7.33
    L1/TEX Cache Throughput             %         7.42
    L2 Cache Throughput                 %         1.65
    SM Active Cycles                cycle     3,650.17
    Compute (SM) Throughput             %         7.94
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 67.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        32.87
    Achieved Active Warps Per SM           warp        10.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.13%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (32.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557109 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83973e-11
GPU Step==nostream 5000, Center temp: 3.18358e-09
GPU Step==nostream 6000, Center temp: 6.66448e-08
GPU Step==nostream 7000, Center temp: 7.34352e-07
GPU Step==nostream 8000, Center temp: 5.1333e-06
GPU Step==nostream 9000, Center temp: 2.56427e-05
GPU: Temperature at center: 9.90613e-05
GPU Execution Time: 536.665 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 536.724 ms
GPU: Temperature at center: 9.90613e-05
==PROF== Disconnected from process 557109
[557109] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.92
    SM Frequency            cycle/usecond       830.14
    Elapsed Cycles                  cycle        6,546
    Memory Throughput                   %        20.65
    DRAM Throughput                     %         0.47
    Duration                      usecond         7.84
    L1/TEX Cache Throughput             %        32.12
    L2 Cache Throughput                 %         5.67
    SM Active Cycles                cycle     4,184.63
    Compute (SM) Throughput             %        20.65
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block           12.31
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 35.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        64.92
    Achieved Active Warps Per SM           warp        20.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 35.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (64.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557164 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 570.877 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 570.939 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557164
[557164] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       822.54
    Elapsed Cycles                  cycle        5,121
    Memory Throughput                   %         5.32
    DRAM Throughput                     %         0.59
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %         9.16
    L2 Cache Throughput                 %         2.00
    SM Active Cycles                cycle     2,964.17
    Compute (SM) Throughput             %        11.48
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 56.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.59
    Achieved Active Warps Per SM           warp        13.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.41%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557214 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18295e-09
GPU Step==nostream 6000, Center temp: 6.66034e-08
GPU Step==nostream 7000, Center temp: 7.33339e-07
GPU Step==nostream 8000, Center temp: 5.12055e-06
GPU Step==nostream 9000, Center temp: 2.55431e-05
GPU: Temperature at center: 9.85148e-05
GPU Execution Time: 524.178 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 524.223 ms
GPU: Temperature at center: 9.85148e-05
==PROF== Disconnected from process 557214
[557214] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.89
    SM Frequency            cycle/usecond       830.29
    Elapsed Cycles                  cycle        5,651
    Memory Throughput                   %         6.11
    DRAM Throughput                     %         0.54
    Duration                      usecond         6.78
    L1/TEX Cache Throughput             %         9.87
    L2 Cache Throughput                 %         1.82
    SM Active Cycles                cycle     3,484.07
    Compute (SM) Throughput             %        13.34
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block           12.31
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 40.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        59.75
    Achieved Active Warps Per SM           warp        19.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.25%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (59.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557256 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.472 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 547.519 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557256
[557256] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.60
    SM Frequency            cycle/usecond       932.81
    Elapsed Cycles                  cycle        4,779
    Memory Throughput                   %         5.67
    DRAM Throughput                     %         0.64
    Duration                      usecond         5.12
    L1/TEX Cache Throughput             %        10.09
    L2 Cache Throughput                 %         2.12
    SM Active Cycles                cycle     2,684.77
    Compute (SM) Throughput             %         9.06
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 55.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        44.47
    Achieved Active Warps Per SM           warp        14.23
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 55.53%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (44.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1, y=1024
Block size: 1 x 1024
==PROF== Connected to process 557298 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1x1024
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 536.579 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 536.656 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557298
[557298] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (50, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       926.44
    Elapsed Cycles                  cycle        4,786
    Memory Throughput                   %         5.68
    DRAM Throughput                     %         0.64
    Duration                      usecond         5.15
    L1/TEX Cache Throughput             %        10.33
    L2 Cache Throughput                 %         2.11
    SM Active Cycles                cycle     2,623.13
    Compute (SM) Throughput             %         9.07
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 56.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.23
    Achieved Active Warps Per SM           warp        13.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.77%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557340 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.007 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 546.054 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557340
[557340] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.22
    SM Frequency            cycle/usecond       872.11
    Elapsed Cycles                  cycle        7,059
    Memory Throughput                   %         9.43
    DRAM Throughput                     %         0.42
    Duration                      usecond         8.06
    L1/TEX Cache Throughput             %        13.52
    L2 Cache Throughput                 %         5.85
    SM Active Cycles                cycle     4,904.53
    Compute (SM) Throughput             %        20.74
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 27.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        36.49
    Achieved Active Warps Per SM           warp        11.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 27.02%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (36.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557395 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 542.396 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 542.446 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557395
[557395] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.11
    SM Frequency            cycle/usecond       855.88
    Elapsed Cycles                  cycle        7,388
    Memory Throughput                   %        21.48
    DRAM Throughput                     %         0.40
    Duration                      usecond         8.58
    L1/TEX Cache Throughput             %        29.05
    L2 Cache Throughput                 %         5.77
    SM Active Cycles                cycle     5,427.40
    Compute (SM) Throughput             %        25.19
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              48
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 25.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        37.37
    Achieved Active Warps Per SM           warp        11.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.25%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (37.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557445 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 534.7 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 534.747 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557445
[557445] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.23
    SM Frequency            cycle/usecond       875.12
    Elapsed Cycles                  cycle        7,193
    Memory Throughput                   %         9.29
    DRAM Throughput                     %         0.42
    Duration                      usecond         8.16
    L1/TEX Cache Throughput             %        12.73
    L2 Cache Throughput                 %         5.88
    SM Active Cycles                cycle     5,209.40
    Compute (SM) Throughput             %        19.66
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 34.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        32.75
    Achieved Active Warps Per SM           warp        10.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 34.51%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (32.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557501 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 562.988 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 563.036 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557501
[557501] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       891.62
    Elapsed Cycles                  cycle        7,818
    Memory Throughput                   %        20.31
    DRAM Throughput                     %         0.38
    Duration                      usecond         8.70
    L1/TEX Cache Throughput             %        28.51
    L2 Cache Throughput                 %         5.38
    SM Active Cycles                cycle     5,529.50
    Compute (SM) Throughput             %        21.95
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              48
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 30.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        34.96
    Achieved Active Warps Per SM           warp        11.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 30.09%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (35.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557545 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 565.855 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 565.9 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557545
[557545] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.88
    SM Frequency            cycle/usecond       966.20
    Elapsed Cycles                  cycle        6,091
    Memory Throughput                   %        10.94
    DRAM Throughput                     %         0.49
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %        17.14
    L2 Cache Throughput                 %         6.87
    SM Active Cycles                cycle     3,868.33
    Compute (SM) Throughput             %        11.04
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 38.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.63
    Achieved Active Warps Per SM           warp         9.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=1
Block size: 2 x 1
==PROF== Connected to process 557587 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 530.851 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 530.896 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557587
[557587] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 50, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.85
    SM Frequency            cycle/usecond       961.82
    Elapsed Cycles                  cycle        6,089
    Memory Throughput                   %        10.94
    DRAM Throughput                     %         0.49
    Duration                      usecond         6.30
    L1/TEX Cache Throughput             %        17.42
    L2 Cache Throughput                 %         6.82
    SM Active Cycles                cycle     3,807.07
    Compute (SM) Throughput             %        11.03
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,250
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                2.60
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 33.33%                                                                                          
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 289 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 39.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.46
    Achieved Active Warps Per SM           warp         9.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 39.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557639 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 573.628 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 573.677 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557639
[557639] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.41
    SM Frequency            cycle/usecond       903.07
    Elapsed Cycles                  cycle        5,603
    Memory Throughput                   %         6.18
    DRAM Throughput                     %         0.54
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        10.13
    L2 Cache Throughput                 %         4.32
    SM Active Cycles                cycle     3,402.83
    Compute (SM) Throughput             %        13.75
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 36.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        31.89
    Achieved Active Warps Per SM           warp        10.21
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 36.21%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557686 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 550.365 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 550.439 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557686
[557686] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.17
    SM Frequency            cycle/usecond       864.43
    Elapsed Cycles                  cycle        5,669
    Memory Throughput                   %        14.23
    DRAM Throughput                     %         0.53
    Duration                      usecond         6.53
    L1/TEX Cache Throughput             %        21.83
    L2 Cache Throughput                 %         4.43
    SM Active Cycles                cycle     3,678.43
    Compute (SM) Throughput             %        17.09
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 33.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        33.22
    Achieved Active Warps Per SM           warp        10.63
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 33.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557728 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.633 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 539.673 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557728
[557728] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       912.37
    Elapsed Cycles                  cycle        5,682
    Memory Throughput                   %         6.09
    DRAM Throughput                     %         0.53
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %         9.72
    L2 Cache Throughput                 %         4.31
    SM Active Cycles                cycle     3,550.30
    Compute (SM) Throughput             %        13.08
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 41.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.12
    Achieved Active Warps Per SM           warp         9.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557770 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 530.132 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 530.177 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557770
[557770] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.04
    SM Frequency            cycle/usecond       847.24
    Elapsed Cycles                  cycle        5,943
    Memory Throughput                   %        13.59
    DRAM Throughput                     %         0.50
    Duration                      usecond         6.98
    L1/TEX Cache Throughput             %        21.08
    L2 Cache Throughput                 %         4.15
    SM Active Cycles                cycle     3,809.43
    Compute (SM) Throughput             %        15.02
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 39.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.12
    Achieved Active Warps Per SM           warp         9.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 39.76%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557813 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3524.12 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3524.15 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557813
[557813] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       923.74
    Elapsed Cycles                  cycle        4,709
    Memory Throughput                   %         7.33
    DRAM Throughput                     %         0.64
    Duration                      usecond         5.09
    L1/TEX Cache Throughput             %        12.49
    L2 Cache Throughput                 %         5.13
    SM Active Cycles                cycle     2,759.60
    Compute (SM) Throughput             %         7.56
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 44.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.01
    Achieved Active Warps Per SM           warp         8.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 43.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=2
Block size: 2 x 2
==PROF== Connected to process 557888 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 535.62 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 535.684 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557888
[557888] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 25, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       926.44
    Elapsed Cycles                  cycle        4,783
    Memory Throughput                   %         7.22
    DRAM Throughput                     %         0.62
    Duration                      usecond         5.15
    L1/TEX Cache Throughput             %        12.47
    L2 Cache Throughput                 %         5.09
    SM Active Cycles                cycle     2,764.17
    Compute (SM) Throughput             %         7.45
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    625
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,500
    Waves Per SM                                                1.30
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 144 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 44.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.95
    Achieved Active Warps Per SM           warp         8.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.1%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 557930 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3549.56 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 3549.61 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 557930
[557930] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.82
    SM Frequency            cycle/usecond       821.21
    Elapsed Cycles                  cycle        4,346
    Memory Throughput                   %         4.21
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.28
    L1/TEX Cache Throughput             %         7.35
    L2 Cache Throughput                 %         3.53
    SM Active Cycles                cycle     2,479.47
    Compute (SM) Throughput             %         9.39
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.94
    Achieved Active Warps Per SM           warp         8.30
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.12%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 558020 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 532.111 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 532.159 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 558020
[558020] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.84
    SM Frequency            cycle/usecond       821.57
    Elapsed Cycles                  cycle        4,486
    Memory Throughput                   %         9.41
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.44
    L1/TEX Cache Throughput             %        16.51
    L2 Cache Throughput                 %         3.58
    SM Active Cycles                cycle     2,547.50
    Compute (SM) Throughput             %        11.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.51
    Achieved Active Warps Per SM           warp         8.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 558062 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.607 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 546.673 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 558062
[558062] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.52
    SM Frequency            cycle/usecond       771.08
    Elapsed Cycles                  cycle        4,231
    Memory Throughput                   %         4.33
    DRAM Throughput                     %         0.70
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         8.11
    L2 Cache Throughput                 %         3.67
    SM Active Cycles                cycle     2,250.93
    Compute (SM) Throughput             %         9.42
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.77
    Achieved Active Warps Per SM           warp         8.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.47%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (27.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 558104 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 536.73 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 536.81 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 558104
[558104] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       795.10
    Elapsed Cycles                  cycle        4,263
    Memory Throughput                   %         9.90
    DRAM Throughput                     %         0.70
    Duration                      usecond         5.34
    L1/TEX Cache Throughput             %        17.76
    L2 Cache Throughput                 %         3.66
    SM Active Cycles                cycle     2,369.23
    Compute (SM) Throughput             %        11.16
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.06
    Achieved Active Warps Per SM           warp         8.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 43.88%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 558167 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3561.73 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3561.81 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 558167
[558167] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       917.37
    Elapsed Cycles                  cycle        3,496
    Memory Throughput                   %         5.22
    DRAM Throughput                     %         0.86
    Duration                      usecond         3.81
    L1/TEX Cache Throughput             %        10.74
    L2 Cache Throughput                 %         4.33
    SM Active Cycles                cycle     1,697.60
    Compute (SM) Throughput             %         5.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.85
    Achieved Active Warps Per SM           warp         8.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (27.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=4
Block size: 2 x 4
==PROF== Connected to process 558218 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 573.64 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 573.725 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 558218
[558218] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 13, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.60
    SM Frequency            cycle/usecond       921.96
    Elapsed Cycles                  cycle        3,484
    Memory Throughput                   %         5.24
    DRAM Throughput                     %         0.85
    Duration                      usecond         3.78
    L1/TEX Cache Throughput             %        10.80
    L2 Cache Throughput                 %         4.36
    SM Active Cycles                cycle     1,688.10
    Compute (SM) Throughput             %         5.52
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.99
    Achieved Active Warps Per SM           warp         8.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.02%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558273 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 569.69 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 569.732 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 558273
[558273] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.58
    SM Frequency            cycle/usecond       786.06
    Elapsed Cycles                  cycle        4,303
    Memory Throughput                   %         2.43
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         4.41
    L2 Cache Throughput                 %         2.43
    SM Active Cycles                cycle     2,292.40
    Compute (SM) Throughput             %         5.17
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.07
    Achieved Active Warps Per SM           warp         4.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.87%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558331 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 566.861 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 566.914 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 558331
[558331] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       802.59
    Elapsed Cycles                  cycle        4,266
    Memory Throughput                   %         5.38
    DRAM Throughput                     %         0.70
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %        10.07
    L2 Cache Throughput                 %         2.64
    SM Active Cycles                cycle     2,279.63
    Compute (SM) Throughput             %         6.55
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             160
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.36
    Achieved Active Warps Per SM           warp         4.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.28%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558373 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 541.233 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 541.28 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 558373
[558373] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.37
    SM Frequency            cycle/usecond       758.09
    Elapsed Cycles                  cycle        4,033
    Memory Throughput                   %         2.62
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %         4.76
    L2 Cache Throughput                 %         2.62
    SM Active Cycles                cycle     2,131.70
    Compute (SM) Throughput             %         5.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.51
    Achieved Active Warps Per SM           warp         4.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.98%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558415 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 554.885 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 554.974 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 558415
[558415] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       797.64
    Elapsed Cycles                  cycle        4,194
    Memory Throughput                   %         5.48
    DRAM Throughput                     %         0.71
    Duration                      usecond         5.25
    L1/TEX Cache Throughput             %        10.79
    L2 Cache Throughput                 %         2.54
    SM Active Cycles                cycle     2,126.40
    Compute (SM) Throughput             %         6.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             160
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.79
    Achieved Active Warps Per SM           warp         5.05
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.43%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558457 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 543.931 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 543.976 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 558457
[558457] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       916.12
    Elapsed Cycles                  cycle        3,382
    Memory Throughput                   %         3.08
    DRAM Throughput                     %         0.88
    Duration                      usecond         3.68
    L1/TEX Cache Throughput             %         6.18
    L2 Cache Throughput                 %         3.08
    SM Active Cycles                cycle     1,636.93
    Compute (SM) Throughput             %         3.15
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.46
    Achieved Active Warps Per SM           warp         4.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.08%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=8
Block size: 2 x 8
==PROF== Connected to process 558512 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 539.553 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 539.599 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 558512
[558512] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 7, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.35
    SM Frequency            cycle/usecond       893.93
    Elapsed Cycles                  cycle        3,291
    Memory Throughput                   %         3.12
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.68
    L1/TEX Cache Throughput             %         6.19
    L2 Cache Throughput                 %         3.12
    SM Active Cycles                cycle     1,634.80
    Compute (SM) Throughput             %         3.23
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.48
    Achieved Active Warps Per SM           warp         4.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.05%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558562 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 571.413 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 571.454 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558562
[558562] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.55
    SM Frequency            cycle/usecond       782.36
    Elapsed Cycles                  cycle        4,232
    Memory Throughput                   %         2.08
    DRAM Throughput                     %         0.71
    Duration                      usecond         5.41
    L1/TEX Cache Throughput             %         2.72
    L2 Cache Throughput                 %         2.08
    SM Active Cycles                cycle     2,225.27
    Compute (SM) Throughput             %         3.05
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.98
    Achieved Active Warps Per SM           warp         2.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.03%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.0%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558604 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 569.593 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 569.634 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558604
[558604] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.49
    SM Frequency            cycle/usecond       774.58
    Elapsed Cycles                  cycle        4,141
    Memory Throughput                   %         3.23
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.34
    L1/TEX Cache Throughput             %         6.15
    L2 Cache Throughput                 %         2.21
    SM Active Cycles                cycle     2,178.43
    Compute (SM) Throughput             %         3.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             288
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.20
    Achieved Active Warps Per SM           warp         2.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.61%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.2%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558646 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 544.766 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 544.832 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 558646
[558646] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.30
    SM Frequency            cycle/usecond       746.55
    Elapsed Cycles                  cycle        4,038
    Memory Throughput                   %         2.15
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.41
    L1/TEX Cache Throughput             %         2.93
    L2 Cache Throughput                 %         2.15
    SM Active Cycles                cycle     2,072.47
    Compute (SM) Throughput             %         3.22
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.26
    Achieved Active Warps Per SM           warp         2.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.49%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558688 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84101e-11
GPU Step==nostream 5000, Center temp: 3.18549e-09
GPU Step==nostream 6000, Center temp: 6.67224e-08
GPU Step==nostream 7000, Center temp: 7.35694e-07
GPU Step==nostream 8000, Center temp: 5.14615e-06
GPU Step==nostream 9000, Center temp: 2.57225e-05
GPU: Temperature at center: 9.94174e-05
GPU Execution Time: 547.308 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 547.36 ms
GPU: Temperature at center: 9.94174e-05
==PROF== Disconnected from process 558688
[558688] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.53
    SM Frequency            cycle/usecond       781.44
    Elapsed Cycles                  cycle        4,135
    Memory Throughput                   %         3.24
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.28
    L1/TEX Cache Throughput             %         6.45
    L2 Cache Throughput                 %         2.13
    SM Active Cycles                cycle     2,075.13
    Compute (SM) Throughput             %         3.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             288
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.40
    Achieved Active Warps Per SM           warp         3.01
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.2%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.4%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558734 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 530.678 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 530.724 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558734
[558734] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       921.88
    Elapsed Cycles                  cycle        3,363
    Memory Throughput                   %         2.57
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %         3.76
    L2 Cache Throughput                 %         2.57
    SM Active Cycles                cycle     1,608.30
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.28
    Achieved Active Warps Per SM           warp         2.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=16
Block size: 2 x 16
==PROF== Connected to process 558783 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 557.653 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 557.695 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558783
[558783] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 4, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       910.56
    Elapsed Cycles                  cycle        3,382
    Memory Throughput                   %         2.55
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.71
    L1/TEX Cache Throughput             %         3.73
    L2 Cache Throughput                 %         2.55
    SM Active Cycles                cycle     1,622.10
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.28
    Achieved Active Warps Per SM           warp         2.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.45%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 558831 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 562.672 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 562.721 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558831
[558831] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       807.64
    Elapsed Cycles                  cycle        4,214
    Memory Throughput                   %         1.90
    DRAM Throughput                     %         0.72
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %         2.93
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle     2,066.83
    Compute (SM) Throughput             %         3.06
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.58
    Achieved Active Warps Per SM           warp         3.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 558873 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 553.897 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 553.937 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 558873
[558873] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       788.62
    Elapsed Cycles                  cycle        4,139
    Memory Throughput                   %         3.23
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.25
    L1/TEX Cache Throughput             %         6.44
    L2 Cache Throughput                 %         2.03
    SM Active Cycles                cycle     2,077.47
    Compute (SM) Throughput             %         3.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             544
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.79
    Achieved Active Warps Per SM           warp         3.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 558915 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 556.178 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 556.223 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 558915
[558915] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.27
    SM Frequency            cycle/usecond       741.76
    Elapsed Cycles                  cycle        4,083
    Memory Throughput                   %         1.95
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.50
    L1/TEX Cache Throughput             %         3.13
    L2 Cache Throughput                 %         1.95
    SM Active Cycles                cycle     1,944.60
    Compute (SM) Throughput             %         3.18
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.78
    Achieved Active Warps Per SM           warp         3.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 558957 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84101e-11
GPU Step==nostream 5000, Center temp: 3.18549e-09
GPU Step==nostream 6000, Center temp: 6.67224e-08
GPU Step==nostream 7000, Center temp: 7.35694e-07
GPU Step==nostream 8000, Center temp: 5.14615e-06
GPU Step==nostream 9000, Center temp: 2.57225e-05
GPU: Temperature at center: 9.94174e-05
GPU Execution Time: 549.613 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 549.671 ms
GPU: Temperature at center: 9.94174e-05
==PROF== Disconnected from process 558957
[558957] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       785.83
    Elapsed Cycles                  cycle        4,176
    Memory Throughput                   %         3.21
    DRAM Throughput                     %         0.72
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %         6.63
    L2 Cache Throughput                 %         1.93
    SM Active Cycles                cycle     2,020.30
    Compute (SM) Throughput             %         3.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             544
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.81
    Achieved Active Warps Per SM           warp         3.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 559012 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 563.358 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 563.415 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559012
[559012] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       910.64
    Elapsed Cycles                  cycle        3,324
    Memory Throughput                   %         2.40
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %         3.97
    L2 Cache Throughput                 %         2.40
    SM Active Cycles                cycle     1,524.13
    Compute (SM) Throughput             %         1.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.58
    Achieved Active Warps Per SM           warp         3.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=32
Block size: 2 x 32
==PROF== Connected to process 559062 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 682.724 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 682.784 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559062
[559062] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 2, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.51
    SM Frequency            cycle/usecond       924.23
    Elapsed Cycles                  cycle        3,343
    Memory Throughput                   %         2.41
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.62
    L1/TEX Cache Throughput             %         3.99
    L2 Cache Throughput                 %         2.41
    SM Active Cycles                cycle     1,517.43
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.57
    Achieved Active Warps Per SM           warp         3.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559104 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26901e-13
GPU Step==nostream 4000, Center temp: 5.84091e-11
GPU Step==nostream 5000, Center temp: 3.18522e-09
GPU Step==nostream 6000, Center temp: 6.67039e-08
GPU Step==nostream 7000, Center temp: 7.3522e-07
GPU Step==nostream 8000, Center temp: 5.13987e-06
GPU Step==nostream 9000, Center temp: 2.5671e-05
GPU: Temperature at center: 9.91224e-05
GPU Execution Time: 541.777 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 541.836 ms
GPU: Temperature at center: 9.91224e-05
==PROF== Disconnected from process 559104
[559104] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.59
    SM Frequency            cycle/usecond       794.08
    Elapsed Cycles                  cycle        4,170
    Memory Throughput                   %         1.64
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.25
    L1/TEX Cache Throughput             %         3.52
    L2 Cache Throughput                 %         1.64
    SM Active Cycles                cycle     1,718.83
    Compute (SM) Throughput             %         3.10
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.51
    Achieved Active Warps Per SM           warp         3.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.49%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559146 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 534.638 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 534.687 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559146
[559146] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.49
    SM Frequency            cycle/usecond       771.08
    Elapsed Cycles                  cycle        4,125
    Memory Throughput                   %         3.25
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.34
    L1/TEX Cache Throughput             %         7.84
    L2 Cache Throughput                 %         1.72
    SM Active Cycles                cycle     1,706.90
    Compute (SM) Throughput             %         3.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.06
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           25
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.07
    Achieved Active Warps Per SM           warp         3.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 87.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (12.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559188 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 585.549 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 585.595 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 559188
[559188] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.37
    SM Frequency            cycle/usecond       757.30
    Elapsed Cycles                  cycle        4,049
    Memory Throughput                   %         1.66
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.34
    L1/TEX Cache Throughput             %         3.82
    L2 Cache Throughput                 %         1.66
    SM Active Cycles                cycle     1,590.07
    Compute (SM) Throughput             %         3.21
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.93
    Achieved Active Warps Per SM           warp         3.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559243 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84101e-11
GPU Step==nostream 5000, Center temp: 3.18549e-09
GPU Step==nostream 6000, Center temp: 6.67224e-08
GPU Step==nostream 7000, Center temp: 7.35694e-07
GPU Step==nostream 8000, Center temp: 5.14615e-06
GPU Step==nostream 9000, Center temp: 2.57225e-05
GPU: Temperature at center: 9.94174e-05
GPU Execution Time: 538.592 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 538.639 ms
GPU: Temperature at center: 9.94174e-05
==PROF== Disconnected from process 559243
[559243] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.52
    SM Frequency            cycle/usecond       778.15
    Elapsed Cycles                  cycle        4,191
    Memory Throughput                   %         3.20
    DRAM Throughput                     %         0.72
    Duration                      usecond         5.38
    L1/TEX Cache Throughput             %         7.95
    L2 Cache Throughput                 %         1.61
    SM Active Cycles                cycle     1,684.33
    Compute (SM) Throughput             %         3.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.06
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           25
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.94
    Achieved Active Warps Per SM           warp         3.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559293 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 553.536 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 553.581 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559293
[559293] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.29
    SM Frequency            cycle/usecond       894.94
    Elapsed Cycles                  cycle        3,353
    Memory Throughput                   %         2.03
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         4.67
    L2 Cache Throughput                 %         2.03
    SM Active Cycles                cycle        1,295
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.31
    Achieved Active Warps Per SM           warp         3.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.69%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=64
Block size: 2 x 64
==PROF== Connected to process 559335 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 545.41 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 545.453 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559335
[559335] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       922.74
    Elapsed Cycles                  cycle        3,397
    Memory Throughput                   %         2.00
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.68
    L1/TEX Cache Throughput             %         4.67
    L2 Cache Throughput                 %         2.00
    SM Active Cycles                cycle     1,295.73
    Compute (SM) Throughput             %         1.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.35
    Achieved Active Warps Per SM           warp         3.63
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.65%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559377 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26901e-13
GPU Step==nostream 4000, Center temp: 5.84091e-11
GPU Step==nostream 5000, Center temp: 3.18522e-09
GPU Step==nostream 6000, Center temp: 6.67039e-08
GPU Step==nostream 7000, Center temp: 7.3522e-07
GPU Step==nostream 8000, Center temp: 5.13987e-06
GPU Step==nostream 9000, Center temp: 2.5671e-05
GPU: Temperature at center: 9.91224e-05
GPU Execution Time: 547.967 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 548.01 ms
GPU: Temperature at center: 9.91224e-05
==PROF== Disconnected from process 559377
[559377] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       798.70
    Elapsed Cycles                  cycle        4,174
    Memory Throughput                   %         1.79
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %         4.30
    L2 Cache Throughput                 %         1.68
    SM Active Cycles                cycle     1,735.97
    Compute (SM) Throughput             %         3.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        16.16
    Achieved Active Warps Per SM           warp         5.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.84%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (16.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559419 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 571.006 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 571.058 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559419
[559419] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.43
    SM Frequency            cycle/usecond       770.71
    Elapsed Cycles                  cycle        4,224
    Memory Throughput                   %         5.09
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %        12.08
    L2 Cache Throughput                 %         1.91
    SM Active Cycles                cycle     1,777.07
    Compute (SM) Throughput             %         5.22
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.08
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           14
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.92
    Achieved Active Warps Per SM           warp         6.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559474 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 586.713 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 586.757 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 559474
[559474] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.33
    SM Frequency            cycle/usecond       755.83
    Elapsed Cycles                  cycle        4,066
    Memory Throughput                   %         1.84
    DRAM Throughput                     %         0.76
    Duration                      usecond         5.38
    L1/TEX Cache Throughput             %         4.69
    L2 Cache Throughput                 %         1.67
    SM Active Cycles                cycle     1,599.13
    Compute (SM) Throughput             %         4.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        17.32
    Achieved Active Warps Per SM           warp         5.54
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.68%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (17.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559525 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84105e-11
GPU Step==nostream 5000, Center temp: 3.18558e-09
GPU Step==nostream 6000, Center temp: 6.67268e-08
GPU Step==nostream 7000, Center temp: 7.35787e-07
GPU Step==nostream 8000, Center temp: 5.14716e-06
GPU Step==nostream 9000, Center temp: 2.57295e-05
GPU: Temperature at center: 9.94514e-05
GPU Execution Time: 555.909 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 555.958 ms
GPU: Temperature at center: 9.94514e-05
==PROF== Disconnected from process 559525
[559525] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.53
    SM Frequency            cycle/usecond       777.80
    Elapsed Cycles                  cycle        4,142
    Memory Throughput                   %         3.58
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.31
    L1/TEX Cache Throughput             %         8.66
    L2 Cache Throughput                 %         1.71
    SM Active Cycles                cycle     1,709.93
    Compute (SM) Throughput             %         4.73
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.08
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           14
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.76
    Achieved Active Warps Per SM           warp         6.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559567 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 639.465 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 639.509 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559567
[559567] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.45
    SM Frequency            cycle/usecond       914.68
    Elapsed Cycles                  cycle        3,220
    Memory Throughput                   %         2.32
    DRAM Throughput                     %         0.96
    Duration                      usecond         3.52
    L1/TEX Cache Throughput             %         5.75
    L2 Cache Throughput                 %         2.16
    SM Active Cycles                cycle     1,298.93
    Compute (SM) Throughput             %         2.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        17.50
    Achieved Active Warps Per SM           warp         5.60
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (17.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=128
Block size: 2 x 128
==PROF== Connected to process 559609 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 617.417 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 617.467 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559609
[559609] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       886.06
    Elapsed Cycles                  cycle        3,261
    Memory Throughput                   %         2.33
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.62
    L1/TEX Cache Throughput             %         5.75
    L2 Cache Throughput                 %         2.18
    SM Active Cycles                cycle     1,298.47
    Compute (SM) Throughput             %         2.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        17.58
    Achieved Active Warps Per SM           warp         5.63
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (17.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559651 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 3.17532e-25
GPU Step==nostream 2000, Center temp: 2.02475e-18
GPU Step==nostream 3000, Center temp: 1.40491e-14
GPU Step==nostream 4000, Center temp: 4.95374e-12
GPU Step==nostream 5000, Center temp: 3.36374e-10
GPU Step==nostream 6000, Center temp: 8.21915e-09
GPU Step==nostream 7000, Center temp: 1.01215e-07
GPU Step==nostream 8000, Center temp: 7.67398e-07
GPU Step==nostream 9000, Center temp: 4.07047e-06
GPU: Temperature at center: 1.64402e-05
GPU Execution Time: 563.968 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 564.018 ms
GPU: Temperature at center: 1.64402e-05
==PROF== Disconnected from process 559651
[559651] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       790.86
    Elapsed Cycles                  cycle        4,294
    Memory Throughput                   %         2.44
    DRAM Throughput                     %         0.74
    Duration                      usecond         5.34
    L1/TEX Cache Throughput             %         5.67
    L2 Cache Throughput                 %         1.71
    SM Active Cycles                cycle     1,814.50
    Compute (SM) Throughput             %         4.96
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        25.91
    Achieved Active Warps Per SM           warp         8.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 74.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (25.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559706 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 608.331 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 608.384 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559706
[559706] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       774.60
    Elapsed Cycles                  cycle        4,723
    Memory Throughput                   %         8.07
    DRAM Throughput                     %         0.68
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %        18.57
    L2 Cache Throughput                 %         2.17
    SM Active Cycles                cycle     2,026.60
    Compute (SM) Throughput             %         8.07
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.13
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        36.21
    Achieved Active Warps Per SM           warp        11.59
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 63.79%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (36.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559756 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 548.53 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 548.578 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 559756
[559756] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.43
    SM Frequency            cycle/usecond       749.33
    Elapsed Cycles                  cycle        4,127
    Memory Throughput                   %         2.53
    DRAM Throughput                     %         0.78
    Duration                      usecond         5.44
    L1/TEX Cache Throughput             %         6.08
    L2 Cache Throughput                 %         1.73
    SM Active Cycles                cycle     1,698.60
    Compute (SM) Throughput             %         5.62
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        28.81
    Achieved Active Warps Per SM           warp         9.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 71.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (28.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559798 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18556e-09
GPU Step==nostream 6000, Center temp: 6.67262e-08
GPU Step==nostream 7000, Center temp: 7.35777e-07
GPU Step==nostream 8000, Center temp: 5.14708e-06
GPU Step==nostream 9000, Center temp: 2.5729e-05
GPU: Temperature at center: 9.94499e-05
GPU Execution Time: 578.941 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 578.989 ms
GPU: Temperature at center: 9.94499e-05
==PROF== Disconnected from process 559798
[559798] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.54
    SM Frequency            cycle/usecond       764.48
    Elapsed Cycles                  cycle        4,384
    Memory Throughput                   %         4.07
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.66
    L1/TEX Cache Throughput             %         9.99
    L2 Cache Throughput                 %         1.68
    SM Active Cycles                cycle     1,764.77
    Compute (SM) Throughput             %         6.33
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.13
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        34.94
    Achieved Active Warps Per SM           warp        11.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 65.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (34.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559840 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26899e-13
GPU Step==nostream 4000, Center temp: 5.84052e-11
GPU Step==nostream 5000, Center temp: 3.18458e-09
GPU Step==nostream 6000, Center temp: 6.66758e-08
GPU Step==nostream 7000, Center temp: 7.34687e-07
GPU Step==nostream 8000, Center temp: 5.13425e-06
GPU Step==nostream 9000, Center temp: 2.56322e-05
GPU: Temperature at center: 9.89272e-05
GPU Execution Time: 668.893 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 668.937 ms
GPU: Temperature at center: 9.89272e-05
==PROF== Disconnected from process 559840
[559840] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         7.22
    SM Frequency            cycle/usecond       995.01
    Elapsed Cycles                  cycle        3,843
    Memory Throughput                   %         2.72
    DRAM Throughput                     %         0.83
    Duration                      usecond         3.81
    L1/TEX Cache Throughput             %         7.30
    L2 Cache Throughput                 %         1.90
    SM Active Cycles                cycle     1,410.13
    Compute (SM) Throughput             %         3.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.37
    Achieved Active Warps Per SM           warp         9.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (29.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=256
Block size: 2 x 256
==PROF== Connected to process 559882 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26899e-13
GPU Step==nostream 4000, Center temp: 5.84053e-11
GPU Step==nostream 5000, Center temp: 3.18461e-09
GPU Step==nostream 6000, Center temp: 6.66772e-08
GPU Step==nostream 7000, Center temp: 7.34716e-07
GPU Step==nostream 8000, Center temp: 5.13455e-06
GPU Step==nostream 9000, Center temp: 2.56342e-05
GPU: Temperature at center: 9.89372e-05
GPU Execution Time: 569.938 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 569.993 ms
GPU: Temperature at center: 9.89372e-05
==PROF== Disconnected from process 559882
[559882] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         7.16
    SM Frequency            cycle/usecond       994.18
    Elapsed Cycles                  cycle        3,866
    Memory Throughput                   %         2.70
    DRAM Throughput                     %         0.83
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %         7.34
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle     1,403.20
    Compute (SM) Throughput             %         3.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.43
    Achieved Active Warps Per SM           warp         9.42
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.57%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (29.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 559938 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 4.10339e-25
GPU Step==nostream 2000, Center temp: 9.90359e-18
GPU Step==nostream 3000, Center temp: 1.1514e-13
GPU Step==nostream 4000, Center temp: 4.54096e-11
GPU Step==nostream 5000, Center temp: 2.97799e-09
GPU Step==nostream 6000, Center temp: 6.62276e-08
GPU Step==nostream 7000, Center temp: 7.25757e-07
GPU Step==nostream 8000, Center temp: 4.87096e-06
GPU Step==nostream 9000, Center temp: 2.29417e-05
GPU: Temperature at center: 8.28752e-05
GPU Execution Time: 544 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 544.057 ms
GPU: Temperature at center: 8.28752e-05
==PROF== Disconnected from process 559938
[559938] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.80
    SM Frequency            cycle/usecond       802.88
    Elapsed Cycles                  cycle        4,738
    Memory Throughput                   %         3.41
    DRAM Throughput                     %         0.73
    Duration                      usecond         5.82
    L1/TEX Cache Throughput             %         8.26
    L2 Cache Throughput                 %         1.67
    SM Active Cycles                cycle     1,930.90
    Compute (SM) Throughput             %         6.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.75
    Achieved Active Warps Per SM           warp        14.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.25%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 559988 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26903e-13
GPU Step==nostream 4000, Center temp: 5.84124e-11
GPU Step==nostream 5000, Center temp: 3.18588e-09
GPU Step==nostream 6000, Center temp: 6.67401e-08
GPU Step==nostream 7000, Center temp: 7.36027e-07
GPU Step==nostream 8000, Center temp: 5.14954e-06
GPU Step==nostream 9000, Center temp: 2.57446e-05
GPU: Temperature at center: 9.9521e-05
GPU Execution Time: 585.798 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 585.843 ms
GPU: Temperature at center: 9.9521e-05
==PROF== Disconnected from process 559988
[559988] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       780.93
    Elapsed Cycles                  cycle        4,882
    Memory Throughput                   %        14.50
    DRAM Throughput                     %         0.71
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        31.61
    L2 Cache Throughput                 %         2.94
    SM Active Cycles                cycle     2,212.87
    Compute (SM) Throughput             %        14.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            8.22
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        70.32
    Achieved Active Warps Per SM           warp        22.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 29.68%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (70.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 560030 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67252e-08
GPU Step==nostream 7000, Center temp: 7.35749e-07
GPU Step==nostream 8000, Center temp: 5.14673e-06
GPU Step==nostream 9000, Center temp: 2.57263e-05
GPU: Temperature at center: 9.94357e-05
GPU Execution Time: 556.098 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 556.152 ms
GPU: Temperature at center: 9.94357e-05
==PROF== Disconnected from process 560030
[560030] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.49
    SM Frequency            cycle/usecond       748.45
    Elapsed Cycles                  cycle        4,248
    Memory Throughput                   %         3.81
    DRAM Throughput                     %         0.82
    Duration                      usecond         5.60
    L1/TEX Cache Throughput             %         9.31
    L2 Cache Throughput                 %         1.84
    SM Active Cycles                cycle     1,715.03
    Compute (SM) Throughput             %         8.62
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        51.80
    Achieved Active Warps Per SM           warp        16.58
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (51.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 560072 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87593e-17
GPU Step==nostream 3000, Center temp: 2.26902e-13
GPU Step==nostream 4000, Center temp: 5.84104e-11
GPU Step==nostream 5000, Center temp: 3.18555e-09
GPU Step==nostream 6000, Center temp: 6.67255e-08
GPU Step==nostream 7000, Center temp: 7.35765e-07
GPU Step==nostream 8000, Center temp: 5.14698e-06
GPU Step==nostream 9000, Center temp: 2.57286e-05
GPU: Temperature at center: 9.94497e-05
GPU Execution Time: 576.801 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 576.852 ms
GPU: Temperature at center: 9.94497e-05
==PROF== Disconnected from process 560072
[560072] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.54
    SM Frequency            cycle/usecond       763.70
    Elapsed Cycles                  cycle        4,551
    Memory Throughput                   %         5.18
    DRAM Throughput                     %         0.75
    Duration                      usecond         5.89
    L1/TEX Cache Throughput             %        12.17
    L2 Cache Throughput                 %         1.73
    SM Active Cycles                cycle     1,912.67
    Compute (SM) Throughput             %         9.80
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            8.22
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        66.31
    Achieved Active Warps Per SM           warp        21.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 33.69%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (66.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 560114 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87591e-17
GPU Step==nostream 3000, Center temp: 2.26883e-13
GPU Step==nostream 4000, Center temp: 5.83834e-11
GPU Step==nostream 5000, Center temp: 3.18089e-09
GPU Step==nostream 6000, Center temp: 6.65027e-08
GPU Step==nostream 7000, Center temp: 7.31214e-07
GPU Step==nostream 8000, Center temp: 5.09575e-06
GPU Step==nostream 9000, Center temp: 2.53552e-05
GPU: Temperature at center: 9.74906e-05
GPU Execution Time: 541.138 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 541.187 ms
GPU: Temperature at center: 9.74906e-05
==PROF== Disconnected from process 560114
[560114] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.64
    SM Frequency            cycle/usecond       920.11
    Elapsed Cycles                  cycle        3,776
    Memory Throughput                   %         4.26
    DRAM Throughput                     %         0.92
    Duration                      usecond         4.06
    L1/TEX Cache Throughput             %        11.04
    L2 Cache Throughput                 %         2.09
    SM Active Cycles                cycle        1,444
    Compute (SM) Throughput             %         6.70
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        54.97
    Achieved Active Warps Per SM           warp        17.59
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 45.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (55.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=2, y=512
Block size: 2 x 512
==PROF== Connected to process 560167 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 2x512
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.83221e-24
GPU Step==nostream 2000, Center temp: 5.68377e-17
GPU Step==nostream 3000, Center temp: 3.31964e-13
GPU Step==nostream 4000, Center temp: 1.00992e-10
GPU Step==nostream 5000, Center temp: 6.00319e-09
GPU Step==nostream 6000, Center temp: 1.29477e-07
GPU Step==nostream 7000, Center temp: 1.42134e-06
GPU Step==nostream 8000, Center temp: 9.71937e-06
GPU Step==nostream 9000, Center temp: 4.70697e-05
GPU: Temperature at center: 0.000175644
GPU Execution Time: 610.893 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 610.937 ms
GPU: Temperature at center: 0.000175644
==PROF== Disconnected from process 560167
[560167] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (25, 1, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       896.55
    Elapsed Cycles                  cycle        3,784
    Memory Throughput                   %         4.28
    DRAM Throughput                     %         0.92
    Duration                      usecond         4.16
    L1/TEX Cache Throughput             %        11.04
    L2 Cache Throughput                 %         2.09
    SM Active Cycles                cycle     1,444.03
    Compute (SM) Throughput             %         6.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        55.08
    Achieved Active Warps Per SM           warp        17.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (55.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560215 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 551.095 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 551.141 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560215
[560215] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.10
    SM Frequency            cycle/usecond       832.74
    Elapsed Cycles                  cycle        6,189
    Memory Throughput                   %         6.20
    DRAM Throughput                     %         0.48
    Duration                      usecond         7.36
    L1/TEX Cache Throughput             %         9.89
    L2 Cache Throughput                 %         6.20
    SM Active Cycles                cycle     3,761.93
    Compute (SM) Throughput             %        13.31
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 37.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        31.07
    Achieved Active Warps Per SM           warp         9.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 37.85%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560257 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 618.391 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 618.461 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560257
[560257] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond            6
    SM Frequency            cycle/usecond       818.11
    Elapsed Cycles                  cycle        6,144
    Memory Throughput                   %        13.57
    DRAM Throughput                     %         0.49
    Duration                      usecond         7.42
    L1/TEX Cache Throughput             %        21.25
    L2 Cache Throughput                 %         6.48
    SM Active Cycles                cycle     3,878.70
    Compute (SM) Throughput             %        16.81
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              72
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 33.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        33.27
    Achieved Active Warps Per SM           warp        10.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 33.46%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (33.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560299 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 590.25 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 590.314 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560299
[560299] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.17
    SM Frequency            cycle/usecond       842.26
    Elapsed Cycles                  cycle        5,896
    Memory Throughput                   %         6.69
    DRAM Throughput                     %         0.50
    Duration                      usecond         6.91
    L1/TEX Cache Throughput             %        10.45
    L2 Cache Throughput                 %         6.69
    SM Active Cycles                cycle     3,724.27
    Compute (SM) Throughput             %        13.23
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 40.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        29.69
    Achieved Active Warps Per SM           warp         9.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.62%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (29.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560341 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.796 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 549.838 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560341
[560341] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.10
    SM Frequency            cycle/usecond       839.88
    Elapsed Cycles                  cycle        6,233
    Memory Throughput                   %        13.39
    DRAM Throughput                     %         0.48
    Duration                      usecond         7.33
    L1/TEX Cache Throughput             %        20.79
    L2 Cache Throughput                 %         6.28
    SM Active Cycles                cycle        3,965
    Compute (SM) Throughput             %        15.04
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              72
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 38.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.84
    Achieved Active Warps Per SM           warp         9.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.32%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560383 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.348 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 553.396 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560383
[560383] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.45
    SM Frequency            cycle/usecond       881.77
    Elapsed Cycles                  cycle        4,643
    Memory Throughput                   %         8.40
    DRAM Throughput                     %         0.63
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %        13.51
    L2 Cache Throughput                 %         8.40
    SM Active Cycles                cycle     2,587.23
    Compute (SM) Throughput             %         7.83
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        31.60
    Achieved Active Warps Per SM           warp        10.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 36.81%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=1
Block size: 4 x 1
==PROF== Connected to process 560439 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 541.38 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 541.421 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560439
[560439] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 50, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       894.21
    Elapsed Cycles                  cycle        4,638
    Memory Throughput                   %         8.34
    DRAM Throughput                     %         0.64
    Duration                      usecond         5.12
    L1/TEX Cache Throughput             %        13.52
    L2 Cache Throughput                 %         8.34
    SM Active Cycles                cycle     2,584.53
    Compute (SM) Throughput             %         7.87
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    650
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                1.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 170 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 36.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        31.56
    Achieved Active Warps Per SM           warp        10.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 36.88%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (31.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560489 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 537.203 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 537.247 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560489
[560489] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.76
    SM Frequency            cycle/usecond       790.01
    Elapsed Cycles                  cycle        4,857
    Memory Throughput                   %         4.71
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %         7.02
    L2 Cache Throughput                 %         4.71
    SM Active Cycles                cycle     2,811.33
    Compute (SM) Throughput             %         8.99
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        23.83
    Achieved Active Warps Per SM           warp         7.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 52.35%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (23.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560531 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 541.733 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 541.78 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560531
[560531] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.90
    SM Frequency            cycle/usecond       802.86
    Elapsed Cycles                  cycle        4,854
    Memory Throughput                   %         8.74
    DRAM Throughput                     %         0.62
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %        14.34
    L2 Cache Throughput                 %         4.89
    SM Active Cycles                cycle     2,928.57
    Compute (SM) Throughput             %        11.11
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp         7.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.86%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560573 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 613.976 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 614.017 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560573
[560573] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.92
    SM Frequency            cycle/usecond       810.95
    Elapsed Cycles                  cycle        4,781
    Memory Throughput                   %         4.84
    DRAM Throughput                     %         0.62
    Duration                      usecond         5.82
    L1/TEX Cache Throughput             %         7.28
    L2 Cache Throughput                 %         4.84
    SM Active Cycles                cycle     2,498.10
    Compute (SM) Throughput             %         8.64
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.83
    Achieved Active Warps Per SM           warp         8.26
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.34%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560615 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 571.198 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 571.247 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560615
[560615] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.06
    SM Frequency            cycle/usecond       824.16
    Elapsed Cycles                  cycle        4,704
    Memory Throughput                   %         9.05
    DRAM Throughput                     %         0.62
    Duration                      usecond         5.63
    L1/TEX Cache Throughput             %        16.52
    L2 Cache Throughput                 %         5.00
    SM Active Cycles                cycle     2,542.33
    Compute (SM) Throughput             %        10.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block              96
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.37
    Achieved Active Warps Per SM           warp         8.44
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 47.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560670 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 593.523 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 593.565 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560670
[560670] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.45
    SM Frequency            cycle/usecond       896.84
    Elapsed Cycles                  cycle        3,595
    Memory Throughput                   %         6.43
    DRAM Throughput                     %         0.83
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %        10.32
    L2 Cache Throughput                 %         6.43
    SM Active Cycles                cycle     1,759.37
    Compute (SM) Throughput             %         5.39
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.01
    Achieved Active Warps Per SM           warp         8.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 43.98%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=2
Block size: 4 x 2
==PROF== Connected to process 560720 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 545.349 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 545.399 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560720
[560720] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 25, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       894.50
    Elapsed Cycles                  cycle        3,626
    Memory Throughput                   %         6.38
    DRAM Throughput                     %         0.82
    Duration                      usecond            4
    L1/TEX Cache Throughput             %        10.38
    L2 Cache Throughput                 %         6.38
    SM Active Cycles                cycle     1,749.27
    Compute (SM) Throughput             %         5.36
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    325
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,600
    Waves Per SM                                                0.68
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        27.93
    Achieved Active Warps Per SM           warp         8.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.14%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (27.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560762 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.564 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 549.644 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560762
[560762] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.82
    SM Frequency            cycle/usecond       795.31
    Elapsed Cycles                  cycle        4,790
    Memory Throughput                   %         3.11
    DRAM Throughput                     %         0.62
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         3.79
    L2 Cache Throughput                 %         3.11
    SM Active Cycles                cycle     2,530.33
    Compute (SM) Throughput             %         4.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        13.93
    Achieved Active Warps Per SM           warp         4.46
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 72.13%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (13.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560804 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 533.825 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 533.872 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560804
[560804] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       768.03
    Elapsed Cycles                  cycle        4,637
    Memory Throughput                   %         4.81
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         8.85
    L2 Cache Throughput                 %         3.36
    SM Active Cycles                cycle     2,485.57
    Compute (SM) Throughput             %         6.15
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             144
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.09
    Achieved Active Warps Per SM           warp         4.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 71.82%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (14.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560846 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 565.686 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 565.736 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560846
[560846] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.54
    SM Frequency            cycle/usecond       768.03
    Elapsed Cycles                  cycle        4,529
    Memory Throughput                   %         3.32
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.82
    L1/TEX Cache Throughput             %         4.23
    L2 Cache Throughput                 %         3.32
    SM Active Cycles                cycle     2,271.67
    Compute (SM) Throughput             %         4.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.83
    Achieved Active Warps Per SM           warp         4.74
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.35%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (14.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560901 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 538.237 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 538.282 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560901
[560901] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.76
    SM Frequency            cycle/usecond       800.89
    Elapsed Cycles                  cycle        4,510
    Memory Throughput                   %         4.93
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.57
    L1/TEX Cache Throughput             %         9.72
    L2 Cache Throughput                 %         3.34
    SM Active Cycles                cycle     2,262.53
    Compute (SM) Throughput             %         5.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             144
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.71
    Achieved Active Warps Per SM           warp         4.71
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.57%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (14.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560952 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.284 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 549.331 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560952
[560952] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.56
    SM Frequency            cycle/usecond       903.13
    Elapsed Cycles                  cycle        3,414
    Memory Throughput                   %         4.35
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         5.79
    L2 Cache Throughput                 %         4.35
    SM Active Cycles                cycle     1,656.23
    Compute (SM) Throughput             %         3.01
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.84
    Achieved Active Warps Per SM           warp         5.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.31%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=4
Block size: 4 x 4
==PROF== Connected to process 560994 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 595.274 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 595.325 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 560994
[560994] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 13, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.56
    SM Frequency            cycle/usecond       903.94
    Elapsed Cycles                  cycle        3,439
    Memory Throughput                   %         4.32
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         5.75
    L2 Cache Throughput                 %         4.32
    SM Active Cycles                cycle        1,668
    Compute (SM) Throughput             %         3.01
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    169
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,704
    Waves Per SM                                                0.35
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.82
    Achieved Active Warps Per SM           warp         5.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.36%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561036 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3550.67 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 3550.78 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561036
[561036] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.63
    SM Frequency            cycle/usecond       807.12
    Elapsed Cycles                  cycle        4,602
    Memory Throughput                   %         2.19
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.70
    L1/TEX Cache Throughput             %         2.67
    L2 Cache Throughput                 %         2.19
    SM Active Cycles                cycle     2,322.40
    Compute (SM) Throughput             %         2.67
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.19
    Achieved Active Warps Per SM           warp         2.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.62%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.2%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561112 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 613.199 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 613.247 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561112
[561112] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       748.82
    Elapsed Cycles                  cycle        4,487
    Memory Throughput                   %         2.70
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %         5.37
    L2 Cache Throughput                 %         2.47
    SM Active Cycles                cycle     2,232.73
    Compute (SM) Throughput             %         3.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             240
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.30
    Achieved Active Warps Per SM           warp         2.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.41%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561154 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 527.447 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 527.514 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 561154
[561154] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       773.48
    Elapsed Cycles                  cycle        4,428
    Memory Throughput                   %         2.31
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.66
    L1/TEX Cache Throughput             %         2.82
    L2 Cache Throughput                 %         2.31
    SM Active Cycles                cycle     2,138.47
    Compute (SM) Throughput             %         2.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.44
    Achieved Active Warps Per SM           warp         2.70
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.12%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.4%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561196 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 600.983 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 601.046 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561196
[561196] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       767.83
    Elapsed Cycles                  cycle        4,415
    Memory Throughput                   %         2.76
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.66
    L1/TEX Cache Throughput             %         5.66
    L2 Cache Throughput                 %         2.35
    SM Active Cycles                cycle     2,116.10
    Compute (SM) Throughput             %         3.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             240
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.48
    Achieved Active Warps Per SM           warp         2.71
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.04%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.5%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561238 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 570.243 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 570.284 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561238
[561238] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       890.36
    Elapsed Cycles                  cycle        3,406
    Memory Throughput                   %         2.95
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.78
    L1/TEX Cache Throughput             %         3.89
    L2 Cache Throughput                 %         2.95
    SM Active Cycles                cycle     1,590.77
    Compute (SM) Throughput             %         1.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.85
    Achieved Active Warps Per SM           warp         2.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.9%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=8
Block size: 4 x 8
==PROF== Connected to process 561293 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 622.396 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 622.461 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561293
[561293] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 7, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.56
    SM Frequency            cycle/usecond       904.02
    Elapsed Cycles                  cycle        3,428
    Memory Throughput                   %         2.94
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         3.90
    L2 Cache Throughput                 %         2.94
    SM Active Cycles                cycle     1,586.77
    Compute (SM) Throughput             %         1.65
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.85
    Achieved Active Warps Per SM           warp         2.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.29%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.9%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561343 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 545.507 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 545.55 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561343
[561343] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.36
    SM Frequency            cycle/usecond       744.79
    Elapsed Cycles                  cycle        4,492
    Memory Throughput                   %         2.01
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         2.78
    L2 Cache Throughput                 %         2.01
    SM Active Cycles                cycle     2,166.47
    Compute (SM) Throughput             %         2.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.19
    Achieved Active Warps Per SM           warp         2.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.81%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561385 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 545.446 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 545.485 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561385
[561385] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       742.16
    Elapsed Cycles                  cycle        4,463
    Memory Throughput                   %         2.95
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         6.14
    L2 Cache Throughput                 %         2.15
    SM Active Cycles                cycle     2,123.93
    Compute (SM) Throughput             %         3.62
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             432
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.59
    Achieved Active Warps Per SM           warp         3.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.41%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561427 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 532.48 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 532.525 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 561427
[561427] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       782.93
    Elapsed Cycles                  cycle        4,419
    Memory Throughput                   %         2.04
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.57
    L1/TEX Cache Throughput             %         2.89
    L2 Cache Throughput                 %         2.04
    SM Active Cycles                cycle     2,063.30
    Compute (SM) Throughput             %         2.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.28
    Achieved Active Warps Per SM           warp         2.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.72%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561469 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 527.48 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 527.551 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561469
[561469] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       779.51
    Elapsed Cycles                  cycle        4,395
    Memory Throughput                   %         2.81
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.57
    L1/TEX Cache Throughput             %         5.97
    L2 Cache Throughput                 %         2.06
    SM Active Cycles                cycle     2,041.77
    Compute (SM) Throughput             %         3.39
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             432
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.56
    Achieved Active Warps Per SM           warp         3.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.44%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561524 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3535.76 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3535.79 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561524
[561524] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.52
    SM Frequency            cycle/usecond       940.01
    Elapsed Cycles                  cycle        3,253
    Memory Throughput                   %         2.64
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.46
    L1/TEX Cache Throughput             %         3.90
    L2 Cache Throughput                 %         2.64
    SM Active Cycles                cycle     1,547.17
    Compute (SM) Throughput             %         1.82
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.69
    Achieved Active Warps Per SM           warp         3.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.31%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=16
Block size: 4 x 16
==PROF== Connected to process 561583 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 600.831 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 600.883 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561583
[561583] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 4, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.49
    SM Frequency            cycle/usecond       896.01
    Elapsed Cycles                  cycle        3,324
    Memory Throughput                   %         2.66
    DRAM Throughput                     %         0.90
    Duration                      usecond         3.68
    L1/TEX Cache Throughput             %         3.91
    L2 Cache Throughput                 %         2.66
    SM Active Cycles                cycle     1,545.10
    Compute (SM) Throughput             %         1.80
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.69
    Achieved Active Warps Per SM           warp         3.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.31%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561638 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 560.048 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 560.135 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561638
[561638] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.48
    SM Frequency            cycle/usecond       751.02
    Elapsed Cycles                  cycle        4,458
    Memory Throughput                   %         1.65
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.89
    L1/TEX Cache Throughput             %         3.28
    L2 Cache Throughput                 %         1.65
    SM Active Cycles                cycle     1,801.80
    Compute (SM) Throughput             %         2.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.91
    Achieved Active Warps Per SM           warp         3.49
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561688 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 569.101 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 569.167 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561688
[561688] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.48
    SM Frequency            cycle/usecond       753.18
    Elapsed Cycles                  cycle        4,561
    Memory Throughput                   %         2.89
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %         7.08
    L2 Cache Throughput                 %         1.63
    SM Active Cycles                cycle     1,842.40
    Compute (SM) Throughput             %         3.55
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             816
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.48
    Achieved Active Warps Per SM           warp         3.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.52%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561730 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 555.385 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 555.431 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 561730
[561730] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.58
    SM Frequency            cycle/usecond       772.64
    Elapsed Cycles                  cycle        4,356
    Memory Throughput                   %         1.73
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.54
    L1/TEX Cache Throughput             %         3.41
    L2 Cache Throughput                 %         1.73
    SM Active Cycles                cycle     1,719.50
    Compute (SM) Throughput             %         2.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.95
    Achieved Active Warps Per SM           warp         3.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.05%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561772 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.398 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 543.497 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561772
[561772] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.73
    SM Frequency            cycle/usecond       790.95
    Elapsed Cycles                  cycle        4,481
    Memory Throughput                   %         2.79
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.60
    L1/TEX Cache Throughput             %         6.90
    L2 Cache Throughput                 %         1.63
    SM Active Cycles                cycle     1,789.23
    Compute (SM) Throughput             %         3.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             816
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.33
    Achieved Active Warps Per SM           warp         3.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.67%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561814 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 605.702 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 605.777 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561814
[561814] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond        19.70
    SM Frequency            cycle/nsecond         2.73
    Elapsed Cycles                  cycle        9,849
    Memory Throughput                   %         0.76
    DRAM Throughput                     %         0.31
    Duration                      usecond         3.55
    L1/TEX Cache Throughput             %         4.49
    L2 Cache Throughput                 %         0.76
    SM Active Cycles                cycle     1,320.17
    Compute (SM) Throughput             %         0.61
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.93
    Achieved Active Warps Per SM           warp         3.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=32
Block size: 4 x 32
==PROF== Connected to process 561869 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 587.778 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 587.835 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 561869
[561869] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 2, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.55
    SM Frequency            cycle/usecond       904.73
    Elapsed Cycles                  cycle        3,233
    Memory Throughput                   %         2.31
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.52
    L1/TEX Cache Throughput             %         4.40
    L2 Cache Throughput                 %         2.31
    SM Active Cycles                cycle     1,346.57
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.88
    Achieved Active Warps Per SM           warp         3.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.12%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 561919 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 590.045 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 590.091 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561919
[561919] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       747.87
    Elapsed Cycles                  cycle        4,507
    Memory Throughput                   %         1.46
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         6.37
    L2 Cache Throughput                 %         1.46
    SM Active Cycles                cycle       920.80
    Compute (SM) Throughput             %         2.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.37
    Achieved Active Warps Per SM           warp         6.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 561961 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 584.471 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 584.512 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 561961
[561961] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       761.41
    Elapsed Cycles                  cycle        4,669
    Memory Throughput                   %         2.83
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %        13.40
    L2 Cache Throughput                 %         1.41
    SM Active Cycles                cycle       973.63
    Compute (SM) Throughput             %         3.47
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.77
    Achieved Active Warps Per SM           warp         7.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 562003 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 542.656 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 542.733 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 562003
[562003] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.83
    SM Frequency            cycle/usecond       806.47
    Elapsed Cycles                  cycle        4,479
    Memory Throughput                   %         1.42
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         6.55
    L2 Cache Throughput                 %         1.42
    SM Active Cycles                cycle       886.87
    Compute (SM) Throughput             %         2.80
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.73
    Achieved Active Warps Per SM           warp         6.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.27%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 562045 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84829e-05
GPU Execution Time: 564.651 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 564.693 ms
GPU: Temperature at center: 9.84829e-05
==PROF== Disconnected from process 562045
[562045] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.73
    SM Frequency            cycle/usecond       795.04
    Elapsed Cycles                  cycle        4,542
    Memory Throughput                   %         2.72
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.63
    L1/TEX Cache Throughput             %        12.73
    L2 Cache Throughput                 %         1.43
    SM Active Cycles                cycle       956.80
    Compute (SM) Throughput             %         3.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.26
    Achieved Active Warps Per SM           warp         7.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.74%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 562098 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 548.652 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 548.697 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 562098
[562098] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       895.64
    Elapsed Cycles                  cycle        3,209
    Memory Throughput                   %         1.94
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.52
    L1/TEX Cache Throughput             %         8.66
    L2 Cache Throughput                 %         1.94
    SM Active Cycles                cycle       678.97
    Compute (SM) Throughput             %         1.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.90
    Achieved Active Warps Per SM           warp         6.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.1%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=64
Block size: 4 x 64
==PROF== Connected to process 562146 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 548.074 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 548.126 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 562146
[562146] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       882.10
    Elapsed Cycles                  cycle        3,254
    Memory Throughput                   %         1.92
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.62
    L1/TEX Cache Throughput             %         8.65
    L2 Cache Throughput                 %         1.92
    SM Active Cycles                cycle       678.77
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.87
    Achieved Active Warps Per SM           warp         6.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.13%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562188 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.84809e-05
GPU Execution Time: 566.568 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 566.608 ms
GPU: Temperature at center: 9.84809e-05
==PROF== Disconnected from process 562188
[562188] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.62
    SM Frequency            cycle/usecond       778.77
    Elapsed Cycles                  cycle        4,690
    Memory Throughput                   %         1.53
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %         7.47
    L2 Cache Throughput                 %         1.42
    SM Active Cycles                cycle       944.17
    Compute (SM) Throughput             %         3.35
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        30.74
    Achieved Active Warps Per SM           warp         9.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.26%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (30.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562230 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84828e-05
GPU Execution Time: 577.638 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 577.687 ms
GPU: Temperature at center: 9.84828e-05
==PROF== Disconnected from process 562230
[562230] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.64
    SM Frequency            cycle/usecond       776.15
    Elapsed Cycles                  cycle        4,888
    Memory Throughput                   %         4.47
    DRAM Throughput                     %         0.62
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %        20.89
    L2 Cache Throughput                 %         1.44
    SM Active Cycles                cycle     1,030.43
    Compute (SM) Throughput             %         4.59
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.12
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.97
    Achieved Active Warps Per SM           warp        12.15
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562272 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 593.249 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 593.337 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 562272
[562272] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       782.35
    Elapsed Cycles                  cycle        4,342
    Memory Throughput                   %         1.65
    DRAM Throughput                     %         0.70
    Duration                      usecond         5.47
    L1/TEX Cache Throughput             %         8.17
    L2 Cache Throughput                 %         1.48
    SM Active Cycles                cycle       866.27
    Compute (SM) Throughput             %         3.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        32.53
    Achieved Active Warps Per SM           warp        10.41
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (32.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562328 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84829e-05
GPU Execution Time: 525.583 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 525.662 ms
GPU: Temperature at center: 9.84829e-05
==PROF== Disconnected from process 562328
[562328] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.82
    SM Frequency            cycle/usecond       801.79
    Elapsed Cycles                  cycle        4,584
    Memory Throughput                   %         3.04
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.63
    L1/TEX Cache Throughput             %        14.26
    L2 Cache Throughput                 %         1.46
    SM Active Cycles                cycle       962.83
    Compute (SM) Throughput             %         4.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.12
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        38.08
    Achieved Active Warps Per SM           warp        12.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 61.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562370 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84796e-05
GPU Execution Time: 562 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 562.05 ms
GPU: Temperature at center: 9.84796e-05
==PROF== Disconnected from process 562370
[562370] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       899.05
    Elapsed Cycles                  cycle        3,223
    Memory Throughput                   %         2.23
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.52
    L1/TEX Cache Throughput             %        10.14
    L2 Cache Throughput                 %         1.96
    SM Active Cycles                cycle       695.57
    Compute (SM) Throughput             %         2.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        33.43
    Achieved Active Warps Per SM           warp        10.70
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 66.57%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (33.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=128
Block size: 4 x 128
==PROF== Connected to process 562418 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84796e-05
GPU Execution Time: 563.715 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 563.762 ms
GPU: Temperature at center: 9.84796e-05
==PROF== Disconnected from process 562418
[562418] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.55
    SM Frequency            cycle/usecond       898.86
    Elapsed Cycles                  cycle        3,220
    Memory Throughput                   %         2.23
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.52
    L1/TEX Cache Throughput             %        10.09
    L2 Cache Throughput                 %         1.95
    SM Active Cycles                cycle       699.27
    Compute (SM) Throughput             %         2.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        33.40
    Achieved Active Warps Per SM           warp        10.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 66.6%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (33.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562460 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.84809e-05
GPU Execution Time: 566.403 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 571.632 ms
GPU: Temperature at center: 9.84809e-05
==PROF== Disconnected from process 562460
[562460] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.53
    SM Frequency            cycle/usecond       766.77
    Elapsed Cycles                  cycle        4,639
    Memory Throughput                   %         2.21
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %        10.18
    L2 Cache Throughput                 %         1.47
    SM Active Cycles                cycle       996.63
    Compute (SM) Throughput             %         4.59
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        49.97
    Achieved Active Warps Per SM           warp        15.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (50.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562502 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84829e-05
GPU Execution Time: 551.278 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 551.321 ms
GPU: Temperature at center: 9.84829e-05
==PROF== Disconnected from process 562502
[562502] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       789.04
    Elapsed Cycles                  cycle        5,167
    Memory Throughput                   %         7.55
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.46
    L1/TEX Cache Throughput             %        33.01
    L2 Cache Throughput                 %         1.58
    SM Active Cycles                cycle     1,166.03
    Compute (SM) Throughput             %         7.55
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.19
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        70.81
    Achieved Active Warps Per SM           warp        22.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 29.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (70.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562544 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.33311e-07
GPU Step==nostream 8000, Center temp: 5.12009e-06
GPU Step==nostream 9000, Center temp: 2.55385e-05
GPU: Temperature at center: 9.84836e-05
GPU Execution Time: 538.574 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 538.65 ms
GPU: Temperature at center: 9.84836e-05
==PROF== Disconnected from process 562544
[562544] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.76
    SM Frequency            cycle/usecond       789.99
    Elapsed Cycles                  cycle        4,449
    Memory Throughput                   %         2.31
    DRAM Throughput                     %         0.71
    Duration                      usecond         5.57
    L1/TEX Cache Throughput             %        10.92
    L2 Cache Throughput                 %         1.54
    SM Active Cycles                cycle          932
    Compute (SM) Throughput             %         5.16
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        55.17
    Achieved Active Warps Per SM           warp        17.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.83%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (55.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562599 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66027e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12008e-06
GPU Step==nostream 9000, Center temp: 2.55384e-05
GPU: Temperature at center: 9.84829e-05
GPU Execution Time: 540.766 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 540.812 ms
GPU: Temperature at center: 9.84829e-05
==PROF== Disconnected from process 562599
[562599] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       792.12
    Elapsed Cycles                  cycle        4,745
    Memory Throughput                   %         3.59
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %        16.14
    L2 Cache Throughput                 %         1.43
    SM Active Cycles                cycle     1,042.07
    Compute (SM) Throughput             %         5.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.19
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        69.30
    Achieved Active Warps Per SM           warp        22.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 30.7%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (69.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562649 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84796e-05
GPU Execution Time: 549.095 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 549.141 ms
GPU: Temperature at center: 9.84796e-05
==PROF== Disconnected from process 562649
[562649] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.28
    SM Frequency            cycle/usecond       867.78
    Elapsed Cycles                  cycle        3,488
    Memory Throughput                   %         2.95
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %        13.63
    L2 Cache Throughput                 %         1.88
    SM Active Cycles                cycle       744.50
    Compute (SM) Throughput             %         4.17
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        58.64
    Achieved Active Warps Per SM           warp        18.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.36%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (58.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=4, y=256
Block size: 4 x 256
==PROF== Connected to process 562695 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 4x256
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84796e-05
GPU Execution Time: 579.255 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 579.298 ms
GPU: Temperature at center: 9.84796e-05
==PROF== Disconnected from process 562695
[562695] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (13, 1, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.33
    SM Frequency            cycle/usecond       870.09
    Elapsed Cycles                  cycle        3,470
    Memory Throughput                   %         2.96
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.94
    L1/TEX Cache Throughput             %        13.61
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle       745.40
    Compute (SM) Throughput             %         4.20
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        58.64
    Achieved Active Warps Per SM           warp        18.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.36%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (58.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562737 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66012e-08
GPU Step==nostream 7000, Center temp: 7.33263e-07
GPU Step==nostream 8000, Center temp: 5.11929e-06
GPU Step==nostream 9000, Center temp: 2.55304e-05
GPU: Temperature at center: 9.84276e-05
GPU Execution Time: 547.76 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 547.803 ms
GPU: Temperature at center: 9.84276e-05
==PROF== Disconnected from process 562737
[562737] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       800.73
    Elapsed Cycles                  cycle        5,024
    Memory Throughput                   %         7.09
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %         9.53
    L2 Cache Throughput                 %         7.09
    SM Active Cycles                cycle     3,256.60
    Compute (SM) Throughput             %        10.21
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        24.58
    Achieved Active Warps Per SM           warp         7.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50.85%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (24.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562780 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 524.054 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 524.116 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 562780
[562780] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       781.97
    Elapsed Cycles                  cycle        5,119
    Memory Throughput                   %         8.83
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        14.77
    L2 Cache Throughput                 %         7.18
    SM Active Cycles                cycle     3,451.07
    Compute (SM) Throughput             %        12.14
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             120
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        25.61
    Achieved Active Warps Per SM           warp         8.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (25.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562835 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 536.584 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 536.628 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 562835
[562835] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       778.81
    Elapsed Cycles                  cycle        4,851
    Memory Throughput                   %         7.36
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         9.87
    L2 Cache Throughput                 %         7.36
    SM Active Cycles                cycle     2,917.67
    Compute (SM) Throughput             %         9.46
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        26.62
    Achieved Active Warps Per SM           warp         8.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (26.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562885 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 578.833 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 578.881 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 562885
[562885] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.74
    SM Frequency            cycle/usecond       785.20
    Elapsed Cycles                  cycle        4,978
    Memory Throughput                   %         9.15
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.24
    L1/TEX Cache Throughput             %        15.02
    L2 Cache Throughput                 %         7.19
    SM Active Cycles                cycle     2,986.87
    Compute (SM) Throughput             %        10.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             120
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        28.03
    Achieved Active Warps Per SM           warp         8.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 43.95%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (28.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562927 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66024e-08
GPU Step==nostream 7000, Center temp: 7.33302e-07
GPU Step==nostream 8000, Center temp: 5.11994e-06
GPU Step==nostream 9000, Center temp: 2.55367e-05
GPU: Temperature at center: 9.84705e-05
GPU Execution Time: 602.87 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 602.911 ms
GPU: Temperature at center: 9.84705e-05
==PROF== Disconnected from process 562927
[562927] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       883.13
    Elapsed Cycles                  cycle        3,781
    Memory Throughput                   %         9.51
    DRAM Throughput                     %         0.81
    Duration                      usecond         4.22
    L1/TEX Cache Throughput             %        12.63
    L2 Cache Throughput                 %         9.51
    SM Active Cycles                cycle     1,929.77
    Compute (SM) Throughput             %         5.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.79
    Achieved Active Warps Per SM           warp         9.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.41%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=1
Block size: 8 x 1
==PROF== Connected to process 562970 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66024e-08
GPU Step==nostream 7000, Center temp: 7.33302e-07
GPU Step==nostream 8000, Center temp: 5.11994e-06
GPU Step==nostream 9000, Center temp: 2.55367e-05
GPU: Temperature at center: 9.84705e-05
GPU Execution Time: 549.731 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 549.798 ms
GPU: Temperature at center: 9.84705e-05
==PROF== Disconnected from process 562970
[562970] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 50, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.64
    SM Frequency            cycle/usecond       910.31
    Elapsed Cycles                  cycle        3,876
    Memory Throughput                   %         9.33
    DRAM Throughput                     %         0.79
    Duration                      usecond         4.19
    L1/TEX Cache Throughput             %        12.35
    L2 Cache Throughput                 %         9.33
    SM Active Cycles                cycle     1,927.23
    Compute (SM) Throughput             %         5.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.7 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    350
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.73
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        30.84
    Achieved Active Warps Per SM           warp         9.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 38.33%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (30.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563012 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 591.548 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 591.587 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563012
[563012] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       797.64
    Elapsed Cycles                  cycle        4,919
    Memory Throughput                   %         4.56
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %         5.51
    L2 Cache Throughput                 %         4.56
    SM Active Cycles                cycle     2,781.30
    Compute (SM) Throughput             %         5.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.22
    Achieved Active Warps Per SM           warp         4.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 71.56%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (14.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563067 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 602.35 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 602.393 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563067
[563067] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       784.00
    Elapsed Cycles                  cycle        4,928
    Memory Throughput                   %         4.71
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %         8.13
    L2 Cache Throughput                 %         4.63
    SM Active Cycles                cycle     2,806.33
    Compute (SM) Throughput             %         6.63
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             160
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.62
    Achieved Active Warps Per SM           warp         4.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.76%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (14.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563117 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 591.395 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 591.448 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563117
[563117] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       771.71
    Elapsed Cycles                  cycle        4,759
    Memory Throughput                   %         4.83
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         5.69
    L2 Cache Throughput                 %         4.83
    SM Active Cycles                cycle     2,439.57
    Compute (SM) Throughput             %         5.02
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        14.97
    Achieved Active Warps Per SM           warp         4.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.06%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563159 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 613.392 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 613.47 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563159
[563159] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.68
    SM Frequency            cycle/usecond       775.82
    Elapsed Cycles                  cycle        4,625
    Memory Throughput                   %         5.00
    DRAM Throughput                     %         0.64
    Duration                      usecond         5.89
    L1/TEX Cache Throughput             %         9.34
    L2 Cache Throughput                 %         4.90
    SM Active Cycles                cycle     2,443.63
    Compute (SM) Throughput             %         6.10
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             160
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        15.07
    Achieved Active Warps Per SM           warp         4.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.85%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (15.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563201 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 587.571 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 587.617 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563201
[563201] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       875.34
    Elapsed Cycles                  cycle        3,522
    Memory Throughput                   %         6.43
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %         7.69
    L2 Cache Throughput                 %         6.43
    SM Active Cycles                cycle     1,736.10
    Compute (SM) Throughput             %         3.05
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.37
    Achieved Active Warps Per SM           warp         5.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=2
Block size: 8 x 2
==PROF== Connected to process 563243 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3633.48 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 3633.53 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563243
[563243] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 25, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.76
    SM Frequency            cycle/usecond       971.44
    Elapsed Cycles                  cycle        3,608
    Memory Throughput                   %         6.16
    DRAM Throughput                     %         0.87
    Duration                      usecond         3.71
    L1/TEX Cache Throughput             %         7.70
    L2 Cache Throughput                 %         6.16
    SM Active Cycles                cycle     1,732.20
    Compute (SM) Throughput             %         2.94
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    175
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,800
    Waves Per SM                                                0.36
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.35
    Achieved Active Warps Per SM           warp         5.23
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.3%                                                                                     
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563318 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 606.506 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 606.571 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563318
[563318] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.53
    SM Frequency            cycle/usecond       764.09
    Elapsed Cycles                  cycle        4,698
    Memory Throughput                   %         3.10
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %         3.51
    L2 Cache Throughput                 %         3.10
    SM Active Cycles                cycle     2,511.87
    Compute (SM) Throughput             %         2.97
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         7.98
    Achieved Active Warps Per SM           warp         2.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 84.04%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.0%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563360 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 568.483 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 568.551 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563360
[563360] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       749.24
    Elapsed Cycles                  cycle        4,634
    Memory Throughput                   %         3.26
    DRAM Throughput                     %         0.71
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         5.07
    L2 Cache Throughput                 %         3.26
    SM Active Cycles                cycle     2,540.23
    Compute (SM) Throughput             %         3.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             240
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.06
    Achieved Active Warps Per SM           warp         2.58
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.88%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.1%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563415 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 582.309 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 582.384 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563415
[563415] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.45
    SM Frequency            cycle/usecond       751.73
    Elapsed Cycles                  cycle        4,554
    Memory Throughput                   %         3.24
    DRAM Throughput                     %         0.65
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %         3.69
    L2 Cache Throughput                 %         3.24
    SM Active Cycles                cycle     2,267.93
    Compute (SM) Throughput             %         2.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.30
    Achieved Active Warps Per SM           warp         2.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.39%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563465 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 580.357 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 580.402 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563465
[563465] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       763.09
    Elapsed Cycles                  cycle        4,522
    Memory Throughput                   %         3.23
    DRAM Throughput                     %         0.65
    Duration                      usecond         5.86
    L1/TEX Cache Throughput             %         5.35
    L2 Cache Throughput                 %         3.23
    SM Active Cycles                cycle     2,233.43
    Compute (SM) Throughput             %         3.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             240
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.28
    Achieved Active Warps Per SM           warp         2.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563507 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 586.053 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 586.127 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563507
[563507] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.41
    SM Frequency            cycle/usecond       878.50
    Elapsed Cycles                  cycle        3,388
    Memory Throughput                   %         4.25
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.81
    L1/TEX Cache Throughput             %         5.25
    L2 Cache Throughput                 %         4.25
    SM Active Cycles                cycle     1,574.13
    Compute (SM) Throughput             %         1.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.00
    Achieved Active Warps Per SM           warp         2.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.99%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.0%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=4
Block size: 8 x 4
==PROF== Connected to process 563563 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 588.529 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 588.57 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563563
[563563] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 13, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.27
    SM Frequency            cycle/usecond       870.75
    Elapsed Cycles                  cycle        3,397
    Memory Throughput                   %         4.25
    DRAM Throughput                     %         0.90
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %         5.16
    L2 Cache Throughput                 %         4.25
    SM Active Cycles                cycle     1,598.43
    Compute (SM) Throughput             %         1.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     91
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,912
    Waves Per SM                                                0.19
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.99
    Achieved Active Warps Per SM           warp         2.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.01%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.0%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563607 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 554.833 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 554.912 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563607
[563607] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.47
    SM Frequency            cycle/usecond       755.65
    Elapsed Cycles                  cycle        4,664
    Memory Throughput                   %         2.42
    DRAM Throughput                     %         0.64
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %         3.02
    L2 Cache Throughput                 %         2.42
    SM Active Cycles                cycle     2,299.93
    Compute (SM) Throughput             %         3.05
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.00
    Achieved Active Warps Per SM           warp         2.88
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 91%                                                                                       
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.0%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563662 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 542.05 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 542.092 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563662
[563662] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       747.18
    Elapsed Cycles                  cycle        4,643
    Memory Throughput                   %         2.73
    DRAM Throughput                     %         0.71
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         5.59
    L2 Cache Throughput                 %         2.53
    SM Active Cycles                cycle     2,240.33
    Compute (SM) Throughput             %         3.74
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             400
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.24
    Achieved Active Warps Per SM           warp         2.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563712 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 527.997 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 528.058 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563712
[563712] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.39
    SM Frequency            cycle/usecond       747.35
    Elapsed Cycles                  cycle        4,480
    Memory Throughput                   %         2.49
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %         3.14
    L2 Cache Throughput                 %         2.49
    SM Active Cycles                cycle     2,232.80
    Compute (SM) Throughput             %         2.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.20
    Achieved Active Warps Per SM           warp         2.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563754 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.687 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 543.748 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563754
[563754] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.51
    SM Frequency            cycle/usecond       756.26
    Elapsed Cycles                  cycle        4,490
    Memory Throughput                   %         2.72
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.86
    L1/TEX Cache Throughput             %         5.80
    L2 Cache Throughput                 %         2.54
    SM Active Cycles                cycle     2,080.20
    Compute (SM) Throughput             %         3.39
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             400
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.31
    Achieved Active Warps Per SM           warp         2.98
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.69%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.3%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563796 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 548.627 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 548.677 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563796
[563796] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       899.03
    Elapsed Cycles                  cycle        3,332
    Memory Throughput                   %         3.43
    DRAM Throughput                     %         0.98
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %         4.50
    L2 Cache Throughput                 %         3.43
    SM Active Cycles                cycle     1,544.20
    Compute (SM) Throughput             %         1.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.53
    Achieved Active Warps Per SM           warp         3.05
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=8
Block size: 8 x 8
==PROF== Connected to process 563839 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 550.399 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 550.467 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563839
[563839] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 7, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.50
    SM Frequency            cycle/usecond       896.47
    Elapsed Cycles                  cycle        3,313
    Memory Throughput                   %         3.39
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.65
    L1/TEX Cache Throughput             %         4.53
    L2 Cache Throughput                 %         3.39
    SM Active Cycles                cycle     1,533.03
    Compute (SM) Throughput             %         1.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     49
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,136
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.51
    Achieved Active Warps Per SM           warp         3.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.49%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.5%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 563881 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.972 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 547.108 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563881
[563881] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.45
    SM Frequency            cycle/usecond       754.30
    Elapsed Cycles                  cycle        4,625
    Memory Throughput                   %         2.25
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %         3.30
    L2 Cache Throughput                 %         2.25
    SM Active Cycles                cycle        2,077
    Compute (SM) Throughput             %         3.15
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.50
    Achieved Active Warps Per SM           warp         3.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 563936 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 597.109 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 597.15 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563936
[563936] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       747.63
    Elapsed Cycles                  cycle        4,600
    Memory Throughput                   %         3.03
    DRAM Throughput                     %         0.72
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %         6.76
    L2 Cache Throughput                 %         1.89
    SM Active Cycles                cycle     2,024.80
    Compute (SM) Throughput             %         3.98
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             720
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.33
    Achieved Active Warps Per SM           warp         3.63
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.67%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 563986 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 584.819 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 584.871 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 563986
[563986] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.45
    SM Frequency            cycle/usecond       746.28
    Elapsed Cycles                  cycle        4,464
    Memory Throughput                   %         2.20
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %         3.55
    L2 Cache Throughput                 %         2.20
    SM Active Cycles                cycle     1,933.43
    Compute (SM) Throughput             %         3.00
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.47
    Achieved Active Warps Per SM           warp         3.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.53%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 564028 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.61 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 540.68 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564028
[564028] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       746.87
    Elapsed Cycles                  cycle        4,429
    Memory Throughput                   %         2.81
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.86
    L1/TEX Cache Throughput             %         6.41
    L2 Cache Throughput                 %         1.99
    SM Active Cycles                cycle     1,917.17
    Compute (SM) Throughput             %         3.57
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             720
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.20
    Achieved Active Warps Per SM           warp         3.58
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 564070 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.832 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 547.88 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564070
[564070] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.64
    SM Frequency            cycle/usecond       913.75
    Elapsed Cycles                  cycle        3,517
    Memory Throughput                   %         3.08
    DRAM Throughput                     %         0.88
    Duration                      usecond         3.78
    L1/TEX Cache Throughput             %         4.65
    L2 Cache Throughput                 %         3.08
    SM Active Cycles                cycle     1,479.50
    Compute (SM) Throughput             %         1.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.55
    Achieved Active Warps Per SM           warp         3.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=16
Block size: 8 x 16
==PROF== Connected to process 564112 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 597.08 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 597.127 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564112
[564112] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 4, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.31
    SM Frequency            cycle/usecond       874.91
    Elapsed Cycles                  cycle        3,401
    Memory Throughput                   %         3.16
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %         4.70
    L2 Cache Throughput                 %         3.16
    SM Active Cycles                cycle     1,465.33
    Compute (SM) Throughput             %         1.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.58
    Achieved Active Warps Per SM           warp         3.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564167 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 595.756 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 595.823 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564167
[564167] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       762.90
    Elapsed Cycles                  cycle        4,687
    Memory Throughput                   %         1.70
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %         6.46
    L2 Cache Throughput                 %         1.70
    SM Active Cycles                cycle     1,044.93
    Compute (SM) Throughput             %         3.12
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.68
    Achieved Active Warps Per SM           warp         6.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564217 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 533.971 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 534.038 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564217
[564217] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       760.96
    Elapsed Cycles                  cycle        4,738
    Memory Throughput                   %         2.93
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %        12.58
    L2 Cache Throughput                 %         1.54
    SM Active Cycles                cycle     1,087.57
    Compute (SM) Throughput             %         3.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.12
    Achieved Active Warps Per SM           warp         7.08
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.88%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564259 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.844 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 540.894 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564259
[564259] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.48
    SM Frequency            cycle/usecond       750.52
    Elapsed Cycles                  cycle        4,421
    Memory Throughput                   %         1.77
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.82
    L1/TEX Cache Throughput             %         6.70
    L2 Cache Throughput                 %         1.77
    SM Active Cycles                cycle     1,008.10
    Compute (SM) Throughput             %         3.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.15
    Achieved Active Warps Per SM           warp         6.45
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.85%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564301 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 545.681 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 545.722 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564301
[564301] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.54
    SM Frequency            cycle/usecond       764.64
    Elapsed Cycles                  cycle        4,568
    Memory Throughput                   %         2.71
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %        11.80
    L2 Cache Throughput                 %         1.62
    SM Active Cycles                cycle     1,041.33
    Compute (SM) Throughput             %         3.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.53
    Achieved Active Warps Per SM           warp         6.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564343 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 575.957 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 576 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564343
[564343] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       886.49
    Elapsed Cycles                  cycle        3,361
    Memory Throughput                   %         2.40
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %         9.24
    L2 Cache Throughput                 %         2.40
    SM Active Cycles                cycle       732.07
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.61
    Achieved Active Warps Per SM           warp         6.60
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.39%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=32
Block size: 8 x 32
==PROF== Connected to process 564398 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.989 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 550.084 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564398
[564398] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 2, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       892.11
    Elapsed Cycles                  cycle        3,239
    Memory Throughput                   %         2.49
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %         9.10
    L2 Cache Throughput                 %         2.49
    SM Active Cycles                cycle       747.27
    Compute (SM) Throughput             %         1.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.37
    Achieved Active Warps Per SM           warp         6.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564448 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 568.819 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 568.86 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564448
[564448] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.60
    SM Frequency            cycle/usecond       771.93
    Elapsed Cycles                  cycle        5,018
    Memory Throughput                   %         1.36
    DRAM Throughput                     %         0.60
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %        12.09
    L2 Cache Throughput                 %         1.26
    SM Active Cycles                cycle       555.70
    Compute (SM) Throughput             %         2.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        40.36
    Achieved Active Warps Per SM           warp        12.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 59.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (40.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564491 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.563 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 540.611 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564491
[564491] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.46
    SM Frequency            cycle/usecond       757.41
    Elapsed Cycles                  cycle        5,190
    Memory Throughput                   %         2.68
    DRAM Throughput                     %         0.58
    Duration                      usecond         6.75
    L1/TEX Cache Throughput             %        22.52
    L2 Cache Throughput                 %         1.28
    SM Active Cycles                cycle       607.67
    Compute (SM) Throughput             %         3.52
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           11
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        43.55
    Achieved Active Warps Per SM           warp        13.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 56.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (43.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564533 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 571.957 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 572.004 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564533
[564533] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.64
    SM Frequency            cycle/usecond       776.70
    Elapsed Cycles                  cycle        4,805
    Memory Throughput                   %         1.43
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %        12.47
    L2 Cache Throughput                 %         1.42
    SM Active Cycles                cycle       540.23
    Compute (SM) Throughput             %         2.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        39.93
    Achieved Active Warps Per SM           warp        12.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 60.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (39.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564575 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.232 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 546.285 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564575
[564575] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.74
    SM Frequency            cycle/usecond       788.14
    Elapsed Cycles                  cycle        5,049
    Memory Throughput                   %         2.46
    DRAM Throughput                     %         0.59
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %        20.91
    L2 Cache Throughput                 %         1.29
    SM Active Cycles                cycle       587.70
    Compute (SM) Throughput             %         3.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           11
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        42.37
    Achieved Active Warps Per SM           warp        13.56
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 57.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (42.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564630 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 570.289 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 570.336 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564630
[564630] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       914.04
    Elapsed Cycles                  cycle        3,311
    Memory Throughput                   %         2.10
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.55
    L1/TEX Cache Throughput             %        17.96
    L2 Cache Throughput                 %         1.83
    SM Active Cycles                cycle       380.33
    Compute (SM) Throughput             %         1.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.38
    Achieved Active Warps Per SM           warp        13.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.62%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=64
Block size: 8 x 64
==PROF== Connected to process 564680 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 596.035 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 596.127 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564680
[564680] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       900.20
    Elapsed Cycles                  cycle        3,280
    Memory Throughput                   %         2.12
    DRAM Throughput                     %         0.95
    Duration                      usecond         3.58
    L1/TEX Cache Throughput             %        18.03
    L2 Cache Throughput                 %         1.85
    SM Active Cycles                cycle          380
    Compute (SM) Throughput             %         1.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.49
    Achieved Active Warps Per SM           warp        13.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.51%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564722 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 536.147 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 536.196 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564722
[564722] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       768.87
    Elapsed Cycles                  cycle        5,045
    Memory Throughput                   %         1.53
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.46
    L1/TEX Cache Throughput             %        13.05
    L2 Cache Throughput                 %         1.31
    SM Active Cycles                cycle       582.67
    Compute (SM) Throughput             %         3.51
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        58.30
    Achieved Active Warps Per SM           warp        18.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 41.7%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (58.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564764 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.16 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 547.213 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564764
[564764] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       790.05
    Elapsed Cycles                  cycle        5,603
    Memory Throughput                   %         4.15
    DRAM Throughput                     %         0.55
    Duration                      usecond         7.01
    L1/TEX Cache Throughput             %        33.07
    L2 Cache Throughput                 %         1.23
    SM Active Cycles                cycle       694.43
    Compute (SM) Throughput             %         4.44
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            5.20
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.54
    Achieved Active Warps Per SM           warp        23.53
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564806 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 608.926 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 608.985 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564806
[564806] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.63
    SM Frequency            cycle/usecond       774.50
    Elapsed Cycles                  cycle        4,931
    Memory Throughput                   %         1.57
    DRAM Throughput                     %         0.62
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %        13.59
    L2 Cache Throughput                 %         1.36
    SM Active Cycles                cycle       560.70
    Compute (SM) Throughput             %         3.48
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        60.41
    Achieved Active Warps Per SM           warp        19.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 39.59%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (60.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564849 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 551.424 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 551.479 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 564849
[564849] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.62
    SM Frequency            cycle/usecond       783.51
    Elapsed Cycles                  cycle        5,142
    Memory Throughput                   %         2.77
    DRAM Throughput                     %         0.60
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        22.67
    L2 Cache Throughput                 %         1.30
    SM Active Cycles                cycle       622.03
    Compute (SM) Throughput             %         3.96
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            5.20
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        72.68
    Achieved Active Warps Per SM           warp        23.26
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 27.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564904 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87591e-17
GPU Step==nostream 3000, Center temp: 2.26882e-13
GPU Step==nostream 4000, Center temp: 5.8383e-11
GPU Step==nostream 5000, Center temp: 3.18099e-09
GPU Step==nostream 6000, Center temp: 6.65149e-08
GPU Step==nostream 7000, Center temp: 7.31597e-07
GPU Step==nostream 8000, Center temp: 5.10135e-06
GPU Step==nostream 9000, Center temp: 2.5404e-05
GPU: Temperature at center: 9.77818e-05
GPU Execution Time: 658.35 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 658.392 ms
GPU: Temperature at center: 9.77818e-05
==PROF== Disconnected from process 564904
[564904] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       914.76
    Elapsed Cycles                  cycle        3,424
    Memory Throughput                   %         2.27
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.68
    L1/TEX Cache Throughput             %        18.87
    L2 Cache Throughput                 %         1.66
    SM Active Cycles                cycle       404.83
    Compute (SM) Throughput             %         2.73
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        67.54
    Achieved Active Warps Per SM           warp        21.61
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 32.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (67.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=8, y=128
Block size: 8 x 128
==PROF== Connected to process 564954 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 8x128
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87591e-17
GPU Step==nostream 3000, Center temp: 2.26882e-13
GPU Step==nostream 4000, Center temp: 5.8383e-11
GPU Step==nostream 5000, Center temp: 3.18099e-09
GPU Step==nostream 6000, Center temp: 6.6515e-08
GPU Step==nostream 7000, Center temp: 7.31601e-07
GPU Step==nostream 8000, Center temp: 5.10147e-06
GPU Step==nostream 9000, Center temp: 2.54057e-05
GPU: Temperature at center: 9.77956e-05
GPU Execution Time: 602.956 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 602.999 ms
GPU: Temperature at center: 9.77956e-05
==PROF== Disconnected from process 564954
[564954] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (7, 1, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.52
    SM Frequency            cycle/usecond       890.31
    Elapsed Cycles                  cycle        3,382
    Memory Throughput                   %         2.30
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.74
    L1/TEX Cache Throughput             %        18.96
    L2 Cache Throughput                 %         1.70
    SM Active Cycles                cycle       404.10
    Compute (SM) Throughput             %         2.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        67.71
    Achieved Active Warps Per SM           warp        21.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 32.29%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (67.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 564996 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 548.857 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 548.926 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 564996
[564996] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.70
    SM Frequency            cycle/usecond       778.58
    Elapsed Cycles                  cycle        4,833
    Memory Throughput                   %         7.20
    DRAM Throughput                     %         0.70
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         9.27
    L2 Cache Throughput                 %         7.20
    SM Active Cycles                cycle     2,974.90
    Compute (SM) Throughput             %         7.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.37
    Achieved Active Warps Per SM           warp         5.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.26%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.4%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 565038 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 585.928 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 585.987 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565038
[565038] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       795.32
    Elapsed Cycles                  cycle        5,010
    Memory Throughput                   %         7.66
    DRAM Throughput                     %         0.74
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %        11.19
    L2 Cache Throughput                 %         7.66
    SM Active Cycles                cycle     3,121.07
    Compute (SM) Throughput             %         8.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             216
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.61
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 66.78%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 565080 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 603.576 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 603.619 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565080
[565080] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       786.32
    Elapsed Cycles                  cycle        4,887
    Memory Throughput                   %         7.09
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         9.60
    L2 Cache Throughput                 %         7.09
    SM Active Cycles                cycle        2,760
    Compute (SM) Throughput             %         6.02
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        16.83
    Achieved Active Warps Per SM           warp         5.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 66.34%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (16.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 565135 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 629.58 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 629.628 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565135
[565135] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.03
    SM Frequency            cycle/usecond       826.52
    Elapsed Cycles                  cycle        4,958
    Memory Throughput                   %         6.96
    DRAM Throughput                     %         0.65
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %        10.78
    L2 Cache Throughput                 %         6.96
    SM Active Cycles                cycle     2,762.47
    Compute (SM) Throughput             %         6.80
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             216
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block          128
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        17.18
    Achieved Active Warps Per SM           warp         5.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 65.65%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (17.2%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 565185 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83951e-11
GPU Step==nostream 5000, Center temp: 3.18289e-09
GPU Step==nostream 6000, Center temp: 6.65984e-08
GPU Step==nostream 7000, Center temp: 7.33185e-07
GPU Step==nostream 8000, Center temp: 5.11818e-06
GPU Step==nostream 9000, Center temp: 2.55205e-05
GPU: Temperature at center: 9.83669e-05
GPU Execution Time: 585.872 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 585.916 ms
GPU: Temperature at center: 9.83669e-05
==PROF== Disconnected from process 565185
[565185] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.44
    SM Frequency            cycle/usecond       882.25
    Elapsed Cycles                  cycle        3,586
    Memory Throughput                   %         9.58
    DRAM Throughput                     %         0.90
    Duration                      usecond            4
    L1/TEX Cache Throughput             %        12.66
    L2 Cache Throughput                 %         9.58
    SM Active Cycles                cycle     1,869.33
    Compute (SM) Throughput             %         3.40
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        18.64
    Achieved Active Warps Per SM           warp         5.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.72%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (18.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=1
Block size: 16 x 1
==PROF== Connected to process 565227 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83951e-11
GPU Step==nostream 5000, Center temp: 3.18289e-09
GPU Step==nostream 6000, Center temp: 6.65984e-08
GPU Step==nostream 7000, Center temp: 7.33184e-07
GPU Step==nostream 8000, Center temp: 5.11816e-06
GPU Step==nostream 9000, Center temp: 2.55203e-05
GPU: Temperature at center: 9.83658e-05
GPU Execution Time: 544.566 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 544.609 ms
GPU: Temperature at center: 9.83658e-05
==PROF== Disconnected from process 565227
[565227] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 50, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.37
    SM Frequency            cycle/usecond       877.94
    Elapsed Cycles                  cycle        3,538
    Memory Throughput                   %         9.67
    DRAM Throughput                     %         0.92
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %        12.89
    L2 Cache Throughput                 %         9.67
    SM Active Cycles                cycle     1,846.43
    Compute (SM) Throughput             %         3.45
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    200
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        18.62
    Achieved Active Warps Per SM           warp         5.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.76%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (18.6%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565269 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.804 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 543.851 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565269
[565269] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.73
    SM Frequency            cycle/usecond       792.50
    Elapsed Cycles                  cycle        4,837
    Memory Throughput                   %         4.60
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %         5.62
    L2 Cache Throughput                 %         4.60
    SM Active Cycles                cycle        2,895
    Compute (SM) Throughput             %         3.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.45
    Achieved Active Warps Per SM           warp         2.70
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.11%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.4%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565311 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 632.37 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 632.412 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565311
[565311] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       766.00
    Elapsed Cycles                  cycle        4,766
    Memory Throughput                   %         4.88
    DRAM Throughput                     %         0.79
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         6.90
    L2 Cache Throughput                 %         4.88
    SM Active Cycles                cycle     2,969.43
    Compute (SM) Throughput             %         4.51
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             288
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.53
    Achieved Active Warps Per SM           warp         2.73
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.95%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.5%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565366 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 619.453 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 619.512 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565366
[565366] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       752.71
    Elapsed Cycles                  cycle        4,590
    Memory Throughput                   %         4.94
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %         5.94
    L2 Cache Throughput                 %         4.94
    SM Active Cycles                cycle     2,471.47
    Compute (SM) Throughput             %         3.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.78
    Achieved Active Warps Per SM           warp         2.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.44%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.8%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565416 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 573.494 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 573.543 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565416
[565416] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.62
    SM Frequency            cycle/usecond       776.13
    Elapsed Cycles                  cycle        4,607
    Memory Throughput                   %         4.84
    DRAM Throughput                     %         0.66
    Duration                      usecond         5.86
    L1/TEX Cache Throughput             %         6.78
    L2 Cache Throughput                 %         4.84
    SM Active Cycles                cycle     2,528.83
    Compute (SM) Throughput             %         3.82
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             288
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.89
    Achieved Active Warps Per SM           warp         2.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.21%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.9%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565472 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.407 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 549.456 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565472
[565472] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       897.75
    Elapsed Cycles                  cycle        3,641
    Memory Throughput                   %         6.12
    DRAM Throughput                     %         0.88
    Duration                      usecond            4
    L1/TEX Cache Throughput             %         8.16
    L2 Cache Throughput                 %         6.12
    SM Active Cycles                cycle     1,646.57
    Compute (SM) Throughput             %         1.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.67
    Achieved Active Warps Per SM           warp         3.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.66%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=2
Block size: 16 x 2
==PROF== Connected to process 565516 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 560.454 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 560.508 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565516
[565516] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 25, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.81
    SM Frequency            cycle/usecond       923.53
    Elapsed Cycles                  cycle        3,761
    Memory Throughput                   %         5.94
    DRAM Throughput                     %         0.84
    Duration                      usecond         4.03
    L1/TEX Cache Throughput             %         8.07
    L2 Cache Throughput                 %         5.94
    SM Active Cycles                cycle     1,648.97
    Compute (SM) Throughput             %         1.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.68
    Achieved Active Warps Per SM           warp         3.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.64%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565558 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.669 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 546.713 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565558
[565558] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       785.00
    Elapsed Cycles                  cycle        4,753
    Memory Throughput                   %         3.58
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         4.62
    L2 Cache Throughput                 %         3.58
    SM Active Cycles                cycle     2,532.97
    Compute (SM) Throughput             %         3.87
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.71
    Achieved Active Warps Per SM           warp         3.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.29%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565613 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.231 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 540.278 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565613
[565613] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       766.19
    Elapsed Cycles                  cycle        4,623
    Memory Throughput                   %         3.74
    DRAM Throughput                     %         0.81
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         5.43
    L2 Cache Throughput                 %         3.74
    SM Active Cycles                cycle     2,536.33
    Compute (SM) Throughput             %         4.70
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             432
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.83
    Achieved Active Warps Per SM           warp         3.15
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565663 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 563.319 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 563.368 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565663
[565663] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.45
    SM Frequency            cycle/usecond       752.18
    Elapsed Cycles                  cycle        4,537
    Memory Throughput                   %         3.65
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         4.83
    L2 Cache Throughput                 %         3.65
    SM Active Cycles                cycle     2,263.60
    Compute (SM) Throughput             %         3.36
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.79
    Achieved Active Warps Per SM           warp         3.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565705 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 542.758 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 542.799 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565705
[565705] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       781.13
    Elapsed Cycles                  cycle        4,516
    Memory Throughput                   %         3.64
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.70
    L1/TEX Cache Throughput             %         5.97
    L2 Cache Throughput                 %         3.64
    SM Active Cycles                cycle     2,230.63
    Compute (SM) Throughput             %         3.94
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             432
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.97
    Achieved Active Warps Per SM           warp         3.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565747 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.665 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 547.725 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565747
[565747] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       928.82
    Elapsed Cycles                  cycle        3,620
    Memory Throughput                   %         4.73
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %         6.70
    L2 Cache Throughput                 %         4.73
    SM Active Cycles                cycle     1,613.03
    Compute (SM) Throughput             %         1.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.98
    Achieved Active Warps Per SM           warp         3.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.02%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=4
Block size: 16 x 4
==PROF== Connected to process 565789 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 573.981 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 574.026 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565789
[565789] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 13, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.24
    SM Frequency            cycle/usecond       862.02
    Elapsed Cycles                  cycle        3,647
    Memory Throughput                   %         4.87
    DRAM Throughput                     %         0.88
    Duration                      usecond         4.16
    L1/TEX Cache Throughput             %         6.69
    L2 Cache Throughput                 %         4.87
    SM Active Cycles                cycle     1,615.77
    Compute (SM) Throughput             %         1.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     52
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.99
    Achieved Active Warps Per SM           warp         3.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 565842 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 563.317 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 563.36 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565842
[565842] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       779.36
    Elapsed Cycles                  cycle        4,724
    Memory Throughput                   %         3.13
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %         4.58
    L2 Cache Throughput                 %         3.13
    SM Active Cycles                cycle     2,286.30
    Compute (SM) Throughput             %         3.93
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.97
    Achieved Active Warps Per SM           warp         3.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 565891 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 542.431 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 542.472 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565891
[565891] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       772.29
    Elapsed Cycles                  cycle        4,640
    Memory Throughput                   %         3.10
    DRAM Throughput                     %         0.80
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         6.28
    L2 Cache Throughput                 %         2.47
    SM Active Cycles                cycle     2,272.47
    Compute (SM) Throughput             %         4.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             720
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.76
    Achieved Active Warps Per SM           warp         3.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 565934 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.83 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 547.879 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565934
[565934] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.42
    SM Frequency            cycle/usecond       747.26
    Elapsed Cycles                  cycle        4,505
    Memory Throughput                   %         3.14
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         4.94
    L2 Cache Throughput                 %         3.14
    SM Active Cycles                cycle     2,115.97
    Compute (SM) Throughput             %         3.45
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.01
    Achieved Active Warps Per SM           warp         3.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.99%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 565976 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 597.782 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 597.823 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 565976
[565976] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       771.82
    Elapsed Cycles                  cycle        4,483
    Memory Throughput                   %         3.05
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.73
    L1/TEX Cache Throughput             %         6.75
    L2 Cache Throughput                 %         2.63
    SM Active Cycles                cycle     1,994.43
    Compute (SM) Throughput             %         4.04
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             720
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.53
    Achieved Active Warps Per SM           warp         3.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 566018 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 549.677 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 549.72 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566018
[566018] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       922.05
    Elapsed Cycles                  cycle        3,592
    Memory Throughput                   %         4.44
    DRAM Throughput                     %         0.90
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %         6.85
    L2 Cache Throughput                 %         4.44
    SM Active Cycles                cycle     1,528.40
    Compute (SM) Throughput             %         1.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.77
    Achieved Active Warps Per SM           warp         3.45
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=8
Block size: 16 x 8
==PROF== Connected to process 566060 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 587.098 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 587.145 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566060
[566060] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 7, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         7.26
    SM Frequency            cycle/usecond       997.37
    Elapsed Cycles                  cycle        3,841
    Memory Throughput                   %         4.10
    DRAM Throughput                     %         0.83
    Duration                      usecond         3.81
    L1/TEX Cache Throughput             %         6.79
    L2 Cache Throughput                 %         4.10
    SM Active Cycles                cycle     1,542.03
    Compute (SM) Throughput             %         1.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     28
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 6.667%                                                                                          
          The grid for this launch is configured to execute only 28 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.83
    Achieved Active Warps Per SM           warp         3.46
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566115 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 552.318 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 552.368 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566115
[566115] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       755.76
    Elapsed Cycles                  cycle        4,638
    Memory Throughput                   %         2.46
    DRAM Throughput                     %         0.69
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %         7.81
    L2 Cache Throughput                 %         2.46
    SM Active Cycles                cycle     1,340.70
    Compute (SM) Throughput             %         4.08
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.95
    Achieved Active Warps Per SM           warp         6.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.05%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566179 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 562.452 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 562.493 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566179
[566179] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       764.27
    Elapsed Cycles                  cycle        4,733
    Memory Throughput                   %         3.33
    DRAM Throughput                     %         0.79
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %        11.63
    L2 Cache Throughput                 %         1.87
    SM Active Cycles                cycle     1,343.50
    Compute (SM) Throughput             %         4.88
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.30
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.15
    Achieved Active Warps Per SM           warp         7.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.85%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566221 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 552.478 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 552.52 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566221
[566221] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.33
    SM Frequency            cycle/usecond       740.65
    Elapsed Cycles                  cycle        4,465
    Memory Throughput                   %         2.48
    DRAM Throughput                     %         0.69
    Duration                      usecond         5.95
    L1/TEX Cache Throughput             %         8.53
    L2 Cache Throughput                 %         2.48
    SM Active Cycles                cycle     1,223.67
    Compute (SM) Throughput             %         3.60
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.70
    Achieved Active Warps Per SM           warp         6.30
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.3%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566266 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 602.465 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 602.514 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566266
[566266] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.51
    SM Frequency            cycle/usecond       754.22
    Elapsed Cycles                  cycle        4,519
    Memory Throughput                   %         3.08
    DRAM Throughput                     %         0.68
    Duration                      usecond         5.92
    L1/TEX Cache Throughput             %        11.06
    L2 Cache Throughput                 %         2.14
    SM Active Cycles                cycle     1,244.53
    Compute (SM) Throughput             %         4.14
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.30
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.44
    Achieved Active Warps Per SM           warp         6.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.56%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566308 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 597.629 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 597.725 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566308
[566308] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.49
    SM Frequency            cycle/usecond       894.70
    Elapsed Cycles                  cycle        3,482
    Memory Throughput                   %         3.12
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %        11.54
    L2 Cache Throughput                 %         3.12
    SM Active Cycles                cycle       907.17
    Compute (SM) Throughput             %         2.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.87
    Achieved Active Warps Per SM           warp         6.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.13%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=16
Block size: 16 x 16
==PROF== Connected to process 566363 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.582 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 543.623 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566363
[566363] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 4, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.49
    SM Frequency            cycle/usecond       895.57
    Elapsed Cycles                  cycle        3,500
    Memory Throughput                   %         3.16
    DRAM Throughput                     %         0.93
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %        11.33
    L2 Cache Throughput                 %         3.16
    SM Active Cycles                cycle       924.10
    Compute (SM) Throughput             %         2.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 46.67%                                                                                          
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.60
    Achieved Active Warps Per SM           warp         6.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.4%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566413 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 577.471 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 577.518 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566413
[566413] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       770.05
    Elapsed Cycles                  cycle        5,017
    Memory Throughput                   %         2.12
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %        14.26
    L2 Cache Throughput                 %         1.79
    SM Active Cycles                cycle       731.47
    Compute (SM) Throughput             %         3.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        39.65
    Achieved Active Warps Per SM           warp        12.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 60.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (39.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566455 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 569.121 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 569.166 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566455
[566455] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       777.89
    Elapsed Cycles                  cycle        5,321
    Memory Throughput                   %         2.98
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.75
    L1/TEX Cache Throughput             %        19.93
    L2 Cache Throughput                 %         1.71
    SM Active Cycles                cycle       783.93
    Compute (SM) Throughput             %         4.35
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.45
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           12
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        42.74
    Achieved Active Warps Per SM           warp        13.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 57.26%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (42.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566497 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 579.173 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 579.216 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566497
[566497] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.64
    SM Frequency            cycle/usecond       774.09
    Elapsed Cycles                  cycle        4,809
    Memory Throughput                   %         2.18
    DRAM Throughput                     %         0.62
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %        15.55
    L2 Cache Throughput                 %         1.95
    SM Active Cycles                cycle       665.73
    Compute (SM) Throughput             %         3.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.86
    Achieved Active Warps Per SM           warp        12.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.14%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566539 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 586.242 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 586.296 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566539
[566539] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.75
    SM Frequency            cycle/usecond       792.53
    Elapsed Cycles                  cycle        4,928
    Memory Throughput                   %         2.83
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %        19.23
    L2 Cache Throughput                 %         1.82
    SM Active Cycles                cycle       715.37
    Compute (SM) Throughput             %         3.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.45
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           12
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.62
    Achieved Active Warps Per SM           warp        13.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.38%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566594 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 548.917 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 548.963 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566594
[566594] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.40
    SM Frequency            cycle/usecond       884.90
    Elapsed Cycles                  cycle        3,450
    Memory Throughput                   %         3.09
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.84
    L1/TEX Cache Throughput             %        21.91
    L2 Cache Throughput                 %         2.53
    SM Active Cycles                cycle       480.03
    Compute (SM) Throughput             %         2.04
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        40.79
    Achieved Active Warps Per SM           warp        13.05
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 59.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (40.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=32
Block size: 16 x 32
==PROF== Connected to process 566644 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 590.861 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 590.906 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566644
[566644] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 2, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.55
    SM Frequency            cycle/usecond       904.66
    Elapsed Cycles                  cycle        3,468
    Memory Throughput                   %         3.07
    DRAM Throughput                     %         0.94
    Duration                      usecond         3.78
    L1/TEX Cache Throughput             %        20.91
    L2 Cache Throughput                 %         2.66
    SM Active Cycles                cycle       502.13
    Compute (SM) Throughput             %         2.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.20
    Achieved Active Warps Per SM           warp        13.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566686 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 541.749 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 541.79 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566686
[566686] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       806.47
    Elapsed Cycles                  cycle        5,762
    Memory Throughput                   %         1.84
    DRAM Throughput                     %         0.56
    Duration                      usecond         7.07
    L1/TEX Cache Throughput             %        24.34
    L2 Cache Throughput                 %         1.56
    SM Active Cycles                cycle       430.77
    Compute (SM) Throughput             %         3.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        76.08
    Achieved Active Warps Per SM           warp        24.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 23.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (76.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566728 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 580.407 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 580.451 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566728
[566728] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.81
    SM Frequency            cycle/usecond       800.98
    Elapsed Cycles                  cycle        6,369
    Memory Throughput                   %         2.49
    DRAM Throughput                     %         0.51
    Duration                      usecond         7.84
    L1/TEX Cache Throughput             %        29.06
    L2 Cache Throughput                 %         1.31
    SM Active Cycles                cycle       537.70
    Compute (SM) Throughput             %         3.62
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.75
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        83.54
    Achieved Active Warps Per SM           warp        26.73
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 16.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566770 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 564.93 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 564.987 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566770
[566770] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.96
    SM Frequency            cycle/usecond       819.13
    Elapsed Cycles                  cycle        5,609
    Memory Throughput                   %         1.95
    DRAM Throughput                     %         0.55
    Duration                      usecond         6.78
    L1/TEX Cache Throughput             %        25.90
    L2 Cache Throughput                 %         1.35
    SM Active Cycles                cycle       417.57
    Compute (SM) Throughput             %         2.82
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.65
    Achieved Active Warps Per SM           warp        23.57
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566827 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 551.038 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 551.082 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566827
[566827] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond            6
    SM Frequency            cycle/usecond       825.67
    Elapsed Cycles                  cycle        5,765
    Memory Throughput                   %         2.41
    DRAM Throughput                     %         0.56
    Duration                      usecond         6.91
    L1/TEX Cache Throughput             %        30.40
    L2 Cache Throughput                 %         1.24
    SM Active Cycles                cycle       452.70
    Compute (SM) Throughput             %         3.21
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.75
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        80.79
    Achieved Active Warps Per SM           warp        25.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 19.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566877 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 571.278 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 571.319 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566877
[566877] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       915.90
    Elapsed Cycles                  cycle        4,037
    Memory Throughput                   %         2.72
    DRAM Throughput                     %         0.81
    Duration                      usecond         4.35
    L1/TEX Cache Throughput             %        34.27
    L2 Cache Throughput                 %         1.94
    SM Active Cycles                cycle       316.60
    Compute (SM) Throughput             %         1.73
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        76.57
    Achieved Active Warps Per SM           warp        24.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 23.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (76.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=16, y=64
Block size: 16 x 64
==PROF== Connected to process 566919 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 16x64
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 565.068 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 565.114 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 566919
[566919] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (4, 1, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       925.09
    Elapsed Cycles                  cycle        4,082
    Memory Throughput                   %         2.69
    DRAM Throughput                     %         0.79
    Duration                      usecond         4.35
    L1/TEX Cache Throughput             %        33.99
    L2 Cache Throughput                 %         1.96
    SM Active Cycles                cycle       319.07
    Compute (SM) Throughput             %         1.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        76.62
    Achieved Active Warps Per SM           warp        24.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 23.38%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (76.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 566961 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 549.81 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 549.865 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 566961
[566961] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.47
    SM Frequency            cycle/usecond       753.00
    Elapsed Cycles                  cycle        4,830
    Memory Throughput                   %         7.55
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %         9.73
    L2 Cache Throughput                 %         7.55
    SM Active Cycles                cycle     3,146.50
    Compute (SM) Throughput             %         4.41
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.89
    Achieved Active Warps Per SM           warp         2.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.22%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.9%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 567003 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 590.293 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 590.35 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567003
[567003] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       766.24
    Elapsed Cycles                  cycle        5,010
    Memory Throughput                   %         7.96
    DRAM Throughput                     %         0.75
    Duration                      usecond         6.46
    L1/TEX Cache Throughput             %        10.30
    L2 Cache Throughput                 %         7.96
    SM Active Cycles                cycle     3,280.87
    Compute (SM) Throughput             %         4.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             408
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.61
    Achieved Active Warps Per SM           warp         2.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.77%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.6%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 567045 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84812e-05
GPU Execution Time: 570.301 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 570.353 ms
GPU: Temperature at center: 9.84812e-05
==PROF== Disconnected from process 567045
[567045] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       777.67
    Elapsed Cycles                  cycle        4,910
    Memory Throughput                   %         7.54
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.24
    L1/TEX Cache Throughput             %         9.57
    L2 Cache Throughput                 %         7.54
    SM Active Cycles                cycle     2,883.67
    Compute (SM) Throughput             %         3.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         8.73
    Achieved Active Warps Per SM           warp         2.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.53%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (8.7%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 567100 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 563.13 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 563.178 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567100
[567100] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       784.74
    Elapsed Cycles                  cycle        4,788
    Memory Throughput                   %         7.35
    DRAM Throughput                     %         0.68
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %         9.72
    L2 Cache Throughput                 %         7.35
    SM Active Cycles                cycle     2,720.90
    Compute (SM) Throughput             %         4.23
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             408
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           64
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.13
    Achieved Active Warps Per SM           warp         2.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.73%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.1%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM.                                                                                            

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 567150 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 581.391 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 581.437 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567150
[567150] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       904.87
    Elapsed Cycles                  cycle        3,757
    Memory Throughput                   %         9.64
    DRAM Throughput                     %         0.87
    Duration                      usecond         4.10
    L1/TEX Cache Throughput             %        12.56
    L2 Cache Throughput                 %         9.64
    SM Active Cycles                cycle     2,034.17
    Compute (SM) Throughput             %         1.71
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.28
    Achieved Active Warps Per SM           warp         2.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.43%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=1
Block size: 32 x 1
==PROF== Connected to process 567193 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 543.914 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 543.984 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567193
[567193] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 50, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.52
    SM Frequency            cycle/usecond       889.58
    Elapsed Cycles                  cycle        3,740
    Memory Throughput                   %         9.69
    DRAM Throughput                     %         0.85
    Duration                      usecond         4.16
    L1/TEX Cache Throughput             %        12.62
    L2 Cache Throughput                 %         9.69
    SM Active Cycles                cycle     2,011.50
    Compute (SM) Throughput             %         1.71
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    100
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           64
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         9.29
    Achieved Active Warps Per SM           warp         2.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 81.42%                                                                                    
          The difference between calculated theoretical (50.0%) and measured achieved occupancy (9.3%) can be the       
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567235 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 590.132 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 590.176 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567235
[567235] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.60
    SM Frequency            cycle/usecond       770.25
    Elapsed Cycles                  cycle        4,929
    Memory Throughput                   %         6.27
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.30
    L1/TEX Cache Throughput             %         7.84
    L2 Cache Throughput                 %         6.27
    SM Active Cycles                cycle     2,825.97
    Compute (SM) Throughput             %         4.33
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.97
    Achieved Active Warps Per SM           warp         3.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567277 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.846 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 543.892 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567277
[567277] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       782.99
    Elapsed Cycles                  cycle        5,026
    Memory Throughput                   %         6.22
    DRAM Throughput                     %         0.74
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %         9.42
    L2 Cache Throughput                 %         6.22
    SM Active Cycles                cycle     2,764.03
    Compute (SM) Throughput             %         4.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             544
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.06
    Achieved Active Warps Per SM           warp         3.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.94%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567332 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12004e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84805e-05
GPU Execution Time: 540.793 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 540.844 ms
GPU: Temperature at center: 9.84805e-05
==PROF== Disconnected from process 567332
[567332] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.58
    SM Frequency            cycle/usecond       765.60
    Elapsed Cycles                  cycle        4,754
    Memory Throughput                   %         6.27
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %         7.98
    L2 Cache Throughput                 %         6.27
    SM Active Cycles                cycle     2,547.20
    Compute (SM) Throughput             %         3.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.77
    Achieved Active Warps Per SM           warp         3.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567382 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 581.911 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 581.975 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567382
[567382] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.79
    SM Frequency            cycle/usecond       797.52
    Elapsed Cycles                  cycle        4,837
    Memory Throughput                   %         5.99
    DRAM Throughput                     %         0.67
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %         9.38
    L2 Cache Throughput                 %         5.99
    SM Active Cycles                cycle     2,479.13
    Compute (SM) Throughput             %         4.18
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             544
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           42
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.92
    Achieved Active Warps Per SM           warp         3.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567424 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 583.546 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 583.588 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567424
[567424] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.33
    SM Frequency            cycle/usecond       869.75
    Elapsed Cycles                  cycle        3,632
    Memory Throughput                   %         8.41
    DRAM Throughput                     %         0.89
    Duration                      usecond         4.13
    L1/TEX Cache Throughput             %        10.74
    L2 Cache Throughput                 %         8.41
    SM Active Cycles                cycle     1,849.67
    Compute (SM) Throughput             %         1.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.94
    Achieved Active Warps Per SM           warp         3.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.9%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=2
Block size: 32 x 2
==PROF== Connected to process 567466 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 606.041 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 606.088 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567466
[567466] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 25, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.44
    SM Frequency            cycle/usecond       886.83
    Elapsed Cycles                  cycle        3,590
    Memory Throughput                   %         8.57
    DRAM Throughput                     %         0.90
    Duration                      usecond            4
    L1/TEX Cache Throughput             %        11.05
    L2 Cache Throughput                 %         8.57
    SM Active Cycles                cycle     1,848.43
    Compute (SM) Throughput             %         1.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.95
    Achieved Active Warps Per SM           warp         3.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.05%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567508 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 548.181 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 548.224 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567508
[567508] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.39
    SM Frequency            cycle/usecond       743.71
    Elapsed Cycles                  cycle        4,751
    Memory Throughput                   %         5.92
    DRAM Throughput                     %         0.68
    Duration                      usecond         6.30
    L1/TEX Cache Throughput             %         7.64
    L2 Cache Throughput                 %         5.92
    SM Active Cycles                cycle        2,437
    Compute (SM) Throughput             %         4.51
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.50
    Achieved Active Warps Per SM           warp         3.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567563 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 570.589 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 570.638 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567563
[567563] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.57
    SM Frequency            cycle/usecond       765.44
    Elapsed Cycles                  cycle        4,935
    Memory Throughput                   %         5.21
    DRAM Throughput                     %         0.76
    Duration                      usecond         6.37
    L1/TEX Cache Throughput             %         7.51
    L2 Cache Throughput                 %         5.21
    SM Active Cycles                cycle     2,395.80
    Compute (SM) Throughput             %         5.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             816
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.84
    Achieved Active Warps Per SM           warp         3.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.16%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567613 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12004e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84805e-05
GPU Execution Time: 537.965 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 538.017 ms
GPU: Temperature at center: 9.84805e-05
==PROF== Disconnected from process 567613
[567613] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.50
    SM Frequency            cycle/usecond       754.67
    Elapsed Cycles                  cycle        4,678
    Memory Throughput                   %         5.97
    DRAM Throughput                     %         0.69
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         8.91
    L2 Cache Throughput                 %         5.97
    SM Active Cycles                cycle     2,166.70
    Compute (SM) Throughput             %         3.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.36
    Achieved Active Warps Per SM           warp         3.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567655 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 619.201 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 619.263 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567655
[567655] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.56
    SM Frequency            cycle/usecond       763.43
    Elapsed Cycles                  cycle        4,713
    Memory Throughput                   %         5.27
    DRAM Throughput                     %         0.69
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %         8.23
    L2 Cache Throughput                 %         5.27
    SM Active Cycles                cycle     2,124.53
    Compute (SM) Throughput             %         4.33
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             816
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.75
    Achieved Active Warps Per SM           warp         3.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.25%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567697 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 537.027 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 537.087 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567697
[567697] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       892.62
    Elapsed Cycles                  cycle        3,561
    Memory Throughput                   %         7.98
    DRAM Throughput                     %         0.91
    Duration                      usecond         3.94
    L1/TEX Cache Throughput             %        11.50
    L2 Cache Throughput                 %         7.98
    SM Active Cycles                cycle     1,595.73
    Compute (SM) Throughput             %         1.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.41
    Achieved Active Warps Per SM           warp         3.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.59%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=4
Block size: 32 x 4
==PROF== Connected to process 567739 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 582.733 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 582.774 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567739
[567739] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 13, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.36
    SM Frequency            cycle/usecond       880.08
    Elapsed Cycles                  cycle        3,575
    Memory Throughput                   %         8.01
    DRAM Throughput                     %         0.91
    Duration                      usecond            4
    L1/TEX Cache Throughput             %        11.46
    L2 Cache Throughput                 %         8.01
    SM Active Cycles                cycle     1,602.67
    Compute (SM) Throughput             %         1.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     26
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 13.33%                                                                                          
          The grid for this launch is configured to execute only 26 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.43
    Achieved Active Warps Per SM           warp         3.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.57%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 567794 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 688.169 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 688.222 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567794
[567794] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       778.40
    Elapsed Cycles                  cycle        5,092
    Memory Throughput                   %         4.70
    DRAM Throughput                     %         0.64
    Duration                      usecond         6.43
    L1/TEX Cache Throughput             %        12.59
    L2 Cache Throughput                 %         4.70
    SM Active Cycles                cycle     1,394.57
    Compute (SM) Throughput             %         4.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.62
    Achieved Active Warps Per SM           warp         6.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.38%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 567844 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 559.402 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 559.445 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567844
[567844] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       776.48
    Elapsed Cycles                  cycle        5,333
    Memory Throughput                   %         4.22
    DRAM Throughput                     %         0.71
    Duration                      usecond         6.78
    L1/TEX Cache Throughput             %        12.41
    L2 Cache Throughput                 %         4.22
    SM Active Cycles                cycle     1,401.27
    Compute (SM) Throughput             %         4.75
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.55
    Achieved Active Warps Per SM           warp         7.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 567887 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33305e-07
GPU Step==nostream 8000, Center temp: 5.11998e-06
GPU Step==nostream 9000, Center temp: 2.55373e-05
GPU: Temperature at center: 9.84752e-05
GPU Execution Time: 551.416 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 551.463 ms
GPU: Temperature at center: 9.84752e-05
==PROF== Disconnected from process 567887
[567887] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       782.93
    Elapsed Cycles                  cycle        4,897
    Memory Throughput                   %         4.97
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %        14.14
    L2 Cache Throughput                 %         4.97
    SM Active Cycles                cycle     1,225.30
    Compute (SM) Throughput             %         3.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.40
    Achieved Active Warps Per SM           warp         6.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.6%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 567929 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.625 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 546.675 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 567929
[567929] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.58
    SM Frequency            cycle/usecond       770.83
    Elapsed Cycles                  cycle        4,812
    Memory Throughput                   %         4.41
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        13.33
    L2 Cache Throughput                 %         4.41
    SM Active Cycles                cycle        1,261
    Compute (SM) Throughput             %         4.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.36
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           21
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.37
    Achieved Active Warps Per SM           warp         7.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 567971 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 582.078 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 582.122 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 567971
[567971] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       884.84
    Elapsed Cycles                  cycle        3,650
    Memory Throughput                   %         6.29
    DRAM Throughput                     %         0.89
    Duration                      usecond         4.06
    L1/TEX Cache Throughput             %        18.54
    L2 Cache Throughput                 %         6.29
    SM Active Cycles                cycle       949.73
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.85
    Achieved Active Warps Per SM           warp         6.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.15%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=8
Block size: 32 x 8
==PROF== Connected to process 568024 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 543.157 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 543.234 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 568024
[568024] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 7, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       900.67
    Elapsed Cycles                  cycle        3,653
    Memory Throughput                   %         6.31
    DRAM Throughput                     %         0.89
    Duration                      usecond            4
    L1/TEX Cache Throughput             %        18.49
    L2 Cache Throughput                 %         6.31
    SM Active Cycles                cycle          953
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     14
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 53.33%                                                                                          
          The grid for this launch is configured to execute only 14 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.84
    Achieved Active Warps Per SM           warp         6.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.16%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568072 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 576.388 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 576.437 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568072
[568072] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       771.14
    Elapsed Cycles                  cycle        5,846
    Memory Throughput                   %         3.65
    DRAM Throughput                     %         0.55
    Duration                      usecond         7.49
    L1/TEX Cache Throughput             %        20.15
    L2 Cache Throughput                 %         3.65
    SM Active Cycles                cycle       879.93
    Compute (SM) Throughput             %         3.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        39.78
    Achieved Active Warps Per SM           warp        12.73
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 60.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (39.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568114 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 587.707 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 587.753 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568114
[568114] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.72
    SM Frequency            cycle/usecond       783.43
    Elapsed Cycles                  cycle        6,285
    Memory Throughput                   %         3.44
    DRAM Throughput                     %         0.59
    Duration                      usecond         7.94
    L1/TEX Cache Throughput             %        19.07
    L2 Cache Throughput                 %         3.44
    SM Active Cycles                cycle       929.03
    Compute (SM) Throughput             %         4.17
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.45
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           12
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        42.10
    Achieved Active Warps Per SM           warp        13.47
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 57.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (42.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568157 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.177 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 553.231 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568157
[568157] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       805.16
    Elapsed Cycles                  cycle        5,306
    Memory Throughput                   %         4.10
    DRAM Throughput                     %         0.61
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        22.95
    L2 Cache Throughput                 %         4.10
    SM Active Cycles                cycle       774.43
    Compute (SM) Throughput             %         3.48
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        39.74
    Achieved Active Warps Per SM           warp        12.72
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 60.26%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (39.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568199 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 547.24 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 547.293 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568199
[568199] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.88
    SM Frequency            cycle/usecond       806.76
    Elapsed Cycles                  cycle        5,583
    Memory Throughput                   %         3.70
    DRAM Throughput                     %         0.58
    Duration                      usecond         6.85
    L1/TEX Cache Throughput             %        19.92
    L2 Cache Throughput                 %         3.70
    SM Active Cycles                cycle       839.20
    Compute (SM) Throughput             %         3.78
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.45
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           12
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.89
    Achieved Active Warps Per SM           warp        13.41
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.11%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568241 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84815e-05
GPU Execution Time: 595.544 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 595.587 ms
GPU: Temperature at center: 9.84815e-05
==PROF== Disconnected from process 568241
[568241] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       908.80
    Elapsed Cycles                  cycle        4,549
    Memory Throughput                   %         4.72
    DRAM Throughput                     %         0.71
    Duration                      usecond         4.96
    L1/TEX Cache Throughput             %        28.22
    L2 Cache Throughput                 %         4.72
    SM Active Cycles                cycle       646.03
    Compute (SM) Throughput             %         1.57
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.36
    Achieved Active Warps Per SM           warp        13.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=16
Block size: 32 x 16
==PROF== Connected to process 568296 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 629.462 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 629.513 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568296
[568296] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 4, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       907.45
    Elapsed Cycles                  cycle        4,557
    Memory Throughput                   %         4.72
    DRAM Throughput                     %         0.70
    Duration                      usecond         4.99
    L1/TEX Cache Throughput             %        28.26
    L2 Cache Throughput                 %         4.72
    SM Active Cycles                cycle       646.43
    Compute (SM) Throughput             %         1.57
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      8
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 73.33%                                                                                          
          The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.43
    Achieved Active Warps Per SM           warp        13.26
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.57%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568346 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.5534e-05
GPU: Temperature at center: 9.84554e-05
GPU Execution Time: 556.153 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 556.199 ms
GPU: Temperature at center: 9.84554e-05
==PROF== Disconnected from process 568346
[568346] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.11
    SM Frequency            cycle/usecond       840.36
    Elapsed Cycles                  cycle        7,622
    Memory Throughput                   %         2.51
    DRAM Throughput                     %         0.43
    Duration                      usecond         8.96
    L1/TEX Cache Throughput             %        31.59
    L2 Cache Throughput                 %         2.51
    SM Active Cycles                cycle       568.77
    Compute (SM) Throughput             %         2.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        74.67
    Achieved Active Warps Per SM           warp        23.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.33%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (74.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568388 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 583 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 583.042 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568388
[568388] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.21
    SM Frequency            cycle/usecond       862.21
    Elapsed Cycles                  cycle        8,365
    Memory Throughput                   %         2.47
    DRAM Throughput                     %         0.43
    Duration                      usecond         9.57
    L1/TEX Cache Throughput             %        27.90
    L2 Cache Throughput                 %         2.47
    SM Active Cycles                cycle       631.10
    Compute (SM) Throughput             %         3.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.62
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        79.85
    Achieved Active Warps Per SM           warp        25.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 20.15%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (79.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568430 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 558.277 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 558.322 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568430
[568430] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.87
    SM Frequency            cycle/usecond       808.60
    Elapsed Cycles                  cycle        6,780
    Memory Throughput                   %         2.91
    DRAM Throughput                     %         0.48
    Duration                      usecond         8.29
    L1/TEX Cache Throughput             %        35.25
    L2 Cache Throughput                 %         2.91
    SM Active Cycles                cycle       513.80
    Compute (SM) Throughput             %         2.71
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        73.97
    Achieved Active Warps Per SM           warp        23.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 26.03%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (74.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568472 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 582.277 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 582.325 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568472
[568472] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.15
    SM Frequency            cycle/usecond       851.72
    Elapsed Cycles                  cycle        7,391
    Memory Throughput                   %         2.75
    DRAM Throughput                     %         0.44
    Duration                      usecond         8.58
    L1/TEX Cache Throughput             %        29.72
    L2 Cache Throughput                 %         2.75
    SM Active Cycles                cycle       556.17
    Compute (SM) Throughput             %         2.87
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.62
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        79.66
    Achieved Active Warps Per SM           warp        25.49
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 20.34%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (79.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568527 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.55339e-05
GPU: Temperature at center: 9.84553e-05
GPU Execution Time: 564.931 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 564.974 ms
GPU: Temperature at center: 9.84553e-05
==PROF== Disconnected from process 568527
[568527] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       920.99
    Elapsed Cycles                  cycle        6,502
    Memory Throughput                   %         3.15
    DRAM Throughput                     %         0.50
    Duration                      usecond         6.94
    L1/TEX Cache Throughput             %        39.15
    L2 Cache Throughput                 %         3.15
    SM Active Cycles                cycle       465.70
    Compute (SM) Throughput             %         1.11
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        75.27
    Achieved Active Warps Per SM           warp        24.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 24.73%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (75.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=32, y=32
Block size: 32 x 32
==PROF== Connected to process 568577 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 32x32
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.55339e-05
GPU: Temperature at center: 9.84553e-05
GPU Execution Time: 546.609 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 546.655 ms
GPU: Temperature at center: 9.84553e-05
==PROF== Disconnected from process 568577
[568577] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (2, 2, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.60
    SM Frequency            cycle/usecond       913.16
    Elapsed Cycles                  cycle        6,302
    Memory Throughput                   %         3.09
    DRAM Throughput                     %         0.52
    Duration                      usecond         6.85
    L1/TEX Cache Throughput             %        38.97
    L2 Cache Throughput                 %         3.09
    SM Active Cycles                cycle       465.53
    Compute (SM) Throughput             %         1.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        74.86
    Achieved Active Warps Per SM           warp        23.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 25.14%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (74.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568619 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 553.528 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 553.573 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 568619
[568619] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       789.54
    Elapsed Cycles                  cycle        5,138
    Memory Throughput                   %         7.07
    DRAM Throughput                     %         0.62
    Duration                      usecond         6.43
    L1/TEX Cache Throughput             %         9.21
    L2 Cache Throughput                 %         7.07
    SM Active Cycles                cycle     3,428.40
    Compute (SM) Throughput             %         4.14
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         8.67
    Achieved Active Warps Per SM           warp         2.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 91.33%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (8.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568661 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 648.384 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 648.437 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568661
[568661] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.70
    SM Frequency            cycle/usecond       783.05
    Elapsed Cycles                  cycle        5,144
    Memory Throughput                   %         7.66
    DRAM Throughput                     %         0.73
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        10.12
    L2 Cache Throughput                 %         7.66
    SM Active Cycles                cycle     3,398.83
    Compute (SM) Throughput             %         4.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             792
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         8.75
    Achieved Active Warps Per SM           warp         2.80
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 91.25%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (8.7%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568703 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.84809e-05
GPU Execution Time: 552.546 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 552.663 ms
GPU: Temperature at center: 9.84809e-05
==PROF== Disconnected from process 568703
[568703] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.76
    SM Frequency            cycle/usecond       789.51
    Elapsed Cycles                  cycle        5,065
    Memory Throughput                   %         7.27
    DRAM Throughput                     %         0.64
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %         9.55
    L2 Cache Throughput                 %         7.27
    SM Active Cycles                cycle     3,028.10
    Compute (SM) Throughput             %         3.57
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         8.85
    Achieved Active Warps Per SM           warp         2.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 91.15%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (8.8%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568758 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 594.741 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 594.783 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568758
[568758] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.78
    SM Frequency            cycle/usecond       797.67
    Elapsed Cycles                  cycle        4,940
    Memory Throughput                   %         7.14
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.11
    L1/TEX Cache Throughput             %         9.64
    L2 Cache Throughput                 %         7.14
    SM Active Cycles                cycle     2,934.37
    Compute (SM) Throughput             %         4.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block             792
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.14
    Achieved Active Warps Per SM           warp         2.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.86%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (9.1%) can be the      
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568808 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 547.834 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 547.884 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 568808
[568808] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         2.66
    SM Frequency            cycle/usecond       366.82
    Elapsed Cycles                  cycle        3,773
    Memory Throughput                   %         9.39
    DRAM Throughput                     %         0.86
    Duration                      usecond        10.14
    L1/TEX Cache Throughput             %        12.53
    L2 Cache Throughput                 %         9.39
    SM Active Cycles                cycle     2,045.87
    Compute (SM) Throughput             %         1.70
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.00
    Achieved Active Warps Per SM           warp         3.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90%                                                                                       
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=64, y=1
Block size: 64 x 1
==PROF== Connected to process 568851 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 64x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 570.694 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 570.737 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 568851
[568851] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       876.19
    Elapsed Cycles                  cycle        3,723
    Memory Throughput                   %         9.63
    DRAM Throughput                     %         0.86
    Duration                      usecond         4.19
    L1/TEX Cache Throughput             %        12.67
    L2 Cache Throughput                 %         9.63
    SM Active Cycles                cycle     2,040.93
    Compute (SM) Throughput             %         1.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           32
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         9.98
    Achieved Active Warps Per SM           warp         3.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 90.02%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 568893 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 553.733 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 553.778 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 568893
[568893] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       781.36
    Elapsed Cycles                  cycle        5,028
    Memory Throughput                   %         5.95
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %         7.58
    L2 Cache Throughput                 %         5.95
    SM Active Cycles                cycle     2,843.27
    Compute (SM) Throughput             %         4.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.42
    Achieved Active Warps Per SM           warp         3.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.58%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 568935 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 586.88 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 586.925 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 568935
[568935] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.71
    SM Frequency            cycle/usecond       784.17
    Elapsed Cycles                  cycle        5,079
    Memory Throughput                   %         6.22
    DRAM Throughput                     %         0.74
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %         9.18
    L2 Cache Throughput                 %         6.22
    SM Active Cycles                cycle     2,818.83
    Compute (SM) Throughput             %         4.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.06
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           25
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.35
    Achieved Active Warps Per SM           warp         3.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.65%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 568990 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84814e-05
GPU Execution Time: 571.979 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 572.023 ms
GPU: Temperature at center: 9.84814e-05
==PROF== Disconnected from process 568990
[568990] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       778.96
    Elapsed Cycles                  cycle        4,913
    Memory Throughput                   %         6.07
    DRAM Throughput                     %         0.65
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %         8.61
    L2 Cache Throughput                 %         6.07
    SM Active Cycles                cycle     2,451.53
    Compute (SM) Throughput             %         3.66
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.57
    Achieved Active Warps Per SM           warp         3.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 569040 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 590.99 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 591.036 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569040
[569040] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       770.89
    Elapsed Cycles                  cycle        4,784
    Memory Throughput                   %         6.03
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         9.40
    L2 Cache Throughput                 %         6.03
    SM Active Cycles                cycle     2,380.30
    Compute (SM) Throughput             %         4.21
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.06
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           25
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.82
    Achieved Active Warps Per SM           warp         3.46
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 569082 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 582.786 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 582.845 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569082
[569082] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.66
    SM Frequency            cycle/usecond       914.89
    Elapsed Cycles                  cycle        3,828
    Memory Throughput                   %         8.49
    DRAM Throughput                     %         0.84
    Duration                      usecond         4.13
    L1/TEX Cache Throughput             %        12.25
    L2 Cache Throughput                 %         8.49
    SM Active Cycles                cycle     1,715.93
    Compute (SM) Throughput             %         1.67
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.11
    Achieved Active Warps Per SM           warp         3.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=64, y=2
Block size: 64 x 2
==PROF== Connected to process 569124 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 64x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 564.806 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 564.852 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569124
[569124] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.62
    SM Frequency            cycle/usecond       913.00
    Elapsed Cycles                  cycle        3,787
    Memory Throughput                   %         8.67
    DRAM Throughput                     %         0.85
    Duration                      usecond         4.10
    L1/TEX Cache Throughput             %        12.02
    L2 Cache Throughput                 %         8.67
    SM Active Cycles                cycle     1,725.53
    Compute (SM) Throughput             %         1.69
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,200
    Waves Per SM                                                0.10
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.10
    Achieved Active Warps Per SM           warp         3.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569167 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 656.987 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 657.044 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569167
[569167] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.52
    SM Frequency            cycle/usecond       759.62
    Elapsed Cycles                  cycle        4,855
    Memory Throughput                   %         5.82
    DRAM Throughput                     %         0.66
    Duration                      usecond         6.30
    L1/TEX Cache Throughput             %        12.83
    L2 Cache Throughput                 %         5.82
    SM Active Cycles                cycle     1,412.03
    Compute (SM) Throughput             %         4.42
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.24
    Achieved Active Warps Per SM           warp         6.48
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569222 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 592.788 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 592.846 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569222
[569222] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.68
    SM Frequency            cycle/usecond       779.55
    Elapsed Cycles                  cycle        5,083
    Memory Throughput                   %         5.07
    DRAM Throughput                     %         0.73
    Duration                      usecond         6.46
    L1/TEX Cache Throughput             %        11.89
    L2 Cache Throughput                 %         5.07
    SM Active Cycles                cycle     1,504.93
    Compute (SM) Throughput             %         4.87
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.81
    Achieved Active Warps Per SM           warp         6.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569272 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84814e-05
GPU Execution Time: 561.537 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 561.58 ms
GPU: Temperature at center: 9.84814e-05
==PROF== Disconnected from process 569272
[569272] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.55
    SM Frequency            cycle/usecond       760.20
    Elapsed Cycles                  cycle        4,827
    Memory Throughput                   %         5.72
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %        14.70
    L2 Cache Throughput                 %         5.72
    SM Active Cycles                cycle     1,270.90
    Compute (SM) Throughput             %         3.76
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.82
    Achieved Active Warps Per SM           warp         6.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569314 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 568.469 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 568.518 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569314
[569314] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       769.43
    Elapsed Cycles                  cycle        4,816
    Memory Throughput                   %         5.12
    DRAM Throughput                     %         0.67
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        13.77
    L2 Cache Throughput                 %         5.12
    SM Active Cycles                cycle     1,276.10
    Compute (SM) Throughput             %         4.23
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.58
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        20.48
    Achieved Active Warps Per SM           warp         6.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 79.52%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (20.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569356 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 765.577 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 765.674 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569356
[569356] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.45
    SM Frequency            cycle/usecond       886.84
    Elapsed Cycles                  cycle        3,579
    Memory Throughput                   %         7.80
    DRAM Throughput                     %         0.90
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %        20.75
    L2 Cache Throughput                 %         7.80
    SM Active Cycles                cycle       879.77
    Compute (SM) Throughput             %         1.83
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.35
    Achieved Active Warps Per SM           warp         6.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.65%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=64, y=4
Block size: 64 x 4
==PROF== Connected to process 569399 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 64x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 542.478 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 542.528 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569399
[569399] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       902.10
    Elapsed Cycles                  cycle        3,597
    Memory Throughput                   %         7.75
    DRAM Throughput                     %         0.89
    Duration                      usecond         3.94
    L1/TEX Cache Throughput             %        19.83
    L2 Cache Throughput                 %         7.75
    SM Active Cycles                cycle       920.13
    Compute (SM) Throughput             %         1.81
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,328
    Waves Per SM                                                0.11
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.65
    Achieved Active Warps Per SM           warp         6.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569454 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 603.536 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 603.593 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569454
[569454] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       784.54
    Elapsed Cycles                  cycle        5,376
    Memory Throughput                   %         4.33
    DRAM Throughput                     %         0.60
    Duration                      usecond         6.78
    L1/TEX Cache Throughput             %        20.68
    L2 Cache Throughput                 %         4.33
    SM Active Cycles                cycle       870.97
    Compute (SM) Throughput             %         4.01
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.36
    Achieved Active Warps Per SM           warp        11.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569504 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 559.472 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 559.52 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569504
[569504] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       806.22
    Elapsed Cycles                  cycle        5,866
    Memory Throughput                   %         3.82
    DRAM Throughput                     %         0.64
    Duration                      usecond         7.17
    L1/TEX Cache Throughput             %        18.65
    L2 Cache Throughput                 %         3.82
    SM Active Cycles                cycle       940.60
    Compute (SM) Throughput             %         4.32
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           11
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.53
    Achieved Active Warps Per SM           warp        12.01
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569546 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12004e-06
GPU Step==nostream 9000, Center temp: 2.55379e-05
GPU: Temperature at center: 9.84792e-05
GPU Execution Time: 551.105 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 551.171 ms
GPU: Temperature at center: 9.84792e-05
==PROF== Disconnected from process 569546
[569546] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       782.74
    Elapsed Cycles                  cycle        5,152
    Memory Throughput                   %         4.64
    DRAM Throughput                     %         0.63
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        23.75
    L2 Cache Throughput                 %         4.64
    SM Active Cycles                cycle       758.30
    Compute (SM) Throughput             %         3.56
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        36.99
    Achieved Active Warps Per SM           warp        11.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 63.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569588 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 555.763 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 555.811 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569588
[569588] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.84
    SM Frequency            cycle/usecond       799.84
    Elapsed Cycles                  cycle        5,170
    Memory Throughput                   %         4.19
    DRAM Throughput                     %         0.62
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %        21.17
    L2 Cache Throughput                 %         4.19
    SM Active Cycles                cycle       804.10
    Compute (SM) Throughput             %         3.95
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.64
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           11
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        38.41
    Achieved Active Warps Per SM           warp        12.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 61.59%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569631 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 3568.7 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3568.76 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569631
[569631] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.62
    SM Frequency            cycle/usecond       947.23
    Elapsed Cycles                  cycle        4,159
    Memory Throughput                   %         5.23
    DRAM Throughput                     %         0.80
    Duration                      usecond         4.38
    L1/TEX Cache Throughput             %        31.51
    L2 Cache Throughput                 %         5.23
    SM Active Cycles                cycle       572.90
    Compute (SM) Throughput             %         1.60
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        41.50
    Achieved Active Warps Per SM           warp        13.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 58.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (41.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=64, y=8
Block size: 64 x 8
==PROF== Connected to process 569705 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 64x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33304e-07
GPU Step==nostream 8000, Center temp: 5.11997e-06
GPU Step==nostream 9000, Center temp: 2.55371e-05
GPU: Temperature at center: 9.84728e-05
GPU Execution Time: 563.976 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 564.023 ms
GPU: Temperature at center: 9.84728e-05
==PROF== Disconnected from process 569705
[569705] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       901.15
    Elapsed Cycles                  cycle        4,106
    Memory Throughput                   %         5.34
    DRAM Throughput                     %         0.78
    Duration                      usecond         4.51
    L1/TEX Cache Throughput             %        31.69
    L2 Cache Throughput                 %         5.34
    SM Active Cycles                cycle       568.63
    Compute (SM) Throughput             %         1.63
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           3,584
    Waves Per SM                                                0.12
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        42.62
    Achieved Active Warps Per SM           warp        13.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 57.38%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (42.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 569747 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.885 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 553.933 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569747
[569747] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.90
    SM Frequency            cycle/usecond       815.86
    Elapsed Cycles                  cycle        6,718
    Memory Throughput                   %         3.26
    DRAM Throughput                     %         0.49
    Duration                      usecond         8.13
    L1/TEX Cache Throughput             %        29.62
    L2 Cache Throughput                 %         3.26
    SM Active Cycles                cycle       621.17
    Compute (SM) Throughput             %         3.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        68.93
    Achieved Active Warps Per SM           warp        22.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 31.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (68.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 569800 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 628.848 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 628.892 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569800
[569800] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.32
    SM Frequency            cycle/usecond       873.92
    Elapsed Cycles                  cycle        7,675
    Memory Throughput                   %         2.86
    DRAM Throughput                     %         0.49
    Duration                      usecond         8.67
    L1/TEX Cache Throughput             %        25.20
    L2 Cache Throughput                 %         2.86
    SM Active Cycles                cycle       713.20
    Compute (SM) Throughput             %         3.40
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.75
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        69.83
    Achieved Active Warps Per SM           warp        22.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 30.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (69.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 569848 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.5534e-05
GPU: Temperature at center: 9.84554e-05
GPU Execution Time: 580.906 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 580.954 ms
GPU: Temperature at center: 9.84554e-05
==PROF== Disconnected from process 569848
[569848] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.11
    SM Frequency            cycle/usecond       843.34
    Elapsed Cycles                  cycle        6,263
    Memory Throughput                   %         3.56
    DRAM Throughput                     %         0.52
    Duration                      usecond         7.30
    L1/TEX Cache Throughput             %        32.39
    L2 Cache Throughput                 %         3.56
    SM Active Cycles                cycle       552.27
    Compute (SM) Throughput             %         3.04
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        68.55
    Achieved Active Warps Per SM           warp        21.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 31.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (68.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 569890 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3551.93 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 3552 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 569890
[569890] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.17
    SM Frequency            cycle/usecond       874.95
    Elapsed Cycles                  cycle        6,448
    Memory Throughput                   %         3.27
    DRAM Throughput                     %         0.52
    Duration                      usecond         7.33
    L1/TEX Cache Throughput             %        28.31
    L2 Cache Throughput                 %         3.27
    SM Active Cycles                cycle       595.80
    Compute (SM) Throughput             %         3.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.75
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        72.27
    Achieved Active Warps Per SM           warp        23.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 27.73%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 569954 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.55339e-05
GPU: Temperature at center: 9.84553e-05
GPU Execution Time: 586.107 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 586.174 ms
GPU: Temperature at center: 9.84553e-05
==PROF== Disconnected from process 569954
[569954] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       911.29
    Elapsed Cycles                  cycle        5,628
    Memory Throughput                   %         3.76
    DRAM Throughput                     %         0.58
    Duration                      usecond         6.08
    L1/TEX Cache Throughput             %        39.73
    L2 Cache Throughput                 %         3.76
    SM Active Cycles                cycle       454.10
    Compute (SM) Throughput             %         1.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        80.75
    Achieved Active Warps Per SM           warp        25.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 19.25%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=64, y=16
Block size: 64 x 16
==PROF== Connected to process 570005 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 64x16
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33276e-07
GPU Step==nostream 8000, Center temp: 5.11959e-06
GPU Step==nostream 9000, Center temp: 2.55339e-05
GPU: Temperature at center: 9.84553e-05
GPU Execution Time: 575.757 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 575.803 ms
GPU: Temperature at center: 9.84553e-05
==PROF== Disconnected from process 570005
[570005] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 4, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.61
    SM Frequency            cycle/usecond       912.01
    Elapsed Cycles                  cycle        5,567
    Memory Throughput                   %         3.82
    DRAM Throughput                     %         0.59
    Duration                      usecond         6.02
    L1/TEX Cache Throughput             %        38.64
    L2 Cache Throughput                 %         3.82
    SM Active Cycles                cycle       467.17
    Compute (SM) Throughput             %         1.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        79.50
    Achieved Active Warps Per SM           warp        25.44
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 20.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (79.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570047 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33306e-07
GPU Step==nostream 8000, Center temp: 5.12001e-06
GPU Step==nostream 9000, Center temp: 2.55376e-05
GPU: Temperature at center: 9.84771e-05
GPU Execution Time: 571.609 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 571.657 ms
GPU: Temperature at center: 9.84771e-05
==PROF== Disconnected from process 570047
[570047] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.58
    SM Frequency            cycle/usecond       764.94
    Elapsed Cycles                  cycle        4,905
    Memory Throughput                   %         7.89
    DRAM Throughput                     %         0.92
    Duration                      usecond         6.34
    L1/TEX Cache Throughput             %        10.14
    L2 Cache Throughput                 %         7.89
    SM Active Cycles                cycle     3,196.77
    Compute (SM) Throughput             %         4.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.46
    Achieved Active Warps Per SM           warp         3.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.54%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570089 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.408 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 539.453 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570089
[570089] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.94
    SM Frequency            cycle/usecond       813.07
    Elapsed Cycles                  cycle        5,345
    Memory Throughput                   %        10.80
    DRAM Throughput                     %         1.40
    Duration                      usecond         6.46
    L1/TEX Cache Throughput             %        13.67
    L2 Cache Throughput                 %        10.80
    SM Active Cycles                cycle     3,599.83
    Compute (SM) Throughput             %         5.72
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.56
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.10
    Achieved Active Warps Per SM           warp         4.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 85.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570131 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.5538e-05
GPU: Temperature at center: 9.84806e-05
GPU Execution Time: 574.63 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 574.678 ms
GPU: Temperature at center: 9.84806e-05
==PROF== Disconnected from process 570131
[570131] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       778.35
    Elapsed Cycles                  cycle        4,876
    Memory Throughput                   %         8.04
    DRAM Throughput                     %         0.93
    Duration                      usecond         6.21
    L1/TEX Cache Throughput             %        10.35
    L2 Cache Throughput                 %         8.04
    SM Active Cycles                cycle     2,909.23
    Compute (SM) Throughput             %         4.38
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.76
    Achieved Active Warps Per SM           warp         3.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570186 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 552.665 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 552.711 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570186
[570186] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.82
    SM Frequency            cycle/usecond       794.56
    Elapsed Cycles                  cycle        4,805
    Memory Throughput                   %         7.95
    DRAM Throughput                     %         0.94
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %        10.42
    L2 Cache Throughput                 %         7.95
    SM Active Cycles                cycle     2,753.17
    Compute (SM) Throughput             %         5.02
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            1.56
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           18
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        14.54
    Achieved Active Warps Per SM           warp         4.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 85.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570236 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 555.229 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 555.279 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570236
[570236] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.39
    SM Frequency            cycle/usecond       874.44
    Elapsed Cycles                  cycle        3,715
    Memory Throughput                   %        10.34
    DRAM Throughput                     %         1.22
    Duration                      usecond         4.19
    L1/TEX Cache Throughput             %        13.61
    L2 Cache Throughput                 %        10.34
    SM Active Cycles                cycle     2,058.43
    Compute (SM) Throughput             %         2.45
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        13.33
    Achieved Active Warps Per SM           warp         4.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 86.67%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (13.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=128, y=1
Block size: 128 x 1
==PROF== Connected to process 570278 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 128x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84725e-05
GPU Execution Time: 3587.94 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 3587.98 ms
GPU: Temperature at center: 9.84725e-05
==PROF== Disconnected from process 570278
[570278] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.47
    SM Frequency            cycle/usecond       933.32
    Elapsed Cycles                  cycle        3,797
    Memory Throughput                   %         9.86
    DRAM Throughput                     %         1.24
    Duration                      usecond         4.06
    L1/TEX Cache Throughput             %        13.04
    L2 Cache Throughput                 %         9.86
    SM Active Cycles                cycle     2,049.90
    Compute (SM) Throughput             %         2.37
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        13.32
    Achieved Active Warps Per SM           warp         4.26
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 86.68%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (13.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570353 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 555.855 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 555.905 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570353
[570353] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.46
    SM Frequency            cycle/usecond       754.05
    Elapsed Cycles                  cycle        4,945
    Memory Throughput                   %         6.77
    DRAM Throughput                     %         0.92
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %         8.01
    L2 Cache Throughput                 %         6.77
    SM Active Cycles                cycle     2,762.90
    Compute (SM) Throughput             %         4.84
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        13.53
    Achieved Active Warps Per SM           warp         4.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 86.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (13.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570395 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 540.137 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 540.186 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570395
[570395] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.85
    SM Frequency            cycle/usecond       802.84
    Elapsed Cycles                  cycle        5,394
    Memory Throughput                   %         7.88
    DRAM Throughput                     %         1.38
    Duration                      usecond         6.62
    L1/TEX Cache Throughput             %        11.79
    L2 Cache Throughput                 %         7.88
    SM Active Cycles                cycle     3,060.53
    Compute (SM) Throughput             %         5.67
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.08
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           14
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        16.15
    Achieved Active Warps Per SM           warp         5.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.85%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (16.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570437 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.8481e-05
GPU Execution Time: 587.955 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 587.998 ms
GPU: Temperature at center: 9.8481e-05
==PROF== Disconnected from process 570437
[570437] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       782.16
    Elapsed Cycles                  cycle        4,940
    Memory Throughput                   %         6.63
    DRAM Throughput                     %         0.92
    Duration                      usecond         6.24
    L1/TEX Cache Throughput             %         8.67
    L2 Cache Throughput                 %         6.63
    SM Active Cycles                cycle     2,583.90
    Compute (SM) Throughput             %         4.34
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        13.96
    Achieved Active Warps Per SM           warp         4.47
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 86.04%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (14.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570479 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 640.801 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 640.856 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570479
[570479] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.61
    SM Frequency            cycle/usecond       772.57
    Elapsed Cycles                  cycle        4,811
    Memory Throughput                   %         6.51
    DRAM Throughput                     %         0.95
    Duration                      usecond         6.14
    L1/TEX Cache Throughput             %         9.79
    L2 Cache Throughput                 %         6.51
    SM Active Cycles                cycle     2,385.83
    Compute (SM) Throughput             %         5.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            2.08
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           14
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        16.89
    Achieved Active Warps Per SM           warp         5.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.11%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (16.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570534 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 554.109 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 554.155 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570534
[570534] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       895.43
    Elapsed Cycles                  cycle        3,751
    Memory Throughput                   %         9.07
    DRAM Throughput                     %         1.22
    Duration                      usecond         4.13
    L1/TEX Cache Throughput             %        12.87
    L2 Cache Throughput                 %         9.07
    SM Active Cycles                cycle     1,723.70
    Compute (SM) Throughput             %         2.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        15.85
    Achieved Active Warps Per SM           warp         5.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 84.15%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (15.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=128, y=2
Block size: 128 x 2
==PROF== Connected to process 570584 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 128x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 554.971 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 555.047 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570584
[570584] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       892.63
    Elapsed Cycles                  cycle        3,768
    Memory Throughput                   %         8.85
    DRAM Throughput                     %         1.22
    Duration                      usecond         4.16
    L1/TEX Cache Throughput             %        12.81
    L2 Cache Throughput                 %         8.85
    SM Active Cycles                cycle     1,727.67
    Compute (SM) Throughput             %         2.42
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,400
    Waves Per SM                                                0.21
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        15.93
    Achieved Active Warps Per SM           warp         5.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 84.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (15.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570626 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 572.565 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 572.616 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570626
[570626] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.67
    SM Frequency            cycle/usecond       779.92
    Elapsed Cycles                  cycle        5,141
    Memory Throughput                   %         5.92
    DRAM Throughput                     %         0.88
    Duration                      usecond         6.53
    L1/TEX Cache Throughput             %        12.62
    L2 Cache Throughput                 %         5.92
    SM Active Cycles                cycle        1,529
    Compute (SM) Throughput             %         4.70
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        25.51
    Achieved Active Warps Per SM           warp         8.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 74.49%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (25.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570668 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.612 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 553.654 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570668
[570668] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.80
    SM Frequency            cycle/usecond       802.61
    Elapsed Cycles                  cycle        5,674
    Memory Throughput                   %         5.94
    DRAM Throughput                     %         1.33
    Duration                      usecond         6.98
    L1/TEX Cache Throughput             %        14.07
    L2 Cache Throughput                 %         5.94
    SM Active Cycles                cycle     1,716.87
    Compute (SM) Throughput             %         5.46
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.12
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.68
    Achieved Active Warps Per SM           warp         9.50
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (29.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570710 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.84806e-05
GPU Execution Time: 549.424 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 549.495 ms
GPU: Temperature at center: 9.84806e-05
==PROF== Disconnected from process 570710
[570710] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.49
    SM Frequency            cycle/usecond       759.95
    Elapsed Cycles                  cycle        4,926
    Memory Throughput                   %         6.10
    DRAM Throughput                     %         0.93
    Duration                      usecond         6.43
    L1/TEX Cache Throughput             %        15.49
    L2 Cache Throughput                 %         6.10
    SM Active Cycles                cycle     1,335.33
    Compute (SM) Throughput             %         4.35
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        26.53
    Achieved Active Warps Per SM           warp         8.49
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 73.47%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (26.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570765 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 566.137 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 566.186 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570765
[570765] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.70
    SM Frequency            cycle/usecond       786.61
    Elapsed Cycles                  cycle        5,212
    Memory Throughput                   %         5.14
    DRAM Throughput                     %         0.88
    Duration                      usecond         6.53
    L1/TEX Cache Throughput             %        13.20
    L2 Cache Throughput                 %         5.14
    SM Active Cycles                cycle     1,396.50
    Compute (SM) Throughput             %         4.69
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.12
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        31.38
    Achieved Active Warps Per SM           warp        10.04
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 68.62%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (31.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570815 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 595.579 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 595.632 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570815
[570815] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.48
    SM Frequency            cycle/usecond       886.82
    Elapsed Cycles                  cycle        3,621
    Memory Throughput                   %         8.38
    DRAM Throughput                     %         1.25
    Duration                      usecond         4.03
    L1/TEX Cache Throughput             %        21.49
    L2 Cache Throughput                 %         8.38
    SM Active Cycles                cycle       902.63
    Compute (SM) Throughput             %         2.58
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        30.83
    Achieved Active Warps Per SM           warp         9.87
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (30.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=128, y=4
Block size: 128 x 4
==PROF== Connected to process 570857 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 128x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84723e-05
GPU Execution Time: 603.281 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 603.325 ms
GPU: Temperature at center: 9.84723e-05
==PROF== Disconnected from process 570857
[570857] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       906.42
    Elapsed Cycles                  cycle        3,638
    Memory Throughput                   %         8.16
    DRAM Throughput                     %         1.26
    Duration                      usecond         3.97
    L1/TEX Cache Throughput             %        21.22
    L2 Cache Throughput                 %         8.16
    SM Active Cycles                cycle       911.37
    Compute (SM) Throughput             %         2.56
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           6,656
    Waves Per SM                                                0.22
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        30.65
    Achieved Active Warps Per SM           warp         9.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 69.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (30.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 570900 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33306e-07
GPU Step==nostream 8000, Center temp: 5.12001e-06
GPU Step==nostream 9000, Center temp: 2.55376e-05
GPU: Temperature at center: 9.84771e-05
GPU Execution Time: 580.767 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 580.808 ms
GPU: Temperature at center: 9.84771e-05
==PROF== Disconnected from process 570900
[570900] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.84
    SM Frequency            cycle/usecond       806.17
    Elapsed Cycles                  cycle        6,319
    Memory Throughput                   %         4.07
    DRAM Throughput                     %         0.72
    Duration                      usecond         7.74
    L1/TEX Cache Throughput             %        18.10
    L2 Cache Throughput                 %         4.07
    SM Active Cycles                cycle     1,064.80
    Compute (SM) Throughput             %         3.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        45.29
    Achieved Active Warps Per SM           warp        14.49
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 54.71%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (45.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 570942 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 565.832 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 565.887 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 570942
[570942] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.02
    SM Frequency            cycle/usecond       827.80
    Elapsed Cycles                  cycle        6,914
    Memory Throughput                   %         4.14
    DRAM Throughput                     %         1.08
    Duration                      usecond         8.26
    L1/TEX Cache Throughput             %        19.97
    L2 Cache Throughput                 %         4.14
    SM Active Cycles                cycle     1,181.70
    Compute (SM) Throughput             %         4.59
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            5.20
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        54.36
    Achieved Active Warps Per SM           warp        17.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 45.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (54.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 570995 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.84805e-05
GPU Execution Time: 550.427 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 550.478 ms
GPU: Temperature at center: 9.84805e-05
==PROF== Disconnected from process 570995
[570995] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond            6
    SM Frequency            cycle/usecond       832.64
    Elapsed Cycles                  cycle        6,068
    Memory Throughput                   %         3.96
    DRAM Throughput                     %         0.76
    Duration                      usecond         7.17
    L1/TEX Cache Throughput             %        21.34
    L2 Cache Throughput                 %         3.96
    SM Active Cycles                cycle       890.07
    Compute (SM) Throughput             %         3.64
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        48.65
    Achieved Active Warps Per SM           warp        15.57
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 51.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (48.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 571037 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 541.02 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 541.074 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571037
[571037] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.07
    SM Frequency            cycle/usecond       837.38
    Elapsed Cycles                  cycle        6,073
    Memory Throughput                   %         3.92
    DRAM Throughput                     %         0.75
    Duration                      usecond         7.17
    L1/TEX Cache Throughput             %        18.53
    L2 Cache Throughput                 %         3.92
    SM Active Cycles                cycle       965.70
    Compute (SM) Throughput             %         4.12
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            5.20
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            6
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        57.65
    Achieved Active Warps Per SM           warp        18.45
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 42.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (57.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 571085 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12003e-06
GPU Step==nostream 9000, Center temp: 2.55378e-05
GPU: Temperature at center: 9.8478e-05
GPU Execution Time: 765.204 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 765.271 ms
GPU: Temperature at center: 9.8478e-05
==PROF== Disconnected from process 571085
[571085] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.43
    SM Frequency            cycle/usecond       885.06
    Elapsed Cycles                  cycle        4,185
    Memory Throughput                   %         5.71
    DRAM Throughput                     %         1.09
    Duration                      usecond         4.67
    L1/TEX Cache Throughput             %        31.96
    L2 Cache Throughput                 %         5.71
    SM Active Cycles                cycle       597.03
    Compute (SM) Throughput             %         2.32
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        59.72
    Achieved Active Warps Per SM           warp        19.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 40.28%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (59.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=128, y=8
Block size: 128 x 8
==PROF== Connected to process 571127 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 128x8
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12003e-06
GPU Step==nostream 9000, Center temp: 2.55378e-05
GPU: Temperature at center: 9.8478e-05
GPU Execution Time: 586.32 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 586.388 ms
GPU: Temperature at center: 9.8478e-05
==PROF== Disconnected from process 571127
[571127] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 7, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.68
    SM Frequency            cycle/usecond       920.45
    Elapsed Cycles                  cycle        4,350
    Memory Throughput                   %         5.47
    DRAM Throughput                     %         1.05
    Duration                      usecond         4.67
    L1/TEX Cache Throughput             %        32.38
    L2 Cache Throughput                 %         5.47
    SM Active Cycles                cycle       592.07
    Compute (SM) Throughput             %         2.24
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      7
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           7,168
    Waves Per SM                                                0.23
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 76.67%                                                                                          
          The grid for this launch is configured to execute only 7 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        60.20
    Achieved Active Warps Per SM           warp        19.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 39.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (60.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571170 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84724e-05
GPU Execution Time: 561.404 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 561.453 ms
GPU: Temperature at center: 9.84724e-05
==PROF== Disconnected from process 571170
[571170] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       804.19
    Elapsed Cycles                  cycle        5,296
    Memory Throughput                   %         7.86
    DRAM Throughput                     %         1.37
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        10.31
    L2 Cache Throughput                 %         7.86
    SM Active Cycles                cycle     3,335.73
    Compute (SM) Throughput             %         5.56
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        16.52
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 83.48%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (16.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571212 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 644.434 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 644.494 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571212
[571212] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.64
    SM Frequency            cycle/usecond       904.33
    Elapsed Cycles                  cycle        6,207
    Memory Throughput                   %        14.74
    DRAM Throughput                     %         2.37
    Duration                      usecond         6.78
    L1/TEX Cache Throughput             %        18.61
    L2 Cache Throughput                 %        14.74
    SM Active Cycles                cycle     4,057.40
    Compute (SM) Throughput             %         6.81
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.10
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        26.25
    Achieved Active Warps Per SM           warp         8.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 73.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (26.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571267 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84814e-05
GPU Execution Time: 603.7 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 603.75 ms
GPU: Temperature at center: 9.84814e-05
==PROF== Disconnected from process 571267
[571267] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.80
    SM Frequency            cycle/usecond       790.02
    Elapsed Cycles                  cycle        5,022
    Memory Throughput                   %         8.34
    DRAM Throughput                     %         1.43
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %        10.76
    L2 Cache Throughput                 %         8.34
    SM Active Cycles                cycle     3,005.83
    Compute (SM) Throughput             %         5.60
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        17.94
    Achieved Active Warps Per SM           warp         5.74
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 82.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (17.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571318 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.869 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 543.916 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571318
[571318] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.07
    SM Frequency            cycle/usecond       826.59
    Elapsed Cycles                  cycle        5,018
    Memory Throughput                   %         8.25
    DRAM Throughput                     %         1.43
    Duration                      usecond         5.98
    L1/TEX Cache Throughput             %        10.82
    L2 Cache Throughput                 %         8.25
    SM Active Cycles                cycle     2,950.63
    Compute (SM) Throughput             %         6.42
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            3.10
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block            9
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        26.36
    Achieved Active Warps Per SM           warp         8.43
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 73.64%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (26.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571360 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84725e-05
GPU Execution Time: 535.414 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 535.464 ms
GPU: Temperature at center: 9.84725e-05
==PROF== Disconnected from process 571360
[571360] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.70
    SM Frequency            cycle/usecond       913.91
    Elapsed Cycles                  cycle        4,152
    Memory Throughput                   %         9.87
    DRAM Throughput                     %         1.73
    Duration                      usecond         4.48
    L1/TEX Cache Throughput             %        13.08
    L2 Cache Throughput                 %         9.87
    SM Active Cycles                cycle     2,063.83
    Compute (SM) Throughput             %         3.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.25
    Achieved Active Warps Per SM           warp         7.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=256, y=1
Block size: 256 x 1
==PROF== Connected to process 571402 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 256x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33303e-07
GPU Step==nostream 8000, Center temp: 5.11996e-06
GPU Step==nostream 9000, Center temp: 2.5537e-05
GPU: Temperature at center: 9.84726e-05
GPU Execution Time: 655.134 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 655.179 ms
GPU: Temperature at center: 9.84726e-05
==PROF== Disconnected from process 571402
[571402] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       912.80
    Elapsed Cycles                  cycle        4,143
    Memory Throughput                   %         9.89
    DRAM Throughput                     %         1.74
    Duration                      usecond         4.48
    L1/TEX Cache Throughput             %        13.08
    L2 Cache Throughput                 %         9.89
    SM Active Cycles                cycle     2,053.83
    Compute (SM) Throughput             %         3.51
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            8
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        22.41
    Achieved Active Warps Per SM           warp         7.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 77.59%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (22.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571444 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33306e-07
GPU Step==nostream 8000, Center temp: 5.12001e-06
GPU Step==nostream 9000, Center temp: 2.55377e-05
GPU: Temperature at center: 9.84776e-05
GPU Execution Time: 557.697 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 557.744 ms
GPU: Temperature at center: 9.84776e-05
==PROF== Disconnected from process 571444
[571444] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.96
    SM Frequency            cycle/usecond       821.12
    Elapsed Cycles                  cycle        5,402
    Memory Throughput                   %         6.74
    DRAM Throughput                     %         1.34
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %         8.83
    L2 Cache Throughput                 %         6.74
    SM Active Cycles                cycle     2,845.63
    Compute (SM) Throughput             %         5.45
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        19.50
    Achieved Active Warps Per SM           warp         6.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 80.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (19.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571499 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3586.11 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 3586.16 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571499
[571499] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.02
    SM Frequency            cycle/usecond       856.56
    Elapsed Cycles                  cycle        5,734
    Memory Throughput                   %        10.87
    DRAM Throughput                     %         2.65
    Duration                      usecond         6.69
    L1/TEX Cache Throughput             %        17.23
    L2 Cache Throughput                 %        10.87
    SM Active Cycles                cycle     3,407.37
    Compute (SM) Throughput             %         7.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.13
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.83
    Achieved Active Warps Per SM           warp         9.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (29.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571558 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84814e-05
GPU Execution Time: 597.661 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 597.71 ms
GPU: Temperature at center: 9.84814e-05
==PROF== Disconnected from process 571558
[571558] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.89
    SM Frequency            cycle/usecond       804.73
    Elapsed Cycles                  cycle        5,028
    Memory Throughput                   %         7.32
    DRAM Throughput                     %         1.43
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %         9.76
    L2 Cache Throughput                 %         7.32
    SM Active Cycles                cycle     2,579.03
    Compute (SM) Throughput             %         5.58
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.13
    Achieved Active Warps Per SM           warp         6.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 78.87%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (21.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571613 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 626.511 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 626.554 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571613
[571613] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.66
    SM Frequency            cycle/usecond       776.17
    Elapsed Cycles                  cycle        4,948
    Memory Throughput                   %         6.98
    DRAM Throughput                     %         1.45
    Duration                      usecond         6.30
    L1/TEX Cache Throughput             %        10.27
    L2 Cache Throughput                 %         6.98
    SM Active Cycles                cycle     2,521.80
    Compute (SM) Throughput             %         6.47
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            4.13
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            7
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        29.90
    Achieved Active Warps Per SM           warp         9.57
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 70.1%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (29.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571663 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12004e-06
GPU Step==nostream 9000, Center temp: 2.55378e-05
GPU: Temperature at center: 9.84785e-05
GPU Execution Time: 597.039 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 597.128 ms
GPU: Temperature at center: 9.84785e-05
==PROF== Disconnected from process 571663
[571663] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.99
    SM Frequency            cycle/usecond       954.15
    Elapsed Cycles                  cycle        4,082
    Memory Throughput                   %         8.42
    DRAM Throughput                     %         1.76
    Duration                      usecond         4.22
    L1/TEX Cache Throughput             %        12.96
    L2 Cache Throughput                 %         8.42
    SM Active Cycles                cycle     1,699.33
    Compute (SM) Throughput             %         3.56
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        26.94
    Achieved Active Warps Per SM           warp         8.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 73.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (26.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=256, y=2
Block size: 256 x 2
==PROF== Connected to process 571709 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 256x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33308e-07
GPU Step==nostream 8000, Center temp: 5.12004e-06
GPU Step==nostream 9000, Center temp: 2.55378e-05
GPU: Temperature at center: 9.84785e-05
GPU Execution Time: 630.927 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 631.044 ms
GPU: Temperature at center: 9.84785e-05
==PROF== Disconnected from process 571709
[571709] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.87
    SM Frequency            cycle/usecond       941.20
    Elapsed Cycles                  cycle        4,122
    Memory Throughput                   %         8.31
    DRAM Throughput                     %         1.75
    Duration                      usecond         4.32
    L1/TEX Cache Throughput             %        12.30
    L2 Cache Throughput                 %         8.31
    SM Active Cycles                cycle     1,773.83
    Compute (SM) Throughput             %         3.53
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          12,800
    Waves Per SM                                                0.42
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        26.42
    Achieved Active Warps Per SM           warp         8.45
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 73.58%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (26.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571761 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66025e-08
GPU Step==nostream 7000, Center temp: 7.33307e-07
GPU Step==nostream 8000, Center temp: 5.12003e-06
GPU Step==nostream 9000, Center temp: 2.55379e-05
GPU: Temperature at center: 9.84795e-05
GPU Execution Time: 569.052 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 569.102 ms
GPU: Temperature at center: 9.84795e-05
==PROF== Disconnected from process 571761
[571761] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.87
    SM Frequency            cycle/usecond       806.36
    Elapsed Cycles                  cycle        5,410
    Memory Throughput                   %         6.35
    DRAM Throughput                     %         1.33
    Duration                      usecond         6.62
    L1/TEX Cache Throughput             %        13.54
    L2 Cache Throughput                 %         6.35
    SM Active Cycles                cycle     1,620.70
    Compute (SM) Throughput             %         5.51
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        36.98
    Achieved Active Warps Per SM           warp        11.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 63.02%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571805 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 537.728 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 537.777 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571805
[571805] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.94
    SM Frequency            cycle/usecond       814.37
    Elapsed Cycles                  cycle        6,018
    Memory Throughput                   %         7.95
    DRAM Throughput                     %         2.47
    Duration                      usecond         7.30
    L1/TEX Cache Throughput             %        20.96
    L2 Cache Throughput                 %         7.95
    SM Active Cycles                cycle     1,860.23
    Compute (SM) Throughput             %         7.18
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.19
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        53.30
    Achieved Active Warps Per SM           warp        17.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 46.7%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (53.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571860 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84814e-05
GPU Execution Time: 609.231 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 609.282 ms
GPU: Temperature at center: 9.84814e-05
==PROF== Disconnected from process 571860
[571860] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.65
    SM Frequency            cycle/usecond       772.08
    Elapsed Cycles                  cycle        5,019
    Memory Throughput                   %         6.75
    DRAM Throughput                     %         1.44
    Duration                      usecond         6.40
    L1/TEX Cache Throughput             %        16.11
    L2 Cache Throughput                 %         6.75
    SM Active Cycles                cycle     1,363.07
    Compute (SM) Throughput             %         5.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        42.57
    Achieved Active Warps Per SM           warp        13.62
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 57.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (42.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571911 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 562.932 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 562.975 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 571911
[571911] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.69
    SM Frequency            cycle/usecond       774.98
    Elapsed Cycles                  cycle        5,296
    Memory Throughput                   %         5.69
    DRAM Throughput                     %         1.35
    Duration                      usecond         6.75
    L1/TEX Cache Throughput             %        14.12
    L2 Cache Throughput                 %         5.69
    SM Active Cycles                cycle        1,449
    Compute (SM) Throughput             %         6.22
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.19
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        55.03
    Achieved Active Warps Per SM           warp        17.61
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 44.97%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (55.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571956 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.8481e-05
GPU Execution Time: 587.157 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 587.198 ms
GPU: Temperature at center: 9.8481e-05
==PROF== Disconnected from process 571956
[571956] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.70
    SM Frequency            cycle/usecond       919.65
    Elapsed Cycles                  cycle        3,838
    Memory Throughput                   %         8.75
    DRAM Throughput                     %         1.88
    Duration                      usecond         4.13
    L1/TEX Cache Throughput             %        23.83
    L2 Cache Throughput                 %         8.75
    SM Active Cycles                cycle       928.20
    Compute (SM) Throughput             %         3.89
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        51.63
    Achieved Active Warps Per SM           warp        16.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 48.37%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (51.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=256, y=4
Block size: 256 x 4
==PROF== Connected to process 571998 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 256x4
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55381e-05
GPU: Temperature at center: 9.8481e-05
GPU Execution Time: 563.894 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 563.943 ms
GPU: Temperature at center: 9.8481e-05
==PROF== Disconnected from process 571998
[571998] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 13, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.61
    SM Frequency            cycle/usecond       907.85
    Elapsed Cycles                  cycle        3,830
    Memory Throughput                   %         8.67
    DRAM Throughput                     %         1.89
    Duration                      usecond         4.16
    L1/TEX Cache Throughput             %        22.62
    L2 Cache Throughput                 %         8.67
    SM Active Cycles                cycle       960.40
    Compute (SM) Throughput             %         3.91
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.4 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     13
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          13,312
    Waves Per SM                                                0.43
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 56.67%                                                                                          
          The grid for this launch is configured to execute only 13 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        52.68
    Achieved Active Warps Per SM           warp        16.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 47.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (52.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572041 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12006e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84813e-05
GPU Execution Time: 551.802 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 551.845 ms
GPU: Temperature at center: 9.84813e-05
==PROF== Disconnected from process 572041
[572041] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.86
    SM Frequency            cycle/usecond       941.76
    Elapsed Cycles                  cycle        6,197
    Memory Throughput                   %         7.92
    DRAM Throughput                     %         2.03
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        10.26
    L2 Cache Throughput                 %         7.92
    SM Active Cycles                cycle     3,408.07
    Compute (SM) Throughput             %         6.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        27.80
    Achieved Active Warps Per SM           warp         8.90
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 72.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572096 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26891e-13
GPU Step==nostream 4000, Center temp: 5.83951e-11
GPU Step==nostream 5000, Center temp: 3.18288e-09
GPU Step==nostream 6000, Center temp: 6.65978e-08
GPU Step==nostream 7000, Center temp: 7.33163e-07
GPU Step==nostream 8000, Center temp: 5.11778e-06
GPU Step==nostream 9000, Center temp: 2.55163e-05
GPU: Temperature at center: 9.83373e-05
GPU Execution Time: 621.44 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 621.484 ms
GPU: Temperature at center: 9.83373e-05
==PROF== Disconnected from process 572096
[572096] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.54
    SM Frequency            cycle/usecond       890.57
    Elapsed Cycles                  cycle        8,377
    Memory Throughput                   %        23.95
    DRAM Throughput                     %         3.51
    Duration                      usecond         9.31
    L1/TEX Cache Throughput             %        29.02
    L2 Cache Throughput                 %        23.95
    SM Active Cycles                cycle     5,411.77
    Compute (SM) Throughput             %         8.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.17
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        54.34
    Achieved Active Warps Per SM           warp        17.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 45.66%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (54.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572146 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 709.806 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 709.863 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572146
[572146] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.80
    SM Frequency            cycle/usecond       796.58
    Elapsed Cycles                  cycle        5,000
    Memory Throughput                   %         9.99
    DRAM Throughput                     %         2.52
    Duration                      usecond         6.18
    L1/TEX Cache Throughput             %        12.78
    L2 Cache Throughput                 %         9.99
    SM Active Cycles                cycle     2,984.63
    Compute (SM) Throughput             %         8.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        32.11
    Achieved Active Warps Per SM           warp        10.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (32.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572188 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 612.885 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 612.931 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572188
[572188] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.01
    SM Frequency            cycle/usecond       818.23
    Elapsed Cycles                  cycle        5,003
    Memory Throughput                   %         9.86
    DRAM Throughput                     %         2.48
    Duration                      usecond         6.05
    L1/TEX Cache Throughput             %        12.66
    L2 Cache Throughput                 %         9.86
    SM Active Cycles                cycle     2,901.47
    Compute (SM) Throughput             %         9.68
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            6.17
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block            5
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        47.65
    Achieved Active Warps Per SM           warp        15.25
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 52.35%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (47.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572231 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 546.316 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 546.365 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572231
[572231] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.56
    SM Frequency            cycle/usecond       895.71
    Elapsed Cycles                  cycle        4,796
    Memory Throughput                   %        10.36
    DRAM Throughput                     %         2.61
    Duration                      usecond         5.28
    L1/TEX Cache Throughput             %        14.38
    L2 Cache Throughput                 %        10.36
    SM Active Cycles                cycle     2,202.13
    Compute (SM) Throughput             %         5.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        38.66
    Achieved Active Warps Per SM           warp        12.37
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 61.34%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=512, y=1
Block size: 512 x 1
==PROF== Connected to process 572273 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 512x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 572.077 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 572.122 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572273
[572273] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       895.20
    Elapsed Cycles                  cycle        4,800
    Memory Throughput                   %        10.45
    DRAM Throughput                     %         2.62
    Duration                      usecond         5.28
    L1/TEX Cache Throughput             %        14.22
    L2 Cache Throughput                 %        10.45
    SM Active Cycles                cycle     2,219.07
    Compute (SM) Throughput             %         5.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        38.52
    Achieved Active Warps Per SM           warp        12.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 61.48%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572329 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84815e-05
GPU Execution Time: 571.486 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 571.53 ms
GPU: Temperature at center: 9.84815e-05
==PROF== Disconnected from process 572329
[572329] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       902.14
    Elapsed Cycles                  cycle        5,954
    Memory Throughput                   %         7.44
    DRAM Throughput                     %         2.12
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %         9.47
    L2 Cache Throughput                 %         7.44
    SM Active Cycles                cycle     2,963.30
    Compute (SM) Throughput             %         6.79
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        32.24
    Achieved Active Warps Per SM           warp        10.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (32.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572379 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18292e-09
GPU Step==nostream 6000, Center temp: 6.66011e-08
GPU Step==nostream 7000, Center temp: 7.33269e-07
GPU Step==nostream 8000, Center temp: 5.11954e-06
GPU Step==nostream 9000, Center temp: 2.55341e-05
GPU: Temperature at center: 9.8459e-05
GPU Execution Time: 596.877 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 596.922 ms
GPU: Temperature at center: 9.8459e-05
==PROF== Disconnected from process 572379
[572379] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.55
    SM Frequency            cycle/usecond       891.38
    Elapsed Cycles                  cycle        6,956
    Memory Throughput                   %        16.97
    DRAM Throughput                     %         4.23
    Duration                      usecond         7.71
    L1/TEX Cache Throughput             %        26.12
    L2 Cache Throughput                 %        16.97
    SM Active Cycles                cycle     4,153.77
    Compute (SM) Throughput             %        10.17
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            8.22
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        62.58
    Achieved Active Warps Per SM           warp        20.03
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 37.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (62.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572421 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 539.17 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 539.211 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572421
[572421] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.04
    SM Frequency            cycle/usecond       822.76
    Elapsed Cycles                  cycle        5,213
    Memory Throughput                   %         8.48
    DRAM Throughput                     %         2.39
    Duration                      usecond         6.27
    L1/TEX Cache Throughput             %        11.15
    L2 Cache Throughput                 %         8.48
    SM Active Cycles                cycle     2,575.83
    Compute (SM) Throughput             %         7.90
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.93
    Achieved Active Warps Per SM           warp        12.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 62.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (37.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572463 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 694.428 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 694.505 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572463
[572463] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.86
    SM Frequency            cycle/usecond       802.96
    Elapsed Cycles                  cycle        5,286
    Memory Throughput                   %         7.98
    DRAM Throughput                     %         2.37
    Duration                      usecond         6.50
    L1/TEX Cache Throughput             %        11.46
    L2 Cache Throughput                 %         7.98
    SM Active Cycles                cycle     2,572.03
    Compute (SM) Throughput             %         9.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block            8.22
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            3
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        54.37
    Achieved Active Warps Per SM           warp        17.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 45.63%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (54.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572505 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 553.034 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 553.107 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572505
[572505] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       899.33
    Elapsed Cycles                  cycle        4,796
    Memory Throughput                   %         9.31
    DRAM Throughput                     %         2.62
    Duration                      usecond         5.25
    L1/TEX Cache Throughput             %        14.99
    L2 Cache Throughput                 %         9.31
    SM Active Cycles                cycle     1,868.23
    Compute (SM) Throughput             %         5.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        45.81
    Achieved Active Warps Per SM           warp        14.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 54.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (45.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=512, y=2
Block size: 512 x 2
==PROF== Connected to process 572560 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 512x2
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 543.502 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 543.546 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572560
[572560] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 25, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.58
    SM Frequency            cycle/usecond       904.33
    Elapsed Cycles                  cycle        4,779
    Memory Throughput                   %         9.23
    DRAM Throughput                     %         2.63
    Duration                      usecond         5.22
    L1/TEX Cache Throughput             %        15.10
    L2 Cache Throughput                 %         9.23
    SM Active Cycles                cycle     1,868.93
    Compute (SM) Throughput             %         5.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.8 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     25
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          25,600
    Waves Per SM                                                0.83
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 16.67%                                                                                          
          The grid for this launch is configured to execute only 25 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        46.16
    Achieved Active Warps Per SM           warp        14.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 53.84%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (46.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_fma, solver=fma, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572611 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 3
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83952e-11
GPU Step==nostream 5000, Center temp: 3.18293e-09
GPU Step==nostream 6000, Center temp: 6.66014e-08
GPU Step==nostream 7000, Center temp: 7.33266e-07
GPU Step==nostream 8000, Center temp: 5.11929e-06
GPU Step==nostream 9000, Center temp: 2.55301e-05
GPU: Temperature at center: 9.84245e-05
GPU Execution Time: 543.56 ms
Kernel Type: fma
Total GPU Execution Time (including verification): 543.609 ms
GPU: Temperature at center: 9.84245e-05
==PROF== Disconnected from process 572611
[572611] heat_equation_solver@127.0.0.1
  heat_equation_kernel_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.99
    SM Frequency            cycle/usecond       824.12
    Elapsed Cycles                  cycle        8,524
    Memory Throughput                   %         7.53
    DRAM Throughput                     %         2.74
    Duration                      usecond        10.21
    L1/TEX Cache Throughput             %         9.58
    L2 Cache Throughput                 %         7.53
    SM Active Cycles                cycle     5,004.57
    Compute (SM) Throughput             %         6.89
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 72.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        27.45
    Achieved Active Warps Per SM           warp         8.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 72.55%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (27.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory_fma, solver=shared_fma, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572653 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 4
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26891e-13
GPU Step==nostream 4000, Center temp: 5.83951e-11
GPU Step==nostream 5000, Center temp: 3.18288e-09
GPU Step==nostream 6000, Center temp: 6.65981e-08
GPU Step==nostream 7000, Center temp: 7.33169e-07
GPU Step==nostream 8000, Center temp: 5.11787e-06
GPU Step==nostream 9000, Center temp: 2.5517e-05
GPU: Temperature at center: 9.83411e-05
GPU Execution Time: 554.481 ms
Kernel Type: shared_fma
Total GPU Execution Time (including verification): 554.526 ms
GPU: Temperature at center: 9.83411e-05
==PROF== Disconnected from process 572653
[572653] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.46
    SM Frequency            cycle/usecond       869.45
    Elapsed Cycles                  cycle       13,721
    Memory Throughput                   %        33.83
    DRAM Throughput                     %         4.23
    Duration                      usecond        15.62
    L1/TEX Cache Throughput             %        35.90
    L2 Cache Throughput                 %        33.83
    SM Active Cycles                cycle    10,129.57
    Compute (SM) Throughput             %         9.89
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              30
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block           12.31
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 30.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        69.34
    Achieved Active Warps Per SM           warp        22.19
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 30.66%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (69.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_basic, solver=basic, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572695 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 0
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_basic": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.33309e-07
GPU Step==nostream 8000, Center temp: 5.12005e-06
GPU Step==nostream 9000, Center temp: 2.55379e-05
GPU: Temperature at center: 9.84792e-05
GPU Execution Time: 602.527 ms
Kernel Type: basic
Total GPU Execution Time (including verification): 602.595 ms
GPU: Temperature at center: 9.84792e-05
==PROF== Disconnected from process 572695
[572695] heat_equation_solver@127.0.0.1
  heat_equation_kernel_basic(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.93
    SM Frequency            cycle/usecond       814.65
    Elapsed Cycles                  cycle        8,069
    Memory Throughput                   %         7.94
    DRAM Throughput                     %         2.88
    Duration                      usecond         9.76
    L1/TEX Cache Throughput             %        10.24
    L2 Cache Throughput                 %         7.94
    SM Active Cycles                cycle     4,466.47
    Compute (SM) Throughput             %         8.03
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 67.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        32.94
    Achieved Active Warps Per SM           warp        10.54
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 67.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (32.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_shared_memory, solver=shared, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572737 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 1
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_shared_memory": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 544.309 ms
Kernel Type: shared
Total GPU Execution Time (including verification): 544.358 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572737
[572737] heat_equation_solver@127.0.0.1
  heat_equation_kernel_shared_memory(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         5.89
    SM Frequency            cycle/usecond       807.15
    Elapsed Cycles                  cycle        8,755
    Memory Throughput                   %         7.20
    DRAM Throughput                     %         2.64
    Duration                      usecond        10.72
    L1/TEX Cache Throughput             %         9.35
    L2 Cache Throughput                 %         7.20
    SM Active Cycles                cycle     4,494.93
    Compute (SM) Throughput             %         8.98
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              26
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block      Kbyte/block           12.31
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 47.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            2
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        52.54
    Achieved Active Warps Per SM           warp        16.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 47.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (52.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll, solver=loop_unroll, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572793 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 2
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3547.27 ms
Kernel Type: loop_unroll
Total GPU Execution Time (including verification): 3547.33 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572793
[572793] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       965.63
    Elapsed Cycles                  cycle        7,341
    Memory Throughput                   %         8.42
    DRAM Throughput                     %         3.27
    Duration                      usecond         7.58
    L1/TEX Cache Throughput             %        12.14
    L2 Cache Throughput                 %         8.42
    SM Active Cycles                cycle     3,350.93
    Compute (SM) Throughput             %         5.91
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 61.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        38.26
    Achieved Active Warps Per SM           warp        12.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 61.74%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (38.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
Running ncu with kernel=heat_equation_kernel_loop_unroll_fma, solver=loop_unroll_fma, block sizes x=1024, y=1
Block size: 1024 x 1
==PROF== Connected to process 572851 (/home/tesla/exp/ggml/build/bin/heat_equation_solver)
HeatEquationSolverNoStreams initialized with:
  Grid size: 50 x 50
Initial Condition set.
Verifying results between CPU and GPU without streams...
Using GPU without streams for computation.
Kernel Type: 5
Block Size: 1024x1
GPU Step==nostream 0, Center temp: 0
==PROF== Profiling "heat_equation_kernel_loop_unroll_fma": 0%....50%....100% - 8 passes
GPU Step==nostream 1000, Center temp: 7.74316e-24
GPU Step==nostream 2000, Center temp: 4.87592e-17
GPU Step==nostream 3000, Center temp: 2.26892e-13
GPU Step==nostream 4000, Center temp: 5.83953e-11
GPU Step==nostream 5000, Center temp: 3.18294e-09
GPU Step==nostream 6000, Center temp: 6.66026e-08
GPU Step==nostream 7000, Center temp: 7.3331e-07
GPU Step==nostream 8000, Center temp: 5.12007e-06
GPU Step==nostream 9000, Center temp: 2.55382e-05
GPU: Temperature at center: 9.84816e-05
GPU Execution Time: 3664.93 ms
Kernel Type: loop_unroll_fma
Total GPU Execution Time (including verification): 3664.99 ms
GPU: Temperature at center: 9.84816e-05
==PROF== Disconnected from process 572851
[572851] heat_equation_solver@127.0.0.1
  heat_equation_kernel_loop_unroll_fma(float *, float *, int, int, float, float, float, float) (1, 50, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       950.94
    Elapsed Cycles                  cycle        7,367
    Memory Throughput                   %         8.48
    DRAM Throughput                     %         3.23
    Duration                      usecond         7.71
    L1/TEX Cache Throughput             %        12.49
    L2 Cache Throughput                 %         8.48
    SM Active Cycles                cycle     3,255.83
    Compute (SM) Throughput             %         5.90
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     50
    Registers Per Thread             register/thread              28
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          51,200
    Waves Per SM                                                1.67
    -------------------------------- --------------- ---------------

    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the 
          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   
          hardware busy.                                                                                                
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 50%                                                                                             
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 20 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 60.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        39.25
    Achieved Active Warps Per SM           warp        12.56
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 60.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (39.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

---------------------------------
